{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentence_Level_QE_2020.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonmiu0214/C490CW/blob/master/Sentence_Level_QE_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZxVjhzS2c-V",
        "colab_type": "text"
      },
      "source": [
        "# CO490 Coursework: Quality Estimation\n",
        "\n",
        "__Team__\n",
        "* Anson Miu (kcm116)\n",
        "* Cheryl Chen (czc16)\n",
        "* Clara Gila (acg116)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWQnFCxu4dY2",
        "colab_type": "text"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3D_kGEs2Ytf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sklearn\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVbHKGnn5rMa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup CUDA\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "torch_device = getattr(torch, str(device))\n",
        "torch_device.empty_cache()\n",
        "print(f'DEVICE={torch_device.get_device_name()}')\n",
        "print(torch.cuda.memory_summary(device=device))\n",
        "print(torch.cuda.get_device_properties(device))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRPKYtOY4b_R",
        "colab_type": "text"
      },
      "source": [
        "## Utilities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ0QmO6854oV",
        "colab_type": "text"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu7YdlRu67oI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n",
        "\n",
        "TRAIN_EN = 'train.enzh.src'\n",
        "TRAIN_ZH = 'train.enzh.mt'\n",
        "TRAIN_SCORES = 'train.enzh.scores'\n",
        "VAL_EN = 'dev.enzh.src'\n",
        "VAL_ZH = 'dev.enzh.mt'\n",
        "VAL_SCORES = 'dev.enzh.scores'\n",
        "TEST_EN = 'test.enzh.src'\n",
        "TEST_ZH = 'test.enzh.mt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iueDTtRB6_FR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read from file\n",
        "\n",
        "with open(TRAIN_EN) as f:\n",
        "    train_en = f.readlines()\n",
        "with open(TRAIN_ZH) as f:\n",
        "    train_zh = f.readlines()\n",
        "with open(TRAIN_SCORES) as f:\n",
        "    train_scores = [float(score.strip()) for score in f]\n",
        "with open(VAL_EN) as f:\n",
        "    val_en = f.readlines()\n",
        "with open(VAL_ZH) as f:\n",
        "    val_zh = f.readlines()\n",
        "with open(VAL_SCORES) as f:\n",
        "    val_scores = [float(score.strip()) for score in f]\n",
        "with open(TEST_EN) as f:\n",
        "    test_en = f.readlines()\n",
        "with open(TEST_ZH) as f:\n",
        "    test_zh = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E4aobJfx-8Du",
        "colab_type": "text"
      },
      "source": [
        "### Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DfzhFEZU-9dh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    is_numpy = isinstance(pred, np.ndarray) or isinstance(target, np.ndarray)\n",
        "\n",
        "    mean = np.mean if is_numpy else torch.mean\n",
        "    sqrt = np.sqrt if is_numpy else torch.sqrt\n",
        "    return sqrt(mean((pred - target) ** 2))\n",
        "\n",
        "def pearson_score(pred, target):\n",
        "    if isinstance(pred, torch.Tensor):\n",
        "        pred = pred.numpy()\n",
        "\n",
        "    if isinstance(target, torch.Tensor):\n",
        "        target = target.numpy()\n",
        "\n",
        "    score, _ = pearsonr(pred, target)\n",
        "    return score\n",
        "\n",
        "from sklearn.metrics import make_scorer\n",
        "pearson_sklearn = make_scorer(pearson_score, greater_is_better=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqVMR9GWRE24",
        "colab_type": "text"
      },
      "source": [
        "### Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihnKQs_4RGvI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def concat_zip(en_embs, zh_embs):\n",
        "    \"\"\"Zip up the sentence embeddings as pairs.\"\"\"\n",
        "\n",
        "    if isinstance(en_embs, list):\n",
        "        en_embs = torch.cat(en_embs)\n",
        "    if isinstance(zh_embs, list):\n",
        "        zh_embs = torch.cat(zh_embs)\n",
        "    return torch.cat((en_embs, zh_embs), dim=1)\n",
        "\n",
        "\n",
        "class SourceMTDataset(Dataset):\n",
        "    \"\"\"PyTorch dataset for **labelled** data.\"\"\"\n",
        "\n",
        "    def __init__(self, inputs, output):\n",
        "        assert isinstance(inputs, list), f'Expected type of inputs to be list, got {type(inputs)}'\n",
        "\n",
        "        self.inputs = inputs\n",
        "        self.output = output\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return [input_[index] for input_ in self.inputs], self.output[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.output)\n",
        "\n",
        "def build_dataset(*, X, Y, idxs=None):\n",
        "    \"\"\"Return labelled Dataset object compatible with DataLoader.\n",
        "    \n",
        "    Optionally pass in `idxs` to filter which data points to use.\"\"\"\n",
        "\n",
        "    if idxs is not None:\n",
        "        X = [input_[idxs] for input_ in X]\n",
        "        Y = Y[idxs]\n",
        "\n",
        "    Cnstr = torch.LongTensor if type(X[0]) == np.ndarray else torch.FloatTensor\n",
        "\n",
        "    inputs_tensors = [Cnstr(input_) for input_ in X]\n",
        "    return SourceMTDataset(inputs_tensors, Y)\n",
        "\n",
        "\n",
        "class SourceMTTestset(Dataset):\n",
        "    \"\"\"PyTorch dataset for **unlabelled** data.\"\"\"\n",
        "\n",
        "    def __init__(self, inputs):\n",
        "        assert isinstance(inputs, list), f'Expected type of inputs to be list, got {type(inputs)}'\n",
        "\n",
        "        self.inputs = inputs\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return [input_[index] for input_ in self.inputs]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs[0])\n",
        "\n",
        "def build_test_dataset(X):\n",
        "    \"\"\"Return unlabelled Dataset object compatible with DataLoader.\"\"\"\n",
        "\n",
        "    Cnstr = torch.LongTensor if type(X[0]) == np.ndarray else torch.FloatTensor\n",
        "\n",
        "    inputs_tensors = [Cnstr(input_) for input_ in X]\n",
        "    return SourceMTTestset(inputs_tensors)\n",
        "\n",
        "def save_predictions(results, *, zip_name):\n",
        "    \"\"\"Save predictions into compressed text file for CodaLab submission.\"\"\"\n",
        "\n",
        "    with open('predictions.txt', 'w') as f:\n",
        "        for line in results:\n",
        "            f.write(f'{line}\\n')\n",
        "\n",
        "    zip_name = f'{zip_name}.zip'\n",
        "    !zip $zip_name predictions.txt "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI1jjStOB712",
        "colab_type": "text"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74W4mB7XB-aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import PrettyPrinter\n",
        "\n",
        "pp = PrettyPrinter()\n",
        "\n",
        "def suppress_log(*args, **kwargs):\n",
        "    pass\n",
        "\n",
        "def debug_log(*args, **kwargs):\n",
        "    print('[Debug]:', end='')\n",
        "    print(*args, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21_ZnyY30Upk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def torch_model_factory(model_cls, model_params, *,\n",
        "                        opt, lr, num_epochs, batch_size, loss_fn,\n",
        "                        detailed_log=True):\n",
        "    \"\"\"A pseudo-decorator for a PyTorch model to support k-fold cross validation.\n",
        "\n",
        "    Params:\n",
        "        model_cls: Model class\n",
        "        model_params: Parameters to construct `model_cls`\n",
        "\n",
        "        others: for model training\n",
        "    Returns:\n",
        "        A factory function that builds a new model with additional attributes\n",
        "    \"\"\"\n",
        "\n",
        "    def factory():\n",
        "        model = model_cls(**model_params)\n",
        "    \n",
        "        def fit(dataset):\n",
        "            \"\"\"Performs mini-batch SGD and returns the loss per batch.\"\"\"\n",
        "\n",
        "            # Enter train mode\n",
        "            model.train()\n",
        "            model.to(device)\n",
        "\n",
        "            # Construct data loader\n",
        "            loader = DataLoader(dataset=dataset, batch_size=batch_size)\n",
        "\n",
        "            optimiser = opt(model.parameters(), lr=lr)\n",
        "            \n",
        "            losses = []\n",
        "            epoch_progress = range(1, num_epochs + 1)\n",
        "            if not detailed_log:\n",
        "                epoch_progress = tqdm(epoch_progress, desc='Epoch')\n",
        "\n",
        "            for epoch in epoch_progress:\n",
        "                if detailed_log:\n",
        "                    header = f'Epoch {epoch}'\n",
        "                    print(header)\n",
        "                    print('=' * len(header))\n",
        "\n",
        "                progress = loader\n",
        "                if detailed_log:\n",
        "                    progress = tqdm(progress,\n",
        "                                    desc=f'Training: Mini-Batch SGD (size={batch_size})')\n",
        "                for X, scores in progress:\n",
        "                    optimiser.zero_grad()\n",
        "\n",
        "                    pred = model(*(x.to(device) for x in X)).squeeze()\n",
        "                \n",
        "                    loss = loss_fn(pred, scores.to(device))\n",
        "\n",
        "                    loss.backward()\n",
        "                    optimiser.step()\n",
        "                \n",
        "                    losses.append(loss.cpu().detach().numpy())\n",
        "                \n",
        "                if detailed_log:\n",
        "                    print(f'Most recent loss:', loss.cpu().detach().numpy())\n",
        "                    print()\n",
        "            return losses\n",
        "\n",
        "        def predict(dataset, **metrics):\n",
        "            \"\"\"Returns the loss and metrics from the predictions.\"\"\"\n",
        "\n",
        "            # Enter evaluation mode\n",
        "            model.eval()\n",
        "            model.to(device)\n",
        "\n",
        "            loader = DataLoader(dataset=dataset, batch_size=1)\n",
        "\n",
        "            preds = []\n",
        "            scores = []\n",
        "            with torch.no_grad():\n",
        "                for X, score in tqdm(loader, desc='Validating'):\n",
        "                    pred = model(*(x.to(device) for x in X)).squeeze().cpu()\n",
        "                    preds.append(pred)\n",
        "                    scores.append(score)\n",
        "            \n",
        "                preds = torch.stack(preds)\n",
        "                scores = torch.cat(scores)\n",
        "\n",
        "                loss = loss_fn(preds, scores)\n",
        "                metric_scores = {name: metric_fn(preds, scores)\n",
        "                            for name, metric_fn in metrics.items()}\n",
        "                return loss, metric_scores\n",
        "\n",
        "        def evaluate(train_dataset, test_dataset, **metrics):\n",
        "            \"\"\"Trains the model and accumulates metrics on the test set\n",
        "            on every epoch.\n",
        "            \"\"\"\n",
        "\n",
        "            model.to(device)\n",
        "\n",
        "            # Construct data loaders\n",
        "            train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size)\n",
        "            test_loader = DataLoader(dataset=test_dataset, batch_size=1)\n",
        "\n",
        "            # Setup training\n",
        "            optimiser = opt(model.parameters(), lr=lr)\n",
        "            \n",
        "            train_losses = []\n",
        "            val_losses = []\n",
        "            val_metrics = {metric: [] for metric in metrics}\n",
        "\n",
        "            epoch_progress = range(1, num_epochs + 1)\n",
        "            if not detailed_log:\n",
        "                epoch_progress = tqdm(epoch_progress, desc='Epoch')\n",
        "\n",
        "            for epoch in epoch_progress:\n",
        "                if detailed_log:\n",
        "                    header = f'Epoch {epoch}'\n",
        "                    print(header)\n",
        "                    print('=' * len(header))\n",
        "\n",
        "                progress = train_loader\n",
        "                if detailed_log:\n",
        "                    progress = tqdm(progress,\n",
        "                                    desc=f'Training: Mini-Batch SGD (size={batch_size})')\n",
        "                    \n",
        "                model.train()\n",
        "                for X, scores in progress:\n",
        "                    optimiser.zero_grad()\n",
        "\n",
        "                    pred = model(*(x.to(device) for x in X)).squeeze()\n",
        "                \n",
        "                    loss = loss_fn(pred, scores.to(device))\n",
        "\n",
        "                    loss.backward()\n",
        "                    optimiser.step()\n",
        "                \n",
        "                # Only append most recent loss\n",
        "                train_losses.append(loss.cpu().detach().numpy())\n",
        "                \n",
        "                if detailed_log:\n",
        "                    print(f'Most recent loss:', loss.cpu().detach().numpy())\n",
        "                    print()\n",
        "\n",
        "                # Validation\n",
        "                preds = []\n",
        "                scores = []\n",
        "                with torch.no_grad():\n",
        "                    model.eval()\n",
        "\n",
        "                    eval_progress = test_loader\n",
        "                    if detailed_log:\n",
        "                        eval_progress = tqdm(eval_progress, desc='Validating')\n",
        "\n",
        "                    for X, score in eval_progress:\n",
        "                        pred = model(*(x.to(device) for x in X)).squeeze().cpu()\n",
        "                        preds.append(pred)\n",
        "                        scores.append(score)\n",
        "                \n",
        "                    preds = torch.stack(preds)\n",
        "                    scores = torch.cat(scores)\n",
        "\n",
        "                    loss = loss_fn(preds, scores)\n",
        "                    metric_scores = {name: metric_fn(preds, scores)\n",
        "                                    for name, metric_fn in metrics.items()}\n",
        "\n",
        "                    val_losses.append(loss.cpu().detach().numpy())\n",
        "                    for name, metric in metric_scores.items():\n",
        "                        val_metrics[name].append(metric)\n",
        "            \n",
        "            return model, (train_losses, val_losses, val_metrics, preds, scores)\n",
        "\n",
        "        model.fit = fit\n",
        "        model.predict = predict\n",
        "        model.evaluate = evaluate\n",
        "\n",
        "        return model\n",
        "\n",
        "    return factory\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShuPigQ4-it1",
        "colab_type": "text"
      },
      "source": [
        "### Cross-Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "opPeoVsXxZA9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "def torch_kfold_cross_validate(make_model, *,\n",
        "                               inputs,\n",
        "                               outputs,\n",
        "                               n_splits=2,\n",
        "                               random_state=0,\n",
        "                               **metrics):\n",
        "\n",
        "    # Convert output scores to PyTorch tensor.\n",
        "    if not isinstance(outputs, torch.FloatTensor):\n",
        "        outputs = torch.FloatTensor(outputs)\n",
        "    \n",
        "    if not isinstance(inputs, list):\n",
        "        inputs = [inputs]\n",
        "    \n",
        "    # Reset seeding\n",
        "    torch.manual_seed(random_state)\n",
        "    if device == 'cuda':\n",
        "        torch.cuda.manual_seed(random_state)\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    cv_split = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    total_loss = 0\n",
        "    total_metrics = {metric: 0 for metric in metrics}\n",
        "\n",
        "    for fold, (train_idxs, test_idxs) in enumerate(cv_split.split(inputs[0])):\n",
        "        print(f'>> Fold {fold + 1}')\n",
        "\n",
        "        # Create new model.\n",
        "        model = make_model()\n",
        "\n",
        "        train_set = build_dataset(X=inputs, Y=outputs, idxs=train_idxs)\n",
        "        test_set = build_dataset(X=inputs, Y=outputs, idxs=test_idxs)\n",
        "\n",
        "        # Training\n",
        "        model.fit(train_set)\n",
        "\n",
        "        # Evaluation\n",
        "        loss, metric_scores = model.predict(test_set, **metrics)\n",
        "\n",
        "        total_loss += loss\n",
        "        total_metrics = {name: total_metrics[name] + metric_scores[name]\n",
        "                         for name in metrics}\n",
        "\n",
        "        print()\n",
        "\n",
        "    total_loss /= n_splits\n",
        "    total_metrics = {name: total_metrics[name] / n_splits\n",
        "                     for name in metrics}\n",
        "    return total_loss, total_metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UaKe-jgrWF-g",
        "colab_type": "text"
      },
      "source": [
        "### Visualisations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nj9s1Guvg2SE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def performance_to_dataframe(performance, *,\n",
        "                             sort_by=['pearson', 'Loss'],\n",
        "                             ascending=[0, 1]):\n",
        "    performance_np = np.array(performance)\n",
        "    performance_df = pd.DataFrame(data=performance_np[1:], columns=performance_np[0])\n",
        "    return performance_df.sort_values(by=sort_by, ascending=ascending)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpDQlhdYXD-B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mount Google Drive to save data\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    # FOR COLAB\n",
        "    # =========\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "\n",
        "    !ls '/content'\n",
        "\n",
        "    def in_gdrive(path):\n",
        "        return os.path.join('/content/gdrive/My Drive/Colab Notebooks', path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AXFVI2iYW7K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def visualise(train_losses, val_losses, metrics, predicted, actual, *,\n",
        "              name,\n",
        "              save_to_gdrive=True):\n",
        "    print('>> ACTUAL / PREDICTED SCORE ')\n",
        "    plt.scatter(actual, predicted)\n",
        "    plt.plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'k--', lw=2)\n",
        "    plt.xlabel('Actual')\n",
        "    plt.ylabel('Predicted')\n",
        "\n",
        "    path = f'{name}_actual_predicted.png'\n",
        "    if save_to_gdrive:\n",
        "        path = in_gdrive(path)\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    epoch_ticks = np.arange(1, len(train_losses) + 1, 1)\n",
        "    print('>> TRAINING / VALIDATION LOSS ')\n",
        "    plt.plot(epoch_ticks, train_losses, label='Training')\n",
        "    plt.plot(epoch_ticks, val_losses, label='Validation')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.legend(loc='best')\n",
        "    plt.title(f'Final Training Loss: {train_losses[-1]}\\n'\n",
        "              f'Final Validation Loss: {val_losses[-1]}')\n",
        "\n",
        "    path = f'{name}_train_val_loss.png'\n",
        "    if save_to_gdrive:\n",
        "        path = in_gdrive(path)\n",
        "    plt.savefig(path)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print('\\n>> VALIDATION METRICS')\n",
        "    fig_size = 5\n",
        "    fig, axes = plt.subplots(1, len(metrics), figsize=(fig_size, fig_size * len(metrics)))\n",
        "    if not isinstance(axes, list):\n",
        "        axes = [axes]\n",
        "\n",
        "    for ax, (metric_name, metric_scores) in zip(axes, metrics.items()):\n",
        "        ax.plot(epoch_ticks, metric_scores)\n",
        "        ax.set_xlabel('Epochs')\n",
        "        ax.set_ylabel(metric_name)\n",
        "        ax.set_title(f'Final {metric_name}: {metric_scores[-1]}')\n",
        "\n",
        "        print(f'Final {metric_name}: {metric_scores[-1]}')\n",
        "    path = f'{name}_metrics.png'\n",
        "    if save_to_gdrive:\n",
        "        path = in_gdrive(path)\n",
        "    fig.savefig(path)\n",
        "    fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "veQBkjct8ZaG",
        "colab_type": "text"
      },
      "source": [
        "## Building Blocks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZmZ93sp77m7A",
        "colab_type": "text"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_lrVXI97s2b",
        "colab_type": "text"
      },
      "source": [
        "#### English\n",
        "\n",
        "* spaCy - tokenisation\n",
        "* NLTK - stop word removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUPhA4_O7v9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading spacy models for English\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300 --force\n",
        "\n",
        "# Downloading stop words for English\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download('stopwords')\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXtrvOrY7yky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp_en = spacy.load('en300')\n",
        "\n",
        "def preprocess_en(sentence=None, *, keep_stopwords=False):\n",
        "    \"\"\"Preprocess English sentence using spaCy for tokenisation.\n",
        "    Toggle `keep_stopwords=True` to preserve stopwords.\"\"\"\n",
        "\n",
        "    def wrapper(sentence):\n",
        "        text = sentence.lower()\n",
        "        processed = [token.lemma_ for token in nlp_en.tokenizer(text)]\n",
        "        processed = [token for token in processed if token.isalpha()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_en]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CgiLUG9H7u1w",
        "colab_type": "text"
      },
      "source": [
        "#### Chinese\n",
        "\n",
        "* Jieba - tokenisation\n",
        "* @Tony607/Chinese_sentiment_analysis - stop words removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-AdPRx28I88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download stopwords\n",
        "FILE_STOP_WORDS_ZH = './chinese_stop_words.txt'\n",
        "\n",
        "if not os.path.exists(FILE_STOP_WORDS_ZH):\n",
        "    !wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "with open(FILE_STOP_WORDS_ZH, 'r', encoding='utf-8') as f:\n",
        "    stop_words_zh = [line.rstrip() for line in f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oHaP5WNq8Ktu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "\n",
        "def preprocess_zh(sentence=None, *, keep_stopwords=False):\n",
        "    \"\"\"Preprocess Chinese sentence using jieba for tokenisation.\n",
        "    Toggle `keep_stopwords=True` to preserve stopwords.\"\"\"\n",
        "    \n",
        "    def wrapper(sentence):\n",
        "        tokens = jieba.cut(sentence, cut_all=False)\n",
        "        processed = [token for token in tokens if token.isalnum()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_zh]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPR81o4a8h61",
        "colab_type": "text"
      },
      "source": [
        "### Pretrained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIphelUd8lw4",
        "colab_type": "text"
      },
      "source": [
        "#### English\n",
        "\n",
        "* GloVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sthoro0t_U_I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "def get_en_sentence_vector(tokens, *, dim=100):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            vectors.append(glove.vectors[glove.stoi[token]])\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "    if not vectors:\n",
        "        vectors.append(torch.zeros(dim))\n",
        "    \n",
        "    return torch.stack(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Z_zZxYe8nGR",
        "colab_type": "text"
      },
      "source": [
        "#### Chinese\n",
        "\n",
        "* NLPL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMh7P9lM93vF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ZH_MODEL_BIN = 'model.bin'\n",
        "\n",
        "if not os.path.exists(ZH_MODEL_BIN):\n",
        "    !wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "    !unzip zh.zip \n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(ZH_MODEL_BIN, binary=True) \n",
        "\n",
        "def get_zh_sentence_vector(tokens, *, dim=100):\n",
        "    vectors = []\n",
        "    for token in tokens:\n",
        "        try:\n",
        "            vectors.append(torch.Tensor(wv_from_bin[token]))\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "    if not vectors:\n",
        "        vectors.append(torch.zeros(dim))\n",
        "    \n",
        "    return torch.stack(vectors)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha-UrrMBEsCO",
        "colab_type": "text"
      },
      "source": [
        "### Sentence Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDQXVmCnFBP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences(sents, *, pad_token=0):\n",
        "    \"\"\"Pad sentences with `pad_token` to the longest sentence in `sents.\"\"\"\n",
        "\n",
        "    # Get max sentence length\n",
        "    sent_lengths = [len(sent) for sent in sents]\n",
        "    max_sent_len = max(sent_lengths)\n",
        "    \n",
        "    # Create empty matrix with padding tokens\n",
        "    padded_sents = np.ones((len(sents), max_sent_len)) * pad_token\n",
        "\n",
        "    # Copy over the sequences\n",
        "    for i, (sent_len, sent) in enumerate(zip(sent_lengths, sents)):\n",
        "        padded_sents[i, 0:sent_len] = sent[:sent_len]\n",
        "    return padded_sents\n",
        "\n",
        "def average_vector(sent, *, dim=100):\n",
        "    return torch.mean(sent, dim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ES0WJSe394RK",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary Representation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPM1ZsCy97Fu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Language(object):\n",
        "\n",
        "    PAD_TOKEN = '<PAD>'\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {0: self.PAD_TOKEN,\n",
        "                         1: self.UNK_TOKEN}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for token in sentence:\n",
        "            self.add_word(token)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            idx = len(self)\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "    \n",
        "    def sent_to_idxs(self, sent):\n",
        "        return [self.word2idx.get(word, 1) for word in sent]\n",
        "\n",
        "    def __getitem__(self, key):\n",
        "        if isinstance(key, int):\n",
        "            return self.idx2word[key]\n",
        "        if isinstance(key, str):\n",
        "            return self.word2idx[key]\n",
        "        raise KeyError(key)\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f'Language(name={self.name}) with {len(self)} words'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zRvOx8cweIpu"
      },
      "source": [
        "### BERT (`pytorch-pretrained-bert`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QOC5KCzDeGHc",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-pretrained-bert\n",
        "\n",
        "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0DAKPhFbeFb1"
      },
      "source": [
        "#### Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F8sMbtjN16_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_groups_to_bert_tokens(tokenizer, *sents, max_length=256):\n",
        "    assert len(sents) > 0, 'No sentences to tokenise!'\n",
        "\n",
        "    bert_inputs = []\n",
        "    num_reserved_markers = 3\n",
        "\n",
        "    for sent_group in zip(*sents):\n",
        "        sent_tokens = [tokenizer.tokenize(sent) for sent in sent_group]\n",
        "        total_length = sum([len(sent) for sent in sent_tokens]) + num_reserved_markers\n",
        "        if total_length > max_length:\n",
        "            raise Exception(f'Too long ({total_length} > {max_length})')\n",
        "\n",
        "        tokens = ['[CLS]']\n",
        "        for sent in sent_tokens:\n",
        "            tokens += sent\n",
        "            tokens.append('[SEP]')\n",
        "        \n",
        "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # Apply sentence length padding\n",
        "        padding = [0] * (max_length - len(ids))\n",
        "        ids_tensor = torch.LongTensor(ids + padding)\n",
        "        bert_inputs.append(ids_tensor)\n",
        "\n",
        "    return torch.stack(bert_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjHpfnnMM-pt",
        "colab_type": "text"
      },
      "source": [
        "#### Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coQS0D3KNDR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_bert_embeddings(bert_lm, input_ids, *, batch_size=25):\n",
        "    bert_lm.to(device)\n",
        "\n",
        "    num_batches = math.ceil(len(input_ids) / batch_size)\n",
        "\n",
        "    embs = []\n",
        "    for batch_id in tqdm(range(num_batches), desc='Batch'):\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        input_id_batch = input_ids[start_id:end_id]\n",
        "\n",
        "        if isinstance(bert_lm, BertForSequenceClassification):\n",
        "            emb = bert_lm(input_id_batch.to(device))\n",
        "        else:\n",
        "            _, emb = bert_lm(input_id_batch.to(device))\n",
        "        embs.append(emb.detach().cpu())\n",
        "\n",
        "    return embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W39EUatFYX1s",
        "colab_type": "text"
      },
      "source": [
        "### BERT (`transformers`)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NrAg9l9YaA6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install transformers\n",
        "\n",
        "from transformers import BertForSequenceClassification, BertTokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "652ZiUyWe9cY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_bert_embeddings_with_mask(bert_lm, input_ids, attention_masks, *, batch_size=25):\n",
        "    bert_lm.to(device)\n",
        "\n",
        "    num_batches = math.ceil(len(input_ids) / batch_size)\n",
        "\n",
        "    embs = []\n",
        "    for batch_id in tqdm(range(num_batches), desc='Batch'):\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "\n",
        "        input_id_batch = torch.LongTensor(input_ids[start_id:end_id])\n",
        "        mask_batch = torch.LongTensor(attention_masks[start_id:end_id])\n",
        "\n",
        "        _, emb = bert_lm(input_id_batch.to(device), mask_batch.to(device))\n",
        "        embs.append(emb.detach().cpu())\n",
        "\n",
        "    return embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V6OH0y463VAB",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5C26nlnf3dP2",
        "colab_type": "text"
      },
      "source": [
        "### 1) Baseline with FFNN Regressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkI9PUCZLD1V",
        "colab_type": "text"
      },
      "source": [
        "#### Pipeline\n",
        "\n",
        "1. Manual preprocessing\n",
        "    * EN - tokenisation with [spaCy](https://spacy.io),\n",
        "    stopword removal\n",
        "    * ZH - tokenisation with [jieba](https://github.com/fxsjy/jieba),\n",
        "    stopword removal, \n",
        "2. Pretrained embeddings\n",
        "    * EN - GloVe\n",
        "    * ZH - TODO\n",
        "3. Regression model\n",
        "    * SVR\n",
        "    * LinearRegression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCN0Ys0l3saM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########\n",
        "# ENGLISH\n",
        "##########\n",
        "\n",
        "# Preprocessing\n",
        "preprocess_english = preprocess_en(keep_stopwords=False)\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "# Get sentence average vector representation \n",
        "train_en_vecs = torch.stack([average_vector(get_en_sentence_vector(sent))\n",
        "                             for sent in train_en_sents])\n",
        "val_en_vecs = torch.stack([average_vector(get_en_sentence_vector(sent))\n",
        "                           for sent in val_en_sents])\n",
        "test_en_vecs = torch.stack([average_vector(get_en_sentence_vector(sent))\n",
        "                            for sent in test_en_sents])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDA2ZuQsPCXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########\n",
        "# CHINESE\n",
        "##########\n",
        "\n",
        "# Preprocessing\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=False)\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "# Get sentence average vector representation\n",
        "train_zh_vecs = torch.stack([average_vector(get_zh_sentence_vector(sent))\n",
        "                             for sent in train_zh_sents])\n",
        "val_zh_vecs = torch.stack([average_vector(get_zh_sentence_vector(sent))\n",
        "                           for sent in val_zh_sents])\n",
        "test_zh_vecs = torch.stack([average_vector(get_zh_sentence_vector(sent))\n",
        "                            for sent in test_zh_sents])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3d66UwjlIgym",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_concat_vecs = concat_zip(train_en_vecs, train_zh_vecs)\n",
        "val_concat_vecs = concat_zip(val_en_vecs, val_zh_vecs)\n",
        "test_concat_vecs = concat_zip(test_en_vecs, test_zh_vecs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GTCKGfdLIuQ",
        "colab_type": "text"
      },
      "source": [
        "#### Model Architecture\n",
        "\n",
        "Feed-forward neural network for regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_TjL3MwV9UA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNNRegression(nn.Module):\n",
        "\n",
        "    def __init__(self, *, hidden_dims, input_dim, nonlin=F.relu):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        prev_dim = input_dim\n",
        "        for i, hidden_dim in enumerate(self.hidden_dims):\n",
        "            setattr(self, f'hidden_{i}', nn.Linear(prev_dim, hidden_dim))\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        self.out = nn.Linear(prev_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        act = x\n",
        "        for i, _ in enumerate(self.hidden_dims):\n",
        "            layer = getattr(self, f'hidden_{i}')\n",
        "            act = self.nonlin(layer(act))\n",
        "        return self.out(act)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt3B3pYNJ9N9",
        "colab_type": "text"
      },
      "source": [
        "#### Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFD47omxKC9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################\n",
        "# OPTIONS FOR GRID SEARCH\n",
        "#########################\n",
        "LR = 1e-2, 1e-3\n",
        "NONLIN = F.relu, F.leaky_relu, torch.sigmoid\n",
        "LAYERS = [], (16,), (128,), (32, 16), (64, 16), (128, 64, 16)\n",
        "\n",
        "# Base configurations\n",
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "base_hyperparameters = {'opt': torch.optim.Adam,\n",
        "                        'num_epochs': 200,\n",
        "                        'batch_size': 1,\n",
        "                        'loss_fn': RMSELoss}\n",
        "\n",
        "n_splits = 10\n",
        "performance = []\n",
        "for lr in LR:\n",
        "    for nonlin in NONLIN:\n",
        "        for hidden_dims in LAYERS:\n",
        "            header = f'LR={lr}, nonlin={nonlin.__name__}, hidden_dims={hidden_dims}'\n",
        "            print(header)\n",
        "            print('=' * len(header))\n",
        "\n",
        "            model_params = dict(input_dim=200, hidden_dims=hidden_dims, nonlin=nonlin)\n",
        "            hyperparameters = dict(**base_hyperparameters)\n",
        "            hyperparameters['lr'] = lr\n",
        "\n",
        "            model_factory = torch_model_factory(FFNNRegression,\n",
        "                                                model_params,\n",
        "                                                **hyperparameters,\n",
        "                                                detailed_log=False)\n",
        "            \n",
        "            loss, metrics = torch_kfold_cross_validate(model_factory,\n",
        "                                                       inputs=train_concat_vecs,\n",
        "                                                       outputs=train_scores,\n",
        "                                                       n_splits=n_splits,\n",
        "                                                       **non_loss_metrics)\n",
        "            \n",
        "            performance.append(((lr, nonlin.__name__, hidden_dims), (loss, metrics)))\n",
        "            print()\n",
        "\n",
        "for (lr, nonlin, hidden_dims), (loss, metrics) in performance:\n",
        "    print(f'LR={lr}, nonlin={nonlin}, hidden_dims={hidden_dims}')\n",
        "    print(f'  MAE Loss:\\t {loss}')\n",
        "    for name, metric in metrics.items():\n",
        "        print(f'  {name}:\\t {metric}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qTfpxmXV9jo",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9S7sLhZWIE4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick the optimal model hyperparameters to train.\n",
        "model_params = dict(input_dim=200, hidden_dims=(100,),\n",
        "                    nonlin=torch.tanh)\n",
        "\n",
        "hyperparameters = {'opt': torch.optim.Adam,\n",
        "                   'num_epochs': 500,\n",
        "                   'batch_size': 16,\n",
        "                   'lr': 1e-4,\n",
        "                   'loss_fn': RMSELoss}\n",
        "\n",
        "model_for_validation = torch_model_factory(FFNNRegression,\n",
        "                                           model_params,\n",
        "                                           **hyperparameters,\n",
        "                                           detailed_log=False)()\n",
        "\n",
        "train_set = build_dataset(X=[train_concat_vecs], Y=train_scores)\n",
        "val_set = build_dataset(X=[val_concat_vecs], Y=val_scores)\n",
        "\n",
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "\n",
        "print('>> TRAINING START')\n",
        "model, results = model_for_validation.evaluate(train_set, val_set, **non_loss_metrics)\n",
        "train_losses, val_losses, metrics, predicted, actual = results\n",
        "print('>> TRAINING FINISH')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDwvPMatWImC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise(train_losses, val_losses, metrics, predicted, actual,\n",
        "          name='BERT sentence pair embeddings',\n",
        "          save_to_gdrive=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1FcYJx1h390-",
        "colab_type": "text"
      },
      "source": [
        "### 2) Autoencoder with Quality Estimation Vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-BjP81TD92L",
        "colab_type": "text"
      },
      "source": [
        "#### Pipeline\n",
        "\n",
        "1. Manual preprocessing\n",
        "    * EN - tokenisation with [spaCy](https://spacy.io),\n",
        "    stopword removal\n",
        "    * ZH - tokenisation with [jieba](https://github.com/fxsjy/jieba),\n",
        "    stopword removal, \n",
        "2. Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-WsPDb8D_cN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########\n",
        "# ENGLISH\n",
        "##########\n",
        "\n",
        "preprocess_english = preprocess_en(keep_stopwords=False)\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "EN = Language('EN')\n",
        "for sent in train_en_sents:\n",
        "    EN.add_sentence(sent)\n",
        "print(EN)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_en = train_en_sents[42]\n",
        "print(sample_sent_en)\n",
        "print(EN.sent_to_idxs(sample_sent_en))\n",
        "\n",
        "train_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in train_en_sents])\n",
        "val_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in val_en_sents])\n",
        "test_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in test_en_sents])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0AZicNdEHXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########\n",
        "# CHINESE\n",
        "##########\n",
        "\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=False)\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "ZH = Language('ZH')\n",
        "for sent in train_zh_sents:\n",
        "    ZH.add_sentence(sent)\n",
        "print(ZH)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_zh = train_zh_sents[0]\n",
        "print(sample_sent_zh)\n",
        "print(ZH.sent_to_idxs(sample_sent_zh))\n",
        "\n",
        "train_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in train_zh_sents])\n",
        "val_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in val_zh_sents])\n",
        "test_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in test_zh_sents])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boPVjjtKDpH9",
        "colab_type": "text"
      },
      "source": [
        "#### Model Architecture\n",
        "\n",
        "* Embedding layers\n",
        "* RNN autoencoder to generate quality estimation vectors\n",
        "* Output regression layer using FFNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YcKqF9EG4EvN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class AutoencoderQEV(nn.Module):\n",
        "\n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        \"\"\"Source sentence: embedding layer + encoder.\"\"\"\n",
        "        self.source_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.source_rnn = nn.GRU(input_size=self.emb_dim,\n",
        "                                 hidden_size=self.emb_dim,\n",
        "                                 bidirectional=True)\n",
        "\n",
        "        \"\"\"Target sentence: embedding layer + decoder with attention.\"\"\"\n",
        "        self.target_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "        self.target_rnn = nn.GRU(input_size=self.emb_dim,\n",
        "                                 hidden_size=self.emb_dim * 2,\n",
        "                                 bidirectional=False)\n",
        "\n",
        "        \"\"\"RNN for producing summary unit.\"\"\"\n",
        "        self.qualvec_rnn = nn.GRU(input_size=self.emb_dim * 2,\n",
        "                                  hidden_size=self.emb_dim,\n",
        "                                  bidirectional=False)\n",
        "\n",
        "        \"\"\"Regression output layer.\"\"\"\n",
        "        self.regressor_output = nn.Linear(in_features=self.emb_dim,\n",
        "                                          out_features=1)\n",
        "\n",
        "    def forward(self, en_sent, zh_sent, *, log=suppress_log, get_qualvecs=False):\n",
        "        \"\"\"Perform forward pass and returns the prediction scores.\n",
        "\n",
        "        Parameters:\n",
        "            en_sent: (batch_size, en_max_sent_len)\n",
        "            zh_sent: (batch_size, zh_max_sent_len)\n",
        "        \n",
        "        Debug parameters:\n",
        "            log: custom `print` function, defaults to suppressing messages\n",
        "            get_qualvecs: if True, returns the quality vectors instead.\n",
        "        \"\"\"\n",
        "\n",
        "        en_batch_size, en_sent_len = en_sent.shape\n",
        "        en_emb = self.source_embedding(en_sent)\n",
        "        log('en_emb:', en_emb.shape)\n",
        "\n",
        "        en_emb = en_emb.view(en_sent_len, en_batch_size, -1)\n",
        "        log('en_emb:', en_emb.shape)\n",
        "        en_all_hids, en_last_hid = self.source_rnn(en_emb)\n",
        "\n",
        "        log('en_all_hids:', en_all_hids.shape)\n",
        "        log('en_last_hid:', en_last_hid.shape)\n",
        "\n",
        "        ############################################\n",
        "        def get_context(prev_state):\n",
        "            log('prev_state:', prev_state.shape)\n",
        "            s_s = []\n",
        "            for hid in en_all_hids:\n",
        "                s_s_batches = torch.Tensor([\n",
        "                    one_hid_batch.dot(one_prev_state_batch)\n",
        "                    for one_hid_batch, one_prev_state_batch in zip(prev_state, hid)\n",
        "                ])\n",
        "                s_s.append(s_s_batches)\n",
        "            \n",
        "            s_s = torch.stack(s_s, dim=0)\n",
        "            log('s_s', s_s.shape)\n",
        "\n",
        "            a_s = F.softmax(s_s, dim=0)\n",
        "            log('a_s', a_s.shape)\n",
        "\n",
        "            ctx_vecs = []\n",
        "            for j, (a_i, hid) in enumerate(zip(a_s, en_all_hids)):\n",
        "                vecs = []\n",
        "                for i, (one_a_batch, one_hid_batch) in enumerate(zip(a_i, hid)):\n",
        "                    vec = one_a_batch * one_hid_batch\n",
        "                    vecs.append(vec)\n",
        "                \n",
        "                vecs = torch.stack(vecs)\n",
        "                ctx_vecs.append(vecs)\n",
        "\n",
        "            ctx_vecs = torch.stack(ctx_vecs).sum(dim=0)\n",
        "            log(f'ctx_vecs', ctx_vecs.shape)\n",
        "            return ctx_vecs\n",
        "\n",
        "        ############################################\n",
        "\n",
        "        zh_batch_size, zh_sent_len = zh_sent.shape\n",
        "        log('zh_sent_len', zh_sent_len)\n",
        "        zh_emb = self.target_embedding(zh_sent)\n",
        "\n",
        "        log('zh_emb:', zh_emb.shape)\n",
        "        zh_emb = zh_emb.view(zh_sent_len, zh_batch_size, -1)\n",
        "        log('zh_emb:', zh_emb.shape)\n",
        "\n",
        "        qualvecs = []\n",
        "        zh_hid = None\n",
        "        for zh in zh_emb:\n",
        "            log('zh:', zh.shape)\n",
        "            zh = zh.view(1, zh_batch_size, -1)\n",
        "            log('zh:', zh.shape)\n",
        "            if zh_hid is None:\n",
        "                _, zh_hid = self.target_rnn(zh)\n",
        "            else:\n",
        "                _, zh_hid = self.target_rnn(zh, zh_hid)\n",
        "            log('zh_hid:', zh_hid.shape)\n",
        "\n",
        "            zh_hid_reshaped = zh_hid.view(zh_batch_size, -1)\n",
        "            log('zh_hid_reshaped:', zh_hid_reshaped.shape)\n",
        "\n",
        "            ctx = get_context(zh_hid_reshaped)\n",
        "            log('ctx:', ctx.shape)\n",
        "            \n",
        "            # Linear combination = sum\n",
        "            qualvecs.append(ctx + zh_hid_reshaped)\n",
        "\n",
        "        qualvecs = torch.stack(qualvecs)\n",
        "        log('qualvecs:', qualvecs.shape)\n",
        "\n",
        "        if get_qualvecs:\n",
        "            return qualvecs\n",
        "\n",
        "        _, qualvec_hid = self.qualvec_rnn(qualvecs)\n",
        "        log('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        qualvec_hid = qualvec_hid.view(zh_batch_size, -1)\n",
        "        log('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        qualvec_hid_act = torch.tanh(qualvec_hid)\n",
        "\n",
        "\n",
        "        score = self.regressor_output(qualvec_hid_act)\n",
        "        log('score', score.shape)\n",
        "        \n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_kaWmXADs3H",
        "colab_type": "text"
      },
      "source": [
        "#### Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TRmOuCaDzGC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "\n",
        "base_hyperparameters = {'opt': torch.optim.Adam,\n",
        "                        'num_epochs': 15,\n",
        "                        'loss_fn': RMSELoss}\n",
        "\n",
        "LR = 1e-3, 1e-4\n",
        "BATCH_SIZES = 12, 8\n",
        "\n",
        "performance = [['Model', 'Loss'] + [name for name in non_loss_metrics]]\n",
        "for lr in LR:\n",
        "    for batch_size in BATCH_SIZES:\n",
        "        model_params = dict(en_vocab_size=len(EN),\n",
        "                            zh_vocab_size=len(ZH),\n",
        "                            emb_dim=100)\n",
        "        \n",
        "        hyperparameters = dict(**base_hyperparameters)\n",
        "        hyperparameters['lr'] = lr\n",
        "        hyperparameters['batch_size'] = batch_size\n",
        "\n",
        "        model_factory = torch_model_factory(AutoencoderQEV, model_params,\n",
        "                                            **hyperparameters,\n",
        "                                            detailed_log=True)\n",
        "\n",
        "        loss, metrics = torch_kfold_cross_validate(model_factory,\n",
        "                                    inputs=[train_en_idxs, train_zh_idxs],\n",
        "                                    outputs=train_scores,\n",
        "                                    n_splits=2,\n",
        "                                    **non_loss_metrics)\n",
        "        \n",
        "        performance.append([f'LR={lr}, batch_size={batch_size}', loss.item()] + list(metrics.values()))\n",
        "\n",
        "performance_to_dataframe(performance)\n",
        "dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiB1-o8YILHI",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFe9m5IRIYtI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt_hyperparameters = {'opt': torch.optim.Adam,\n",
        "                       'lr': 1e-3,\n",
        "                       'num_epochs': 15,\n",
        "                       'batch_size': 1,\n",
        "                       'loss_fn': RMSELoss}\n",
        "\n",
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "\n",
        "model_for_validation = torch_model_factory(AutoencoderQEV,\n",
        "                                           dict(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100),\n",
        "                                           **opt_hyperparameters,\n",
        "                                           detailed_log=True)()\n",
        "\n",
        "train_set = build_dataset(X=[train_en_idxs, train_zh_idxs], Y=train_scores)\n",
        "val_set = build_dataset(X=[val_en_idxs, val_zh_idxs], Y=val_scores)\n",
        "\n",
        "model, results = model_for_validation.evaluate(train_set, val_set, **non_loss_metrics)\n",
        "train_losses, val_losses, metrics, predicted, actual = results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UldLQgTOGz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "visualise(train_losses, val_losses, metrics, predicted, actual,\n",
        "          name='Autoencoder with Quality Estimation Vectors',\n",
        "          save_to_gdrive=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSlmNaYv4KUP",
        "colab_type": "text"
      },
      "source": [
        "### 3) BERT with Sentence Score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqvjvqfxf4eC",
        "colab_type": "text"
      },
      "source": [
        "#### Pipeline\n",
        "\n",
        "1. BertTokenizer to prepare inputs for BERT\n",
        "2. BertForSequenceClassification to obtain sentence scores\n",
        "3. Regression model to obtain QE scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-z2M1O14PHS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load tokenisers\n",
        "print(f'Loading EN tokenizer...')\n",
        "en_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "print(f'Loading ZH tokenizer...')\n",
        "zh_tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "\n",
        "# Check tokenizers\n",
        "sample_sent_id = 42\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(en_tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(zh_tokenizer.tokenize(train_zh[sample_sent_id]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mz76eD5-gaQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert sentences to BERT tokens\n",
        "train_en_inputs = sentence_groups_to_bert_tokens(en_tokenizer, train_en, max_length=128)\n",
        "val_en_inputs = sentence_groups_to_bert_tokens(en_tokenizer, val_en, max_length=128)\n",
        "test_en_inputs = sentence_groups_to_bert_tokens(en_tokenizer, test_en, max_length=128)\n",
        "\n",
        "train_zh_inputs = sentence_groups_to_bert_tokens(zh_tokenizer, train_zh, max_length=128)\n",
        "val_zh_inputs = sentence_groups_to_bert_tokens(zh_tokenizer, val_zh, max_length=128)\n",
        "test_zh_inputs = sentence_groups_to_bert_tokens(zh_tokenizer, test_zh, max_length=128)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkUNgpsogwZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get source sentence scores from pre-trained English model\n",
        "en_bert = BertForSequenceClassification.from_pretrained('bert-base-cased', num_labels=1)\n",
        "\n",
        "train_en_embs = get_bert_embeddings(en_bert, train_en_inputs, batch_size=1)\n",
        "val_en_embs = get_bert_embeddings(en_bert, val_en_inputs, batch_size=1)\n",
        "test_en_embs = get_bert_embeddings(en_bert, test_en_inputs, batch_size=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEEiPnR_hqLF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get MT scores from pre-trained Chinese model\n",
        "zh_bert = BertForSequenceClassification.from_pretrained('bert-base-chinese', num_labels=1)\n",
        "\n",
        "train_zh_embs = get_bert_embeddings(zh_bert, train_zh_inputs)\n",
        "val_zh_embs = get_bert_embeddings(zh_bert, val_zh_inputs)\n",
        "test_zh_embs = get_bert_embeddings(zh_bert, test_zh_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqWSSaWdg6m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Concatenate all pairs of English-Chinese sentence scores\n",
        "train_sent_scores = concat_zip(train_en_embs, train_zh_embs).numpy()\n",
        "val_sent_scores = concat_zip(val_en_embs, val_zh_embs).numpy()\n",
        "test_sent_scores = concat_zip(test_en_embs, test_zh_embs).numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_8s9NfihQSE",
        "colab_type": "text"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSoXuIGZkOp1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.svm import SVR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbeejE-ahiKP",
        "colab_type": "text"
      },
      "source": [
        "#### Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D51qLj_-lrdX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_validate, KFold\n",
        "\n",
        "def kfold_cross_validate_sklearn(model, train_inputs, train_scores, scoring,\n",
        "                                 n_splits=10,\n",
        "                                 random_state=0):\n",
        "    if not isinstance(train_scores, np.ndarray):\n",
        "        train_scores = np.array(train_scores)\n",
        "\n",
        "    cv_split = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "\n",
        "    result = cross_validate(model, train_inputs, train_scores,\n",
        "                            cv=cv_split,\n",
        "                            scoring=scoring)\n",
        "    return result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5DZVzSyhoeg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "models_to_test = [('LinearRegression', LinearRegression()),\n",
        "                  ('SVR(kernel=linear)', SVR(kernel='linear')),\n",
        "                  ('SVR(kernel=rbf)', SVR(kernel='rbf')),\n",
        "                  ('SVR(kernel=poly)', SVR(kernel='poly')),]\n",
        "\n",
        "scoring = {'Pearson': pearson_sklearn,\n",
        "           'MAE': make_scorer(mean_absolute_error)}\n",
        "\n",
        "n_splits = 5\n",
        "for name, model in models_to_test:\n",
        "    print(name)\n",
        "    print('=' * len(name))\n",
        "    metrics = kfold_cross_validate_sklearn(model,\n",
        "                                           train_sent_scores,\n",
        "                                           train_scores,\n",
        "                                           scoring,\n",
        "                                           n_splits=n_splits)\n",
        "    \n",
        "    for name, scores in metrics.items():\n",
        "        average = sum(scores) / n_splits\n",
        "        print(f'  {name}\\t: {average:.5f}')\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfKp7dFQHgAZ",
        "colab_type": "text"
      },
      "source": [
        "#### Validation\n",
        "\n",
        "From cross validation, we select `SVR(kernel=linear)` which had the lowest MAE\n",
        "and approximately the highest Pearson score.\n",
        "\n",
        "We use this to fit on the full training set and evaluate on the unseen validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0drkDcRHiOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(f'Fitting on training set of size {len(train_scores)}...', end='')\n",
        "model = SVR(kernel='linear')\n",
        "model.fit(train_sent_scores, train_scores)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "print(f'Predicting on validation set of size {len(val_sent_scores)}...', end='')\n",
        "preds = model.predict(val_sent_scores)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "loss = RMSELoss(preds, val_scores)\n",
        "pearson = pearson_score(preds, val_scores)\n",
        "print(f'MAE Loss:\\t {loss:.5f}')\n",
        "print(f'Pearson:\\t {pearson:.5f}')\n",
        "\n",
        "predicted, actual = preds, np.array(val_scores)\n",
        "plt.scatter(actual, predicted)\n",
        "plt.plot([actual.min(), actual.max()], [actual.min(), actual.max()], 'k--', lw=2)\n",
        "plt.xlabel('Actual')\n",
        "plt.ylabel('Predicted')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtPOZA8HZm4C",
        "colab_type": "text"
      },
      "source": [
        "### 4) BERT with Sentence Pair Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOOBoTDwkhYO",
        "colab_type": "text"
      },
      "source": [
        "#### Pipeline\n",
        "\n",
        "1. BertTokenizer to prepare inputs for BERT\n",
        "2. BertModel to obtain sentence _pair_ embeddings (default dimension = 768)\n",
        "3. FFNN to obtain quality estimation scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8YZG_SRWgie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load tokeniser\n",
        "print(f'Loading tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased',\n",
        "                                          do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "# Check tokeniser\n",
        "sample_sent_id = 42\n",
        "\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_zh[sample_sent_id]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efWPEnekZztw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = tokenizer.batch_encode_plus(list(zip(train_en, train_zh)), pad_to_max_length=True)\n",
        "val_inputs = tokenizer.batch_encode_plus(list(zip(val_en, val_zh)), pad_to_max_length=True)\n",
        "test_inputs = tokenizer.batch_encode_plus(list(zip(test_en, test_zh)), pad_to_max_length=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tvukNyOZ7bQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "bert = BertModel.from_pretrained('bert-base-multilingual-cased')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ0kXOyYfbWd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n>> Training')\n",
        "train_embeddings = get_bert_embeddings_with_mask(bert, train_inputs['input_ids'], train_inputs['attention_mask'])\n",
        "train_embeddings_tensor = torch.cat(train_embeddings)\n",
        "\n",
        "print('\\n>> Validation')\n",
        "val_embeddings = get_bert_embeddings_with_mask(bert, val_inputs['input_ids'], val_inputs['attention_mask'])\n",
        "val_embeddings_tensor = torch.cat(val_embeddings)\n",
        "\n",
        "print('\\n>> Validation')\n",
        "test_embeddings = get_bert_embeddings_with_mask(bert, test_inputs['input_ids'], test_inputs['attention_mask'])\n",
        "test_embeddings_tensor = torch.cat(val_embeddings)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yW1x-vvAkoU_",
        "colab_type": "text"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4Yv_VoekqhR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNNRegression(nn.Module):\n",
        "\n",
        "    def __init__(self, *, hidden_dims, input_dim=768, nonlin=F.relu):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        prev_dim = input_dim\n",
        "        for i, hidden_dim in enumerate(self.hidden_dims):\n",
        "            setattr(self, f'hidden_{i}', nn.Linear(prev_dim, hidden_dim))\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        self.out = nn.Linear(prev_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        act = x\n",
        "        for i, _ in enumerate(self.hidden_dims):\n",
        "            layer = getattr(self, f'hidden_{i}')\n",
        "            act = self.nonlin(layer(act))\n",
        "        return self.out(act)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaMCmcSmklBx",
        "colab_type": "text"
      },
      "source": [
        "#### Model Selection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myk-1YIojLnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#########################\n",
        "# OPTIONS FOR GRID SEARCH\n",
        "#########################\n",
        "LR = 1e-3, 1e-4\n",
        "NONLIN = F.leaky_relu, torch.tanh,\n",
        "LAYERS = [[]] + [[2 ** i] for i in range(1, 5)]\n",
        "\n",
        "# Base configurations\n",
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "base_hyperparameters = {'opt': torch.optim.Adam,\n",
        "                        'num_epochs': 250,\n",
        "                        'batch_size': 64,\n",
        "                        'loss_fn': RMSELoss}\n",
        "\n",
        "n_splits = 5\n",
        "performance = [['Model', 'Loss'] + [name for name in non_loss_metrics]]\n",
        "for lr in LR:\n",
        "    for nonlin in NONLIN:\n",
        "        for hidden_dims in LAYERS:\n",
        "            header = f'LR={lr}, nonlin={nonlin.__name__}, hidden_dims={hidden_dims}'\n",
        "            print(header)\n",
        "            print('=' * len(header))\n",
        "\n",
        "            model_params = dict(hidden_dims=hidden_dims, nonlin=nonlin)\n",
        "            hyperparameters = dict(**base_hyperparameters)\n",
        "            hyperparameters['lr'] = lr\n",
        "\n",
        "            model_factory = torch_model_factory(FFNNRegression,\n",
        "                                                model_params,\n",
        "                                                **hyperparameters,\n",
        "                                                detailed_log=False)\n",
        "            \n",
        "            loss, metrics = torch_kfold_cross_validate(model_factory,\n",
        "                                                       inputs=train_embeddings_tensor,\n",
        "                                                       outputs=train_scores,\n",
        "                                                       n_splits=n_splits,\n",
        "                                                       **non_loss_metrics)\n",
        "            \n",
        "            performance.append([header, loss.item()] + list(metrics.values()))\n",
        "            print(performance[-1])\n",
        "            print()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Ltr276ZdmUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evaluate performance\n",
        "dataframe = performance_to_dataframe(performance)\n",
        "dataframe.to_csv(in_gdrive('bert_with_sentence_embeddings_kfold_epoch-250_batch-64.csv'))\n",
        "dataframe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC2sjQKGKghC",
        "colab_type": "text"
      },
      "source": [
        "#### Validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vF2LEBAekxvg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pick the optimal model hyperparameters to train.\n",
        "model_params = dict(hidden_dims=[128, 16], input_dim=768,\n",
        "                    nonlin=torch.tanh)\n",
        "\n",
        "hyperparameters = {'opt': torch.optim.Adam,\n",
        "                   'num_epochs': 25,\n",
        "                   'batch_size': 64,\n",
        "                   'lr': 1e-4,\n",
        "                   'loss_fn': RMSELoss}\n",
        "\n",
        "model_for_validation = torch_model_factory(FFNNRegression,\n",
        "                                           model_params,\n",
        "                                           **hyperparameters,\n",
        "                                           detailed_log=False)()\n",
        "\n",
        "train_set = build_dataset(X=[train_embeddings_tensor], Y=train_scores)\n",
        "val_set = build_dataset(X=[val_embeddings_tensor], Y=val_scores)\n",
        "\n",
        "non_loss_metrics = {'pearson': pearson_score}\n",
        "\n",
        "print('>> TRAINING START')\n",
        "model, results = model_for_validation.evaluate(train_set, val_set, **non_loss_metrics)\n",
        "print('>> TRAINING FINISH')\n",
        "\n",
        "train_losses, val_losses, metrics, predicted, actual = results\n",
        "visualise(train_losses, val_losses, metrics, predicted, actual,\n",
        "          name='BERT sentence pair embeddings 250 epoch 64 batch',\n",
        "          save_to_gdrive=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-vlnz1Pv9TJ",
        "colab_type": "text"
      },
      "source": [
        "#### Prepare CodaLab Submission\n",
        "\n",
        "We fit a model to the training _and_ validation set\n",
        "and obtain QE score predictions for the test set corpus."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPWiCRrldGYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train model on train/validation set\n",
        "train_val_tensor = torch.cat((train_embeddings_tensor, val_embeddings_tensor))\n",
        "train_val_scores = torch.cat((torch.FloatTensor(train_scores), torch.FloatTensor(val_scores))).squeeze()\n",
        "\n",
        "train_and_val_set = build_dataset(X=[train_val_tensor], Y=train_val_scores)\n",
        "\n",
        "model_params = dict(hidden_dims=[16], input_dim=768,\n",
        "                    nonlin=torch.tanh)\n",
        "\n",
        "hyperparameters = {'opt': torch.optim.Adam,\n",
        "                   'num_epochs': 250,\n",
        "                   'batch_size': 64,\n",
        "                   'lr': 1e-4,\n",
        "                   'loss_fn': RMSELoss}\n",
        "\n",
        "model_for_test = torch_model_factory(FFNNRegression,\n",
        "                                     model_params,\n",
        "                                     **hyperparameters,\n",
        "                                     detailed_log=False)()\n",
        "\n",
        "print('>> TRAINING START')\n",
        "model_for_test.fit(train_and_val_set)\n",
        "print('>> TRAINING FINISH')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5IHrtn3mgmm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predictions on test set\n",
        "test_set = build_test_dataset(X=[test_embeddings_tensor])\n",
        "test_loader = DataLoader(test_set, batch_size=1)\n",
        "\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "preds = []\n",
        "with torch.no_grad():\n",
        "    for X in tqdm(test_loader, 'Getting test set predictions'):\n",
        "        pred = model(*(x.to(device) for x in X)).squeeze().cpu()\n",
        "        preds.append(pred)\n",
        "    preds = torch.stack(preds)\n",
        "\n",
        "# Save ZIP file\n",
        "save_predictions(preds, zip_name='BERT_sentence_pair_embeddings_final')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}