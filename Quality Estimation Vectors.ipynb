{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QEV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPSUNoEDCWouj6kcCN2FBp+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c495c7233a68464caa6e7a04fe528b16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c04f1d802804eaeb0382a7a4b1b5354",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e348d3dae3d447b1a44a58a6442ed805",
              "IPY_MODEL_019eed23f0f04766b09e455b9b6e6254"
            ]
          }
        },
        "8c04f1d802804eaeb0382a7a4b1b5354": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e348d3dae3d447b1a44a58a6442ed805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2e267e15f8ae42a1a6c568b22bc7f8a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "",
            "max": 875,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 650,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cfe18ae9d72148a69ad3adabfd6558ce"
          }
        },
        "019eed23f0f04766b09e455b9b6e6254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fed8eec1d925446ba936a11ed30cf9cd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 74% 649/875 [12:06&lt;04:13,  1.12s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d22c1f8d7daa4839ac2579c4aa444210"
          }
        },
        "2e267e15f8ae42a1a6c568b22bc7f8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cfe18ae9d72148a69ad3adabfd6558ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fed8eec1d925446ba936a11ed30cf9cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d22c1f8d7daa4839ac2579c4aa444210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonmiu0214/C490CW/blob/master/Quality%20Estimation%20Vectors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEKvQGwiJhlX",
        "colab_type": "text"
      },
      "source": [
        "# Approach: Quality Estimation Vectors\n",
        "\n",
        "1. Preprocessing\n",
        "2. Embedding layers\n",
        "3. Attention-based decoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmnOOp0xVK1w",
        "colab_type": "text"
      },
      "source": [
        "## Configure COLAB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1S78pQsVQAP",
        "colab_type": "code",
        "outputId": "50af1a65-54b4-4ca0-86de-e8b77c034758",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import sklearn\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'DEVICE={device}')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=device))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE=cuda\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJboJFEhSvRi",
        "colab_type": "text"
      },
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui1DP9-HSwoP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n",
        "\n",
        "TRAIN_EN = 'train.enzh.src'\n",
        "TRAIN_ZH = 'train.enzh.mt'\n",
        "TRAIN_SCORES = 'train.enzh.scores'\n",
        "VAL_EN = 'dev.enzh.src'\n",
        "VAL_ZH = 'dev.enzh.mt'\n",
        "VAL_SCORES = 'dev.enzh.scores'\n",
        "TEST_EN = 'test.enzh.src'\n",
        "TEST_ZH = 'test.enzh.mt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g94IEZNS4QT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read from file\n",
        "\n",
        "with open(TRAIN_EN) as f:\n",
        "    train_en = f.readlines()\n",
        "with open(TRAIN_ZH) as f:\n",
        "    train_zh = f.readlines()\n",
        "with open(TRAIN_SCORES) as f:\n",
        "    train_scores = [float(score.strip()) for score in f]\n",
        "with open(VAL_EN) as f:\n",
        "    val_en = f.readlines()\n",
        "with open(VAL_ZH) as f:\n",
        "    val_zh = f.readlines()\n",
        "with open(VAL_SCORES) as f:\n",
        "    val_scores = [float(score.strip()) for score in f]\n",
        "with open(TEST_EN) as f:\n",
        "    test_en = f.readlines()\n",
        "with open(TEST_ZH) as f:\n",
        "    test_zh = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lihitPqzS55H",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArzsaTkwWMnH",
        "colab_type": "text"
      },
      "source": [
        "### English\n",
        "\n",
        "1. Tokenise with spaCy\n",
        "2. Remove stopwords and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zhdlnjdW-OZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "c7b35577-15e6-4233-ef8d-fade62263ebd"
      },
      "source": [
        "# Downloading spacy models for English\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300 --force\n",
        "\n",
        "# Downloading stop words for English\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download('stopwords')\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rubzgVOsXJXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp_en = spacy.load('en300')\n",
        "\n",
        "def preprocess_en(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        text = sentence.lower()\n",
        "        processed = [token.lemma_ for token in nlp_en.tokenizer(text)]\n",
        "        processed = [token for token in processed if token.isalpha()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_en]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYDXQIQTWNjE",
        "colab_type": "text"
      },
      "source": [
        "### Chinese\n",
        "\n",
        "1. Tokenise with jieba\n",
        "2. Remove stopwords and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IeqokaT4XUvx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download stopwords\n",
        "FILE_STOP_WORDS_ZH = './chinese_stop_words.txt'\n",
        "\n",
        "if not os.path.exists(FILE_STOP_WORDS_ZH):\n",
        "    !wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "with open(FILE_STOP_WORDS_ZH, 'r', encoding='utf-8') as f:\n",
        "    stop_words_zh = [line.rstrip() for line in f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO-iq1CDXfBB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "\n",
        "def preprocess_zh(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        tokens = jieba.cut(sentence, cut_all=True)\n",
        "        processed = [token for token in tokens if token.isalnum()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_zh]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XhWbyoFWLBy",
        "colab_type": "text"
      },
      "source": [
        "### Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af9v7gHpV2Z5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Language(object):\n",
        "\n",
        "    PAD_TOKEN = '<PAD>'\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {0: self.PAD_TOKEN,\n",
        "                         1: self.UNK_TOKEN}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for token in sentence:\n",
        "            self.add_word(token)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            idx = len(self)\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "    \n",
        "    def sent_to_idxs(self, sent):\n",
        "        return [self.word2idx.get(word, 1) for word in sent]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f'Language(name={self.name}) with {len(self)} words'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMtecl68YAOy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_sentences(sents, *, pad_token=0):\n",
        "    # Get max sentence length\n",
        "    sent_lengths = [len(sent) for sent in sents]\n",
        "    max_sent_len = max(sent_lengths)\n",
        "    \n",
        "    # Create empty matrix with padding tokens\n",
        "    padded_sents = np.ones((len(sents), max_sent_len)) * pad_token\n",
        "\n",
        "    # Copy over the sequences\n",
        "    for i, (sent_len, sent) in enumerate(zip(sent_lengths, sents)):\n",
        "        padded_sents[i, 0:sent_len] = sent[:sent_len]\n",
        "    return padded_sents"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUcjoYtdXwBM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "c34cd3cc-809e-4ab8-94d3-4228d2b1d975"
      },
      "source": [
        "##########\n",
        "# ENGLISH\n",
        "##########\n",
        "\n",
        "preprocess_english = preprocess_en(keep_stopwords=False)\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "EN = Language('EN')\n",
        "for sent in train_en_sents:\n",
        "    EN.add_sentence(sent)\n",
        "print(EN)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_en = train_en_sents[42]\n",
        "print(sample_sent_en)\n",
        "print(EN.sent_to_idxs(sample_sent_en))\n",
        "\n",
        "train_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in train_en_sents])\n",
        "val_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in val_en_sents])\n",
        "test_en_idxs = pad_sentences([EN.sent_to_idxs(sent) for sent in test_en_sents])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language(name=EN) with 19141 words\n",
            "\n",
            "Sample sentence\n",
            "['artilleryman', 'record', 'wound', 'die']\n",
            "[292, 293, 294, 295]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmNdfs4AaJqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "5d1aa7a0-8cbf-41a4-da61-ee9c61ff89ee"
      },
      "source": [
        "##########\n",
        "# CHINESE\n",
        "##########\n",
        "\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=False)\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "ZH = Language('ZH')\n",
        "for sent in train_zh_sents:\n",
        "    ZH.add_sentence(sent)\n",
        "print(ZH)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_zh = train_zh_sents[42]\n",
        "print(sample_sent_zh)\n",
        "print(ZH.sent_to_idxs(sample_sent_zh))\n",
        "\n",
        "train_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in train_zh_sents])\n",
        "val_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in val_zh_sents])\n",
        "test_zh_idxs = pad_sentences([ZH.sent_to_idxs(sent) for sent in test_zh_sents])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.719 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Language(name=ZH) with 23850 words\n",
            "\n",
            "Sample sentence\n",
            "['据', '记录', '所有', '6', '名', '炮兵', '都', '受伤', '了']\n",
            "[482, 483, 484, 266, 485, 486, 487, 488, 16]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNDK0jDbbSZQ",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrdNck-3bXNc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SentenceIndexDataset(Dataset):\n",
        "\n",
        "    def __init__(self, en_sent_tensors, zh_sent_tensors, score_tensors=None):\n",
        "        self.en = en_sent_tensors\n",
        "        self.zh = zh_sent_tensors\n",
        "        self.scores = score_tensors\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        if self.scores is None:\n",
        "            return self.en[index], self.zh[index]\n",
        "        else:\n",
        "            return (self.en[index], self.zh[index]), self.scores[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.en)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXsRJkFqcf2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_dataset(en_idxs, zh_idxs, scores=None):\n",
        "    en_tensors = [torch.LongTensor(sent_idx) for sent_idx in en_idxs]\n",
        "    zh_tensors = [torch.LongTensor(sent_idx) for sent_idx in zh_idxs]\n",
        "    return SentenceIndexDataset(en_tensors, zh_tensors, scores)\n",
        "\n",
        "train_set = build_dataset(train_en_idxs, train_zh_idxs, train_scores)\n",
        "val_set = build_dataset(val_en_idxs, val_zh_idxs, val_scores)\n",
        "test_set = build_dataset(test_en_idxs, test_zh_idxs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rfFCv-hVlGh",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiWNlbnpbbe8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target, *, is_numpy=False):\n",
        "    mean = np.mean if is_numpy else torch.mean\n",
        "    sqrt = np.sqrt if is_numpy else torch.sqrt\n",
        "    return sqrt(mean((pred - target) ** 2))\n",
        "\n",
        "def forward_pass(dataset, model, opt, loss_fn, *, is_validation=False):\n",
        "    loss = 0\n",
        "    pred_scores = []\n",
        "    actual_scores = []\n",
        "\n",
        "    def debug_print(*args, **kwargs):\n",
        "        ...\n",
        "    for ((en_tensor, zh_tensor), score) in tqdm(dataset):\n",
        "        actual_scores.append(score)\n",
        "\n",
        "        if is_validation:\n",
        "            with torch.no_grad():\n",
        "                pred_score = model(en_tensor.to(device), zh_tensor.to(device), print=debug_print).squeeze()\n",
        "                loss += loss_fn(score, pred_score.cpu())\n",
        "        else:\n",
        "            pred_score = model(en_tensor.to(device), zh_tensor.to(device), print=debug_print).squeeze()\n",
        "\n",
        "        loss += loss_fn(score, pred_score.cpu())\n",
        "        pred_scores.append(pred_score.cpu().detach().numpy())\n",
        "    \n",
        "    pred_scores = np.concatenate(pred_scores)\n",
        "    actual_scores = torch.cat(actual_scores)\n",
        "\n",
        "    pearson, _ = pearsonr(pred_scores, actual_scores)\n",
        "    return loss, pearson\n",
        "\n",
        "def train(model, opt, loss_fn, train_set, val_set, *, num_epochs=10, batch_size=8):\n",
        "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size)\n",
        "    val_loader = DataLoader(dataset=val_set, batch_size=batch_size)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for eidx in range(num_epochs):\n",
        "        print(f'Epoch {eidx + 1}')\n",
        "        print('=' * 10)\n",
        "\n",
        "        opt.zero_grad()\n",
        "\n",
        "        train_loss, train_pearson = forward_pass(train_loader, model, opt, loss_fn)\n",
        "        print(f'  Training loss:{train_loss:.5f}')\n",
        "        print(f'  Training Pearson:{train_pearson:.5f}')\n",
        "\n",
        "        val_loss, val_pearson = forward_pass(val_loader, model, opt, loss_fn,\n",
        "                                             is_validation=True)\n",
        "        \n",
        "        print(f'  Validation loss:{val_loss:.5f}')\n",
        "        print(f'  Validation Pearson:{val_pearson:.5f}')\n",
        "\n",
        "        # Backpropagation\n",
        "        train_loss.backward()\n",
        "        opt.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2CFHVlgX12W",
        "colab_type": "text"
      },
      "source": [
        "### Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBByVVf5V2hZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        # Source sentence RNN\n",
        "        self.source_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.source_rnn = nn.GRU(\n",
        "            input_size=self.emb_dim,\n",
        "            hidden_size=self.emb_dim,\n",
        "            bidirectional=True)\n",
        "\n",
        "        # Target sentence RNN with attention\n",
        "        self.target_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "        self.target_rnn = nn.GRU(\n",
        "            input_size=self.emb_dim,\n",
        "            hidden_size=self.emb_dim * 2,\n",
        "            bidirectional=False,\n",
        "        )\n",
        "\n",
        "        # Quality score estimator\n",
        "        self.qualvec_rnn = nn.GRU(\n",
        "            input_size=self.emb_dim * 2,\n",
        "            hidden_size=self.emb_dim * 2,\n",
        "            bidirectional=False\n",
        "        )\n",
        "\n",
        "        # Regressor\n",
        "        self.regressor_output = nn.Linear(\n",
        "            in_features=self.emb_dim * 2,\n",
        "            out_features=1\n",
        "        )\n",
        "\n",
        "    def forward(self, en_sent, zh_sent, *, print=print):\n",
        "        en_batch_size, en_sent_len = en_sent.shape\n",
        "        en_emb = self.source_embedding(en_sent)\n",
        "        print('en_emb:', en_emb.shape)\n",
        "\n",
        "        en_emb = en_emb.view(en_sent_len, en_batch_size, -1)\n",
        "        print('en_emb:', en_emb.shape)\n",
        "        en_all_hids, en_last_hid = self.source_rnn(en_emb)\n",
        "\n",
        "        print('en_all_hids:', en_all_hids.shape)\n",
        "        print('en_last_hid:', en_last_hid.shape)\n",
        "\n",
        "        ############################################\n",
        "        def get_context(prev_state):\n",
        "            print('prev_state:', prev_state.shape)\n",
        "            s_s = []\n",
        "            for hid in en_all_hids:\n",
        "                s_s_batches = torch.Tensor([\n",
        "                    one_hid_batch.dot(one_prev_state_batch)\n",
        "                    for one_hid_batch, one_prev_state_batch in zip(prev_state, hid)\n",
        "                ])\n",
        "                s_s.append(s_s_batches)\n",
        "            \n",
        "            s_s = torch.stack(s_s, dim=0)\n",
        "            print('s_s', s_s.shape)\n",
        "\n",
        "            a_s = F.softmax(s_s, dim=0)\n",
        "            print('a_s', a_s.shape)\n",
        "\n",
        "            ctx_vecs = []\n",
        "            for j, (a_i, hid) in enumerate(zip(a_s, en_all_hids)):\n",
        "                vecs = []\n",
        "                for i, (one_a_batch, one_hid_batch) in enumerate(zip(a_i, hid)):\n",
        "                    # print(f'hid state {j} batch {i}', one_a_batch.shape, one_hid_batch.shape)\n",
        "                    vec = one_a_batch * one_hid_batch\n",
        "                    vecs.append(vec)\n",
        "                \n",
        "                vecs = torch.stack(vecs)\n",
        "                # print(f'hid state {j}', vecs.shape)\n",
        "                ctx_vecs.append(vecs)\n",
        "\n",
        "            ctx_vecs = torch.stack(ctx_vecs).sum(dim=0)\n",
        "            print(f'ctx_vecs', ctx_vecs.shape)\n",
        "            return ctx_vecs\n",
        "\n",
        "            s_s = torch.Tensor([hid.squeeze().dot(prev_state)\n",
        "                                for hid in en_all_hids])\n",
        "    \n",
        "            a_s = F.softmax(s_s)\n",
        "    \n",
        "            return torch.stack([a_i * hid.squeeze()\n",
        "                                for a_i, hid in zip(a_s, en_all_hids)]).sum(dim=0)\n",
        "        ############################################\n",
        "\n",
        "        zh_batch_size, zh_sent_len = zh_sent.shape\n",
        "        print('zh_sent_len', zh_sent_len)\n",
        "        zh_emb = self.target_embedding(zh_sent)\n",
        "\n",
        "        print('zh_emb:', zh_emb.shape)\n",
        "        zh_emb = zh_emb.view(zh_sent_len, zh_batch_size, -1)\n",
        "        print('zh_emb:', zh_emb.shape)\n",
        "\n",
        "        qualvecs = []\n",
        "        zh_hid = None\n",
        "        for zh in zh_emb:\n",
        "            print('zh:', zh.shape)\n",
        "            zh = zh.view(1, zh_batch_size, -1)\n",
        "            print('zh:', zh.shape)\n",
        "            if zh_hid is None:\n",
        "                _, zh_hid = self.target_rnn(zh)\n",
        "            else:\n",
        "                _, zh_hid = self.target_rnn(zh, zh_hid)\n",
        "            print('zh_hid:', zh_hid.shape)\n",
        "\n",
        "            print('zh_hid.squeeze():', zh_hid.squeeze().shape)\n",
        "            ctx = get_context(zh_hid.squeeze())\n",
        "            print('ctx:', ctx.shape)\n",
        "            \n",
        "            #TODO: fix the linear combination\n",
        "            qualvecs.append(ctx + zh_hid.squeeze())\n",
        "\n",
        "        qualvecs = torch.stack(qualvecs)\n",
        "        print('qualvecs:', qualvecs.shape)\n",
        "\n",
        "        _, qualvec_hid = self.qualvec_rnn(qualvecs)\n",
        "        print('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        qualvec_hid = qualvec_hid.view(zh_batch_size, -1)\n",
        "        print('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        qualvec_hid_act = torch.tanh(qualvec_hid)\n",
        "        score = self.regressor_output(qualvec_hid_act)\n",
        "        print('score', score.shape)\n",
        "        \n",
        "        return score\n",
        "\n",
        "        # qualvecs = qualvecs.view(zh_sent_len, zh_batch_size, -1)\n",
        "        # print('qualvecs:', qualvecs.shape)\n",
        "\n",
        "        # _, qualvec_hid = self.qualvec_rnn(qualvecs)\n",
        "        # print('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        # qualvec_hid = qualvec_hid.view(1, -1)\n",
        "        # print('qualvec_hid:', qualvec_hid.shape)\n",
        "\n",
        "        # qualvec_hid_act = F.tanh(qualvec_hid)\n",
        "        # score = self.regressor_output(qualvec_hid_act)\n",
        "        # return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTHIz39YRTN",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5D98C5fRf68l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyperparameters\n",
        "\n",
        "LR = 1e-3\n",
        "OPT = torch.optim.Adam\n",
        "LOSS_FN = RMSELoss\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAjirHgaYQx1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set seed for reproducibility\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "model = Model(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100)\n",
        "opt = OPT(model.parameters(), lr=LR)\n",
        "loss_fn = LOSS_FN"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5PSg5yb6JqH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "c495c7233a68464caa6e7a04fe528b16",
            "8c04f1d802804eaeb0382a7a4b1b5354",
            "e348d3dae3d447b1a44a58a6442ed805",
            "019eed23f0f04766b09e455b9b6e6254",
            "2e267e15f8ae42a1a6c568b22bc7f8a6",
            "cfe18ae9d72148a69ad3adabfd6558ce",
            "fed8eec1d925446ba936a11ed30cf9cd",
            "d22c1f8d7daa4839ac2579c4aa444210"
          ]
        },
        "outputId": "9f870feb-e298-451b-b088-65f68282488d"
      },
      "source": [
        "train(model, opt, loss_fn, train_set, val_set, num_epochs=5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "==========\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c495c7233a68464caa6e7a04fe528b16",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=875), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SArp03CVons",
        "colab_type": "text"
      },
      "source": [
        "# Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0tBzjD6zEw",
        "colab_type": "code",
        "outputId": "0a9cc093-3e14-4af0-e2c1-a60694ea3eee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "# Google Drive authorisation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ls /content/gdrive/My\\ Drive\n",
        "\n",
        "def in_gdrive(path):\n",
        "    return os.path.join('/content/gdrive/My Drive/Colab Notebooks', path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-8431debcaf18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls /content/gdrive/My\\\\ Drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSN72uyXX8zr",
        "colab_type": "code",
        "outputId": "6b730db4-daa5-4941-fe59-a00a0f9bd812",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        }
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "import tqdm\n",
        "\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed(0)\n",
        "np.random.seed(0)\n",
        "\n",
        "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertForSequenceClassification, BertModel\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'DEVICE={device}')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE=cuda\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JV59lAFJ2Tv",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rjr6T2qJlxm",
        "colab_type": "code",
        "outputId": "21861ede-e140-4764-b12b-372d82af966c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        }
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n",
        "\n",
        "TRAIN_EN = 'train.enzh.src'\n",
        "TRAIN_ZH = 'train.enzh.mt'\n",
        "TRAIN_SCORES = 'train.enzh.scores'\n",
        "VAL_EN = 'dev.enzh.src'\n",
        "VAL_ZH = 'dev.enzh.mt'\n",
        "VAL_SCORES = 'dev.enzh.scores'\n",
        "TEST_EN = 'test.enzh.src'\n",
        "TEST_ZH = 'test.enzh.mt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-17 14:41:18--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3c10eb4b06845f897b2ee7b8fbae97da55c7c3e16c04a23a35e9926c8502f6c2&X-Amz-Date=20200217T144119Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200217%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-17 14:41:19--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=3c10eb4b06845f897b2ee7b8fbae97da55c7c3e16c04a23a35e9926c8502f6c2&X-Amz-Date=20200217T144119Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200217%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K  1.02MB/s    in 0.8s    \n",
            "\n",
            "2020-02-17 14:41:21 (1.02 MB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBmQxeIQOPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read from file\n",
        "\n",
        "with open(TRAIN_EN) as f:\n",
        "    train_en = f.readlines()\n",
        "with open(TRAIN_ZH) as f:\n",
        "    train_zh = f.readlines()\n",
        "with open(TRAIN_SCORES) as f:\n",
        "    train_scores = [float(score.strip()) for score in f]\n",
        "with open(VAL_EN) as f:\n",
        "    val_en = f.readlines()\n",
        "with open(VAL_ZH) as f:\n",
        "    val_zh = f.readlines()\n",
        "with open(VAL_SCORES) as f:\n",
        "    val_scores = [float(score.strip()) for score in f]\n",
        "with open(TEST_EN) as f:\n",
        "    test_en = f.readlines()\n",
        "with open(TEST_ZH) as f:\n",
        "    test_zh = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkP11o2TStyB",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mJWNZ4dWvFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_pairs_to_bert_input(tokenizer, *sents, max_seq_length=256):\n",
        "    assert len(sents) > 0, 'No sentences to tokenise!'\n",
        "\n",
        "    bert_inputs = []\n",
        "    num_bert_markers = 3\n",
        "\n",
        "    for sent_group in zip(*sents):\n",
        "        sent_tokens = [tokenizer.tokenize(sent) for sent in sent_group]\n",
        "\n",
        "        total_length = sum([len(sent) for sent in sent_tokens]) + num_bert_markers\n",
        "        if total_length > max_seq_length:\n",
        "            raise Exception(f'Too long ({total_length})')\n",
        "\n",
        "        tokens = ['[CLS]']\n",
        "        for sent in sent_tokens:\n",
        "            tokens += sent\n",
        "            tokens.append('[SEP]')\n",
        "\n",
        "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(ids))\n",
        "\n",
        "        ids_tensor = torch.LongTensor(ids + padding)\n",
        "\n",
        "        bert_inputs.append(ids_tensor)\n",
        "\n",
        "    return torch.stack(bert_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWOFNe1MNrwU",
        "colab_type": "text"
      },
      "source": [
        "## BERT Baseline: Sentence Scalar Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4r7GVGRNwnc",
        "colab_type": "code",
        "outputId": "28a3dd10-4d83-4598-e310-a0ddec29ef17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        }
      },
      "source": [
        "BERT_EN_MODEL = 'bert-base-cased'\n",
        "BERT_ZH_MODEL = 'bert-base-chinese'\n",
        "\n",
        "# Load tokenizer\n",
        "print(f'Loading tokenizer <{BERT_EN_MODEL}>...', end=' ')\n",
        "en_tokenizer = BertTokenizer.from_pretrained(BERT_EN_MODEL,\n",
        "                                             do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "# Check tokenizer\n",
        "sample_sent_id = 42\n",
        "\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(en_tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "# Load tokenizer\n",
        "print(f'Loading tokenizer <{BERT_ZH_MODEL}>...', end=' ')\n",
        "zh_tokenizer = BertTokenizer.from_pretrained(BERT_ZH_MODEL)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(zh_tokenizer.tokenize(train_zh[sample_sent_id]))\n",
        "print()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading tokenizer <bert-base-cased>... done!\n",
            "\n",
            "English\n",
            "All 6 of the artillerymen recorded as wounded died).\n",
            "\n",
            "['All', '6', 'of', 'the', 'artillery', '##men', 'recorded', 'as', 'wounded', 'died', ')', '.']\n",
            "\n",
            "Loading tokenizer <bert-base-chinese>... done!\n",
            "\n",
            "Chinese\n",
            "据记录 ， 所有 6 名炮兵都受伤了) 。\n",
            "\n",
            "['据', '记', '录', '，', '所', '有', '6', '名', '炮', '兵', '都', '受', '伤', '了', ')', '。']\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JC_G6unPBrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_bert_embeddings(bert, input_ids, *, batch_size=25):\n",
        "\n",
        "    num_batches = math.ceil(len(input_ids) / batch_size)\n",
        "\n",
        "    embs = []\n",
        "\n",
        "    for batch_id in range(num_batches):\n",
        "        print(f'Batch {batch_id + 1}/{num_batches}...', end='')\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        input_id_batch = input_ids[start_id:end_id]\n",
        "\n",
        "        emb = bert(input_id_batch.to(device))\n",
        "        embs.append(emb.detach().cpu())\n",
        "        print('done!')\n",
        "\n",
        "    return embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gBovKTTPMr2",
        "colab_type": "code",
        "outputId": "89da484f-2bf1-4298-cce7-e925cb8dad78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        }
      },
      "source": [
        "train_en_inputs = sentence_pairs_to_bert_input(en_tokenizer, train_en, max_seq_length=128)\n",
        "val_en_inputs = sentence_pairs_to_bert_input(en_tokenizer, val_en, max_seq_length=128)\n",
        "test_en_inputs = sentence_pairs_to_bert_input(en_tokenizer, test_en, max_seq_length=128)\n",
        "\n",
        "train_zh_inputs = sentence_pairs_to_bert_input(zh_tokenizer, train_zh, max_seq_length=128)\n",
        "val_zh_inputs = sentence_pairs_to_bert_input(zh_tokenizer, val_zh, max_seq_length=128)\n",
        "test_zh_inputs = sentence_pairs_to_bert_input(zh_tokenizer, test_zh, max_seq_length=128)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-7c24d5616837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_en_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_pairs_to_bert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mval_en_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_pairs_to_bert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_en_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_pairs_to_bert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_en\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_zh_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentence_pairs_to_bert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_zh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'en_tokenizer' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0aYVgoaP6Ro",
        "colab_type": "code",
        "outputId": "bd5385a3-f33b-4f31-956f-0895076df172",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "en_bert = BertForSequenceClassification.from_pretrained(BERT_EN_MODEL, num_labels=1)\n",
        "en_bert.to(device)\n",
        "\n",
        "train_en_embs = get_bert_embeddings(en_bert, train_en_inputs)\n",
        "val_en_embs = get_bert_embeddings(en_bert, val_en_inputs)\n",
        "test_en_embs = get_bert_embeddings(en_bert, test_en_inputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1/280...done!\n",
            "Batch 2/280...done!\n",
            "Batch 3/280...done!\n",
            "Batch 4/280...done!\n",
            "Batch 5/280...done!\n",
            "Batch 6/280...done!\n",
            "Batch 7/280...done!\n",
            "Batch 8/280...done!\n",
            "Batch 9/280...done!\n",
            "Batch 10/280...done!\n",
            "Batch 11/280...done!\n",
            "Batch 12/280...done!\n",
            "Batch 13/280...done!\n",
            "Batch 14/280...done!\n",
            "Batch 15/280...done!\n",
            "Batch 16/280...done!\n",
            "Batch 17/280...done!\n",
            "Batch 18/280...done!\n",
            "Batch 19/280...done!\n",
            "Batch 20/280...done!\n",
            "Batch 21/280...done!\n",
            "Batch 22/280...done!\n",
            "Batch 23/280...done!\n",
            "Batch 24/280...done!\n",
            "Batch 25/280...done!\n",
            "Batch 26/280...done!\n",
            "Batch 27/280...done!\n",
            "Batch 28/280...done!\n",
            "Batch 29/280...done!\n",
            "Batch 30/280...done!\n",
            "Batch 31/280...done!\n",
            "Batch 32/280...done!\n",
            "Batch 33/280...done!\n",
            "Batch 34/280...done!\n",
            "Batch 35/280...done!\n",
            "Batch 36/280...done!\n",
            "Batch 37/280...done!\n",
            "Batch 38/280...done!\n",
            "Batch 39/280...done!\n",
            "Batch 40/280...done!\n",
            "Batch 41/280...done!\n",
            "Batch 42/280...done!\n",
            "Batch 43/280...done!\n",
            "Batch 44/280...done!\n",
            "Batch 45/280...done!\n",
            "Batch 46/280...done!\n",
            "Batch 47/280...done!\n",
            "Batch 48/280...done!\n",
            "Batch 49/280...done!\n",
            "Batch 50/280...done!\n",
            "Batch 51/280...done!\n",
            "Batch 52/280...done!\n",
            "Batch 53/280...done!\n",
            "Batch 54/280...done!\n",
            "Batch 55/280...done!\n",
            "Batch 56/280...done!\n",
            "Batch 57/280...done!\n",
            "Batch 58/280...done!\n",
            "Batch 59/280...done!\n",
            "Batch 60/280...done!\n",
            "Batch 61/280...done!\n",
            "Batch 62/280...done!\n",
            "Batch 63/280...done!\n",
            "Batch 64/280...done!\n",
            "Batch 65/280...done!\n",
            "Batch 66/280...done!\n",
            "Batch 67/280...done!\n",
            "Batch 68/280...done!\n",
            "Batch 69/280...done!\n",
            "Batch 70/280...done!\n",
            "Batch 71/280...done!\n",
            "Batch 72/280...done!\n",
            "Batch 73/280...done!\n",
            "Batch 74/280...done!\n",
            "Batch 75/280...done!\n",
            "Batch 76/280...done!\n",
            "Batch 77/280...done!\n",
            "Batch 78/280...done!\n",
            "Batch 79/280...done!\n",
            "Batch 80/280...done!\n",
            "Batch 81/280...done!\n",
            "Batch 82/280...done!\n",
            "Batch 83/280...done!\n",
            "Batch 84/280...done!\n",
            "Batch 85/280...done!\n",
            "Batch 86/280...done!\n",
            "Batch 87/280...done!\n",
            "Batch 88/280...done!\n",
            "Batch 89/280...done!\n",
            "Batch 90/280...done!\n",
            "Batch 91/280...done!\n",
            "Batch 92/280...done!\n",
            "Batch 93/280...done!\n",
            "Batch 94/280...done!\n",
            "Batch 95/280...done!\n",
            "Batch 96/280...done!\n",
            "Batch 97/280...done!\n",
            "Batch 98/280...done!\n",
            "Batch 99/280...done!\n",
            "Batch 100/280...done!\n",
            "Batch 101/280...done!\n",
            "Batch 102/280...done!\n",
            "Batch 103/280...done!\n",
            "Batch 104/280...done!\n",
            "Batch 105/280...done!\n",
            "Batch 106/280...done!\n",
            "Batch 107/280...done!\n",
            "Batch 108/280...done!\n",
            "Batch 109/280...done!\n",
            "Batch 110/280...done!\n",
            "Batch 111/280...done!\n",
            "Batch 112/280...done!\n",
            "Batch 113/280...done!\n",
            "Batch 114/280...done!\n",
            "Batch 115/280...done!\n",
            "Batch 116/280...done!\n",
            "Batch 117/280...done!\n",
            "Batch 118/280...done!\n",
            "Batch 119/280...done!\n",
            "Batch 120/280...done!\n",
            "Batch 121/280...done!\n",
            "Batch 122/280...done!\n",
            "Batch 123/280...done!\n",
            "Batch 124/280...done!\n",
            "Batch 125/280...done!\n",
            "Batch 126/280...done!\n",
            "Batch 127/280...done!\n",
            "Batch 128/280...done!\n",
            "Batch 129/280...done!\n",
            "Batch 130/280...done!\n",
            "Batch 131/280...done!\n",
            "Batch 132/280...done!\n",
            "Batch 133/280...done!\n",
            "Batch 134/280...done!\n",
            "Batch 135/280...done!\n",
            "Batch 136/280...done!\n",
            "Batch 137/280...done!\n",
            "Batch 138/280...done!\n",
            "Batch 139/280...done!\n",
            "Batch 140/280...done!\n",
            "Batch 141/280...done!\n",
            "Batch 142/280...done!\n",
            "Batch 143/280...done!\n",
            "Batch 144/280...done!\n",
            "Batch 145/280...done!\n",
            "Batch 146/280...done!\n",
            "Batch 147/280...done!\n",
            "Batch 148/280...done!\n",
            "Batch 149/280...done!\n",
            "Batch 150/280...done!\n",
            "Batch 151/280...done!\n",
            "Batch 152/280...done!\n",
            "Batch 153/280...done!\n",
            "Batch 154/280...done!\n",
            "Batch 155/280...done!\n",
            "Batch 156/280...done!\n",
            "Batch 157/280...done!\n",
            "Batch 158/280...done!\n",
            "Batch 159/280...done!\n",
            "Batch 160/280...done!\n",
            "Batch 161/280...done!\n",
            "Batch 162/280...done!\n",
            "Batch 163/280...done!\n",
            "Batch 164/280...done!\n",
            "Batch 165/280...done!\n",
            "Batch 166/280...done!\n",
            "Batch 167/280...done!\n",
            "Batch 168/280...done!\n",
            "Batch 169/280...done!\n",
            "Batch 170/280...done!\n",
            "Batch 171/280...done!\n",
            "Batch 172/280...done!\n",
            "Batch 173/280...done!\n",
            "Batch 174/280...done!\n",
            "Batch 175/280...done!\n",
            "Batch 176/280...done!\n",
            "Batch 177/280...done!\n",
            "Batch 178/280...done!\n",
            "Batch 179/280...done!\n",
            "Batch 180/280...done!\n",
            "Batch 181/280...done!\n",
            "Batch 182/280...done!\n",
            "Batch 183/280...done!\n",
            "Batch 184/280...done!\n",
            "Batch 185/280...done!\n",
            "Batch 186/280...done!\n",
            "Batch 187/280...done!\n",
            "Batch 188/280...done!\n",
            "Batch 189/280...done!\n",
            "Batch 190/280...done!\n",
            "Batch 191/280...done!\n",
            "Batch 192/280...done!\n",
            "Batch 193/280...done!\n",
            "Batch 194/280...done!\n",
            "Batch 195/280...done!\n",
            "Batch 196/280...done!\n",
            "Batch 197/280...done!\n",
            "Batch 198/280...done!\n",
            "Batch 199/280...done!\n",
            "Batch 200/280...done!\n",
            "Batch 201/280...done!\n",
            "Batch 202/280...done!\n",
            "Batch 203/280...done!\n",
            "Batch 204/280...done!\n",
            "Batch 205/280...done!\n",
            "Batch 206/280...done!\n",
            "Batch 207/280...done!\n",
            "Batch 208/280...done!\n",
            "Batch 209/280...done!\n",
            "Batch 210/280...done!\n",
            "Batch 211/280...done!\n",
            "Batch 212/280...done!\n",
            "Batch 213/280...done!\n",
            "Batch 214/280...done!\n",
            "Batch 215/280...done!\n",
            "Batch 216/280...done!\n",
            "Batch 217/280...done!\n",
            "Batch 218/280...done!\n",
            "Batch 219/280...done!\n",
            "Batch 220/280...done!\n",
            "Batch 221/280...done!\n",
            "Batch 222/280...done!\n",
            "Batch 223/280...done!\n",
            "Batch 224/280...done!\n",
            "Batch 225/280...done!\n",
            "Batch 226/280...done!\n",
            "Batch 227/280...done!\n",
            "Batch 228/280...done!\n",
            "Batch 229/280...done!\n",
            "Batch 230/280...done!\n",
            "Batch 231/280...done!\n",
            "Batch 232/280...done!\n",
            "Batch 233/280...done!\n",
            "Batch 234/280...done!\n",
            "Batch 235/280...done!\n",
            "Batch 236/280...done!\n",
            "Batch 237/280...done!\n",
            "Batch 238/280...done!\n",
            "Batch 239/280...done!\n",
            "Batch 240/280...done!\n",
            "Batch 241/280...done!\n",
            "Batch 242/280...done!\n",
            "Batch 243/280...done!\n",
            "Batch 244/280...done!\n",
            "Batch 245/280...done!\n",
            "Batch 246/280...done!\n",
            "Batch 247/280...done!\n",
            "Batch 248/280...done!\n",
            "Batch 249/280...done!\n",
            "Batch 250/280...done!\n",
            "Batch 251/280...done!\n",
            "Batch 252/280...done!\n",
            "Batch 253/280...done!\n",
            "Batch 254/280...done!\n",
            "Batch 255/280...done!\n",
            "Batch 256/280...done!\n",
            "Batch 257/280...done!\n",
            "Batch 258/280...done!\n",
            "Batch 259/280...done!\n",
            "Batch 260/280...done!\n",
            "Batch 261/280...done!\n",
            "Batch 262/280...done!\n",
            "Batch 263/280...done!\n",
            "Batch 264/280...done!\n",
            "Batch 265/280...done!\n",
            "Batch 266/280...done!\n",
            "Batch 267/280...done!\n",
            "Batch 268/280...done!\n",
            "Batch 269/280...done!\n",
            "Batch 270/280...done!\n",
            "Batch 271/280...done!\n",
            "Batch 272/280...done!\n",
            "Batch 273/280...done!\n",
            "Batch 274/280...done!\n",
            "Batch 275/280...done!\n",
            "Batch 276/280...done!\n",
            "Batch 277/280...done!\n",
            "Batch 278/280...done!\n",
            "Batch 279/280...done!\n",
            "Batch 280/280...done!\n",
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n",
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQLF1uvwQxOE",
        "colab_type": "code",
        "outputId": "f4e41a2e-757c-488a-b9e2-b8f8d725d7d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "zh_bert = BertForSequenceClassification.from_pretrained(BERT_ZH_MODEL, num_labels=1)\n",
        "zh_bert.to(device)\n",
        "\n",
        "train_zh_embs = get_bert_embeddings(zh_bert, train_zh_inputs)\n",
        "val_zh_embs = get_bert_embeddings(zh_bert, val_zh_inputs)\n",
        "test_zh_embs = get_bert_embeddings(zh_bert, test_zh_inputs)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1/280...done!\n",
            "Batch 2/280...done!\n",
            "Batch 3/280...done!\n",
            "Batch 4/280...done!\n",
            "Batch 5/280...done!\n",
            "Batch 6/280...done!\n",
            "Batch 7/280...done!\n",
            "Batch 8/280...done!\n",
            "Batch 9/280...done!\n",
            "Batch 10/280...done!\n",
            "Batch 11/280...done!\n",
            "Batch 12/280...done!\n",
            "Batch 13/280...done!\n",
            "Batch 14/280...done!\n",
            "Batch 15/280...done!\n",
            "Batch 16/280...done!\n",
            "Batch 17/280...done!\n",
            "Batch 18/280...done!\n",
            "Batch 19/280...done!\n",
            "Batch 20/280...done!\n",
            "Batch 21/280...done!\n",
            "Batch 22/280...done!\n",
            "Batch 23/280...done!\n",
            "Batch 24/280...done!\n",
            "Batch 25/280...done!\n",
            "Batch 26/280...done!\n",
            "Batch 27/280...done!\n",
            "Batch 28/280...done!\n",
            "Batch 29/280...done!\n",
            "Batch 30/280...done!\n",
            "Batch 31/280...done!\n",
            "Batch 32/280...done!\n",
            "Batch 33/280...done!\n",
            "Batch 34/280...done!\n",
            "Batch 35/280...done!\n",
            "Batch 36/280...done!\n",
            "Batch 37/280...done!\n",
            "Batch 38/280...done!\n",
            "Batch 39/280...done!\n",
            "Batch 40/280...done!\n",
            "Batch 41/280...done!\n",
            "Batch 42/280...done!\n",
            "Batch 43/280...done!\n",
            "Batch 44/280...done!\n",
            "Batch 45/280...done!\n",
            "Batch 46/280...done!\n",
            "Batch 47/280...done!\n",
            "Batch 48/280...done!\n",
            "Batch 49/280...done!\n",
            "Batch 50/280...done!\n",
            "Batch 51/280...done!\n",
            "Batch 52/280...done!\n",
            "Batch 53/280...done!\n",
            "Batch 54/280...done!\n",
            "Batch 55/280...done!\n",
            "Batch 56/280...done!\n",
            "Batch 57/280...done!\n",
            "Batch 58/280...done!\n",
            "Batch 59/280...done!\n",
            "Batch 60/280...done!\n",
            "Batch 61/280...done!\n",
            "Batch 62/280...done!\n",
            "Batch 63/280...done!\n",
            "Batch 64/280...done!\n",
            "Batch 65/280...done!\n",
            "Batch 66/280...done!\n",
            "Batch 67/280...done!\n",
            "Batch 68/280...done!\n",
            "Batch 69/280...done!\n",
            "Batch 70/280...done!\n",
            "Batch 71/280...done!\n",
            "Batch 72/280...done!\n",
            "Batch 73/280...done!\n",
            "Batch 74/280...done!\n",
            "Batch 75/280...done!\n",
            "Batch 76/280...done!\n",
            "Batch 77/280...done!\n",
            "Batch 78/280...done!\n",
            "Batch 79/280...done!\n",
            "Batch 80/280...done!\n",
            "Batch 81/280...done!\n",
            "Batch 82/280...done!\n",
            "Batch 83/280...done!\n",
            "Batch 84/280...done!\n",
            "Batch 85/280...done!\n",
            "Batch 86/280...done!\n",
            "Batch 87/280...done!\n",
            "Batch 88/280...done!\n",
            "Batch 89/280...done!\n",
            "Batch 90/280...done!\n",
            "Batch 91/280...done!\n",
            "Batch 92/280...done!\n",
            "Batch 93/280...done!\n",
            "Batch 94/280...done!\n",
            "Batch 95/280...done!\n",
            "Batch 96/280...done!\n",
            "Batch 97/280...done!\n",
            "Batch 98/280...done!\n",
            "Batch 99/280...done!\n",
            "Batch 100/280...done!\n",
            "Batch 101/280...done!\n",
            "Batch 102/280...done!\n",
            "Batch 103/280...done!\n",
            "Batch 104/280...done!\n",
            "Batch 105/280...done!\n",
            "Batch 106/280...done!\n",
            "Batch 107/280...done!\n",
            "Batch 108/280...done!\n",
            "Batch 109/280...done!\n",
            "Batch 110/280...done!\n",
            "Batch 111/280...done!\n",
            "Batch 112/280...done!\n",
            "Batch 113/280...done!\n",
            "Batch 114/280...done!\n",
            "Batch 115/280...done!\n",
            "Batch 116/280...done!\n",
            "Batch 117/280...done!\n",
            "Batch 118/280...done!\n",
            "Batch 119/280...done!\n",
            "Batch 120/280...done!\n",
            "Batch 121/280...done!\n",
            "Batch 122/280...done!\n",
            "Batch 123/280...done!\n",
            "Batch 124/280...done!\n",
            "Batch 125/280...done!\n",
            "Batch 126/280...done!\n",
            "Batch 127/280...done!\n",
            "Batch 128/280...done!\n",
            "Batch 129/280...done!\n",
            "Batch 130/280...done!\n",
            "Batch 131/280...done!\n",
            "Batch 132/280...done!\n",
            "Batch 133/280...done!\n",
            "Batch 134/280...done!\n",
            "Batch 135/280...done!\n",
            "Batch 136/280...done!\n",
            "Batch 137/280...done!\n",
            "Batch 138/280...done!\n",
            "Batch 139/280...done!\n",
            "Batch 140/280...done!\n",
            "Batch 141/280...done!\n",
            "Batch 142/280...done!\n",
            "Batch 143/280...done!\n",
            "Batch 144/280...done!\n",
            "Batch 145/280...done!\n",
            "Batch 146/280...done!\n",
            "Batch 147/280...done!\n",
            "Batch 148/280...done!\n",
            "Batch 149/280...done!\n",
            "Batch 150/280...done!\n",
            "Batch 151/280...done!\n",
            "Batch 152/280...done!\n",
            "Batch 153/280...done!\n",
            "Batch 154/280...done!\n",
            "Batch 155/280...done!\n",
            "Batch 156/280...done!\n",
            "Batch 157/280...done!\n",
            "Batch 158/280...done!\n",
            "Batch 159/280...done!\n",
            "Batch 160/280...done!\n",
            "Batch 161/280...done!\n",
            "Batch 162/280...done!\n",
            "Batch 163/280...done!\n",
            "Batch 164/280...done!\n",
            "Batch 165/280...done!\n",
            "Batch 166/280...done!\n",
            "Batch 167/280...done!\n",
            "Batch 168/280...done!\n",
            "Batch 169/280...done!\n",
            "Batch 170/280...done!\n",
            "Batch 171/280...done!\n",
            "Batch 172/280...done!\n",
            "Batch 173/280...done!\n",
            "Batch 174/280...done!\n",
            "Batch 175/280...done!\n",
            "Batch 176/280...done!\n",
            "Batch 177/280...done!\n",
            "Batch 178/280...done!\n",
            "Batch 179/280...done!\n",
            "Batch 180/280...done!\n",
            "Batch 181/280...done!\n",
            "Batch 182/280...done!\n",
            "Batch 183/280...done!\n",
            "Batch 184/280...done!\n",
            "Batch 185/280...done!\n",
            "Batch 186/280...done!\n",
            "Batch 187/280...done!\n",
            "Batch 188/280...done!\n",
            "Batch 189/280...done!\n",
            "Batch 190/280...done!\n",
            "Batch 191/280...done!\n",
            "Batch 192/280...done!\n",
            "Batch 193/280...done!\n",
            "Batch 194/280...done!\n",
            "Batch 195/280...done!\n",
            "Batch 196/280...done!\n",
            "Batch 197/280...done!\n",
            "Batch 198/280...done!\n",
            "Batch 199/280...done!\n",
            "Batch 200/280...done!\n",
            "Batch 201/280...done!\n",
            "Batch 202/280...done!\n",
            "Batch 203/280...done!\n",
            "Batch 204/280...done!\n",
            "Batch 205/280...done!\n",
            "Batch 206/280...done!\n",
            "Batch 207/280...done!\n",
            "Batch 208/280...done!\n",
            "Batch 209/280...done!\n",
            "Batch 210/280...done!\n",
            "Batch 211/280...done!\n",
            "Batch 212/280...done!\n",
            "Batch 213/280...done!\n",
            "Batch 214/280...done!\n",
            "Batch 215/280...done!\n",
            "Batch 216/280...done!\n",
            "Batch 217/280...done!\n",
            "Batch 218/280...done!\n",
            "Batch 219/280...done!\n",
            "Batch 220/280...done!\n",
            "Batch 221/280...done!\n",
            "Batch 222/280...done!\n",
            "Batch 223/280...done!\n",
            "Batch 224/280...done!\n",
            "Batch 225/280...done!\n",
            "Batch 226/280...done!\n",
            "Batch 227/280...done!\n",
            "Batch 228/280...done!\n",
            "Batch 229/280...done!\n",
            "Batch 230/280...done!\n",
            "Batch 231/280...done!\n",
            "Batch 232/280...done!\n",
            "Batch 233/280...done!\n",
            "Batch 234/280...done!\n",
            "Batch 235/280...done!\n",
            "Batch 236/280...done!\n",
            "Batch 237/280...done!\n",
            "Batch 238/280...done!\n",
            "Batch 239/280...done!\n",
            "Batch 240/280...done!\n",
            "Batch 241/280...done!\n",
            "Batch 242/280...done!\n",
            "Batch 243/280...done!\n",
            "Batch 244/280...done!\n",
            "Batch 245/280...done!\n",
            "Batch 246/280...done!\n",
            "Batch 247/280...done!\n",
            "Batch 248/280...done!\n",
            "Batch 249/280...done!\n",
            "Batch 250/280...done!\n",
            "Batch 251/280...done!\n",
            "Batch 252/280...done!\n",
            "Batch 253/280...done!\n",
            "Batch 254/280...done!\n",
            "Batch 255/280...done!\n",
            "Batch 256/280...done!\n",
            "Batch 257/280...done!\n",
            "Batch 258/280...done!\n",
            "Batch 259/280...done!\n",
            "Batch 260/280...done!\n",
            "Batch 261/280...done!\n",
            "Batch 262/280...done!\n",
            "Batch 263/280...done!\n",
            "Batch 264/280...done!\n",
            "Batch 265/280...done!\n",
            "Batch 266/280...done!\n",
            "Batch 267/280...done!\n",
            "Batch 268/280...done!\n",
            "Batch 269/280...done!\n",
            "Batch 270/280...done!\n",
            "Batch 271/280...done!\n",
            "Batch 272/280...done!\n",
            "Batch 273/280...done!\n",
            "Batch 274/280...done!\n",
            "Batch 275/280...done!\n",
            "Batch 276/280...done!\n",
            "Batch 277/280...done!\n",
            "Batch 278/280...done!\n",
            "Batch 279/280...done!\n",
            "Batch 280/280...done!\n",
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n",
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6MkpZZi9Rke-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def embs_to_scores(en_embs, zh_embs):\n",
        "    en_sent_score = torch.cat(en_embs)\n",
        "    zh_sent_score = torch.cat(zh_embs)\n",
        "    return torch.cat((en_sent_score, zh_sent_score), dim=1)\n",
        "\n",
        "train_sent_scores = embs_to_scores(train_en_embs, train_zh_embs)\n",
        "val_sent_scores = embs_to_scores(val_en_embs, val_zh_embs)\n",
        "test_sent_scores = embs_to_scores(test_en_embs, test_zh_embs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDt_I4VwROlX",
        "colab_type": "code",
        "outputId": "d1227d98-8776-4565-eaba-1507ad96f571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target, *, numpy=False):\n",
        "    mean = np.mean if numpy else torch.mean\n",
        "    sqrt = np.sqrt if numpy else torch.sqrt\n",
        "    return sqrt(mean((pred - target) ** 2))\n",
        "\n",
        "\n",
        "best_val_pearson = None\n",
        "best_val_loss = None\n",
        "\n",
        "for kernel in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
        "    for C in (0.2, 0.4, 0.6, 1, 2, 4, 8):\n",
        "        for epsilon in (0, 0.1, 0.2, 0.4, 0.8):\n",
        "            print(f'Kernel: {kernel}, C: {C}, epsilon: {epsilon}')\n",
        "            print('=' * 20)\n",
        "            clf_t = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
        "            print('Fitting...', end='')\n",
        "            clf_t.fit(train_sent_scores.numpy(), train_scores)\n",
        "            print('done!')\n",
        "\n",
        "            print('[Train] Predicting...', end='')\n",
        "            predictions = clf_t.predict(train_sent_scores.numpy())\n",
        "            print('done!')\n",
        "            pearson, _ = pearsonr(predictions, train_scores)\n",
        "            print(f'[Train] Pearson = {pearson}')\n",
        "            loss = RMSELoss(predictions, train_scores, numpy=True)\n",
        "            print(f'[Train] RMSE = {loss}')\n",
        "\n",
        "            print('[Val] Predicting...', end='')\n",
        "            predictions = clf_t.predict(val_sent_scores.numpy())\n",
        "            print('done!')\n",
        "            val_pearson, _ = pearsonr(predictions, val_scores)\n",
        "            print(f'[Val] Pearson = {val_pearson}')\n",
        "            val_loss = RMSELoss(predictions, val_scores, numpy=True)\n",
        "            print(f'[Val] RMSE = {val_loss}')\n",
        "            print()\n",
        "\n",
        "            if best_val_pearson is None or val_pearson > best_val_pearson[0]:\n",
        "                best_val_pearson = val_pearson, (kernel, C, epsilon)\n",
        "            \n",
        "            if best_val_loss is None or val_loss < best_val_loss[0]:\n",
        "                best_val_loss = val_loss, (kernel, C, epsilon)\n",
        "\n",
        "print(f'Best validation Pearson: {best_val_pearson[0]} with config {best_val_pearson[1]}')\n",
        "print(f'Best validation loss: {best_val_loss[0]} with config {best_val_loss[1]}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kernel: linear, C: 0.2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055167498925831775\n",
            "[Train] RMSE = 0.9696749539159124\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08018197661824367\n",
            "[Val] RMSE = 0.9595970363357043\n",
            "\n",
            "Kernel: linear, C: 0.2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054400293097078126\n",
            "[Train] RMSE = 0.9677984813942634\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.081810952246767\n",
            "[Val] RMSE = 0.9574365191416886\n",
            "\n",
            "Kernel: linear, C: 0.2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054562412810295044\n",
            "[Train] RMSE = 0.9635943762190082\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08170580830448906\n",
            "[Val] RMSE = 0.9527613144467165\n",
            "\n",
            "Kernel: linear, C: 0.2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054376118055705656\n",
            "[Train] RMSE = 0.9477849687481932\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08182338712582463\n",
            "[Val] RMSE = 0.9350789397397483\n",
            "\n",
            "Kernel: linear, C: 0.2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05515489119980513\n",
            "[Train] RMSE = 0.9274130747569688\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08034060940780727\n",
            "[Val] RMSE = 0.9071426626393502\n",
            "\n",
            "Kernel: linear, C: 0.4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05517003246635009\n",
            "[Train] RMSE = 0.9693711278059678\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08013772018944375\n",
            "[Val] RMSE = 0.9592242117169572\n",
            "\n",
            "Kernel: linear, C: 0.4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05446378014440676\n",
            "[Train] RMSE = 0.9677722078863734\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08177455748696667\n",
            "[Val] RMSE = 0.9574128225215316\n",
            "\n",
            "Kernel: linear, C: 0.4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05459069911292564\n",
            "[Train] RMSE = 0.9635721802246335\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08168294394152631\n",
            "[Val] RMSE = 0.9527359779647675\n",
            "\n",
            "Kernel: linear, C: 0.4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05436630474258486\n",
            "[Train] RMSE = 0.9477935263532313\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08182822419155877\n",
            "[Val] RMSE = 0.9350928071016376\n",
            "\n",
            "Kernel: linear, C: 0.4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055168179464556676\n",
            "[Train] RMSE = 0.927412320532055\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0801707648860503\n",
            "[Val] RMSE = 0.9071338207489236\n",
            "\n",
            "Kernel: linear, C: 0.6, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055168803775571734\n",
            "[Train] RMSE = 0.9694655878629859\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0801600740785419\n",
            "[Val] RMSE = 0.9593247432320186\n",
            "\n",
            "Kernel: linear, C: 0.6, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05446133920493455\n",
            "[Train] RMSE = 0.9678540330099642\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08177606258996321\n",
            "[Val] RMSE = 0.9574987477878768\n",
            "\n",
            "Kernel: linear, C: 0.6, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054544229245602406\n",
            "[Train] RMSE = 0.9635056890975925\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08171971927215543\n",
            "[Val] RMSE = 0.9526582747643603\n",
            "\n",
            "Kernel: linear, C: 0.6, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05436415203053874\n",
            "[Train] RMSE = 0.9477784897250808\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08182926937380647\n",
            "[Val] RMSE = 0.9350640647043333\n",
            "\n",
            "Kernel: linear, C: 0.6, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05515809868199142\n",
            "[Train] RMSE = 0.9274032885386461\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08030640495088141\n",
            "[Val] RMSE = 0.9071305896528298\n",
            "\n",
            "Kernel: linear, C: 1, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05516985499027282\n",
            "[Train] RMSE = 0.9694377823727808\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0801410683265538\n",
            "[Val] RMSE = 0.959297069499979\n",
            "\n",
            "Kernel: linear, C: 1, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05446185133727736\n",
            "[Train] RMSE = 0.9678482467273934\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0817757475356314\n",
            "[Val] RMSE = 0.9574924182841399\n",
            "\n",
            "Kernel: linear, C: 1, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054542053641559556\n",
            "[Train] RMSE = 0.9635686438961886\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08172134398784404\n",
            "[Val] RMSE = 0.9527170682151248\n",
            "\n",
            "Kernel: linear, C: 1, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054348785391209145\n",
            "[Train] RMSE = 0.9477811616882256\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08183656661865978\n",
            "[Val] RMSE = 0.9350647012854774\n",
            "\n",
            "Kernel: linear, C: 1, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05515995960635599\n",
            "[Train] RMSE = 0.9274046588034438\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08028506437704541\n",
            "[Val] RMSE = 0.9071268943422243\n",
            "\n",
            "Kernel: linear, C: 2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05515671429301307\n",
            "[Train] RMSE = 0.969407156581931\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08032153612382423\n",
            "[Val] RMSE = 0.959247859874894\n",
            "\n",
            "Kernel: linear, C: 2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05448811237604953\n",
            "[Train] RMSE = 0.9678276341822201\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08175906330070257\n",
            "[Val] RMSE = 0.9574701795687873\n",
            "\n",
            "Kernel: linear, C: 2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05458614152833569\n",
            "[Train] RMSE = 0.96351907485395\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08168673213648472\n",
            "[Val] RMSE = 0.9526737434221777\n",
            "\n",
            "Kernel: linear, C: 2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0543822654903842\n",
            "[Train] RMSE = 0.9476821415394984\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08182029573894004\n",
            "[Val] RMSE = 0.9349552734827676\n",
            "\n",
            "Kernel: linear, C: 2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055152613002418395\n",
            "[Train] RMSE = 0.9274061063960005\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08036324255035887\n",
            "[Val] RMSE = 0.9071264206288959\n",
            "\n",
            "Kernel: linear, C: 4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055169279188768676\n",
            "[Train] RMSE = 0.9694265152426927\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0801516453756411\n",
            "[Val] RMSE = 0.9592830191300351\n",
            "\n",
            "Kernel: linear, C: 4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054525180751153174\n",
            "[Train] RMSE = 0.9678474644470159\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0817336646905626\n",
            "[Val] RMSE = 0.9574936774676769\n",
            "\n",
            "Kernel: linear, C: 4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0545515586803425\n",
            "[Train] RMSE = 0.9635753191698024\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08171418384738428\n",
            "[Val] RMSE = 0.9527372034395849\n",
            "\n",
            "Kernel: linear, C: 4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054379748130389705\n",
            "[Train] RMSE = 0.9477959255791447\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08182156740738103\n",
            "[Val] RMSE = 0.9350906151480758\n",
            "\n",
            "Kernel: linear, C: 4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.055167349740549196\n",
            "[Train] RMSE = 0.9274306337884606\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08018437745509316\n",
            "[Val] RMSE = 0.9071339113527078\n",
            "\n",
            "Kernel: linear, C: 8, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05517005930923265\n",
            "[Train] RMSE = 0.96940839779348\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08013720998845895\n",
            "[Val] RMSE = 0.9592637829858588\n",
            "\n",
            "Kernel: linear, C: 8, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054460183908111706\n",
            "[Train] RMSE = 0.9678256576809143\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08177677188550701\n",
            "[Val] RMSE = 0.9574591431397247\n",
            "\n",
            "Kernel: linear, C: 8, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054539564993990305\n",
            "[Train] RMSE = 0.9635990208772868\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08172319226468404\n",
            "[Val] RMSE = 0.9527521084803159\n",
            "\n",
            "Kernel: linear, C: 8, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.054335078759272244\n",
            "[Train] RMSE = 0.9477817362265281\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08184283791538666\n",
            "[Val] RMSE = 0.935060297002634\n",
            "\n",
            "Kernel: linear, C: 8, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.05516931592109614\n",
            "[Train] RMSE = 0.9274261450694614\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.08015098307230745\n",
            "[Val] RMSE = 0.9071394069328318\n",
            "\n",
            "Kernel: poly, C: 0.2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04259986113892895\n",
            "[Train] RMSE = 0.9704015593616384\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04687361395119204\n",
            "[Val] RMSE = 0.9614351091973565\n",
            "\n",
            "Kernel: poly, C: 0.2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04308712524941965\n",
            "[Train] RMSE = 0.9680819900408322\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.053232843734245965\n",
            "[Val] RMSE = 0.9586212792220579\n",
            "\n",
            "Kernel: poly, C: 0.2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042475880597374935\n",
            "[Train] RMSE = 0.9642278060055809\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05162132677288728\n",
            "[Val] RMSE = 0.9545199425181233\n",
            "\n",
            "Kernel: poly, C: 0.2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04188514990577775\n",
            "[Train] RMSE = 0.9483138232862102\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0523138234553363\n",
            "[Val] RMSE = 0.9365705076874278\n",
            "\n",
            "Kernel: poly, C: 0.2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04185957412726806\n",
            "[Train] RMSE = 0.9279788000485344\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05896269190721169\n",
            "[Val] RMSE = 0.9082908919820764\n",
            "\n",
            "Kernel: poly, C: 0.4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04255817336029773\n",
            "[Train] RMSE = 0.9703942401878362\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04676381759247505\n",
            "[Val] RMSE = 0.9614380338683426\n",
            "\n",
            "Kernel: poly, C: 0.4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04309222681215381\n",
            "[Train] RMSE = 0.9680660857503068\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05329482851443274\n",
            "[Val] RMSE = 0.9586002639687703\n",
            "\n",
            "Kernel: poly, C: 0.4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04246115117136524\n",
            "[Train] RMSE = 0.9642524305797217\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05178197177210831\n",
            "[Val] RMSE = 0.9545398849122223\n",
            "\n",
            "Kernel: poly, C: 0.4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04186054978773917\n",
            "[Train] RMSE = 0.9482953950389003\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05226546682400093\n",
            "[Val] RMSE = 0.9365515038349492\n",
            "\n",
            "Kernel: poly, C: 0.4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0418295550690756\n",
            "[Train] RMSE = 0.9279935084282829\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05889193232361345\n",
            "[Val] RMSE = 0.9083047608215238\n",
            "\n",
            "Kernel: poly, C: 0.6, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04259707064477095\n",
            "[Train] RMSE = 0.9703748112240852\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04694006327683908\n",
            "[Val] RMSE = 0.9614072127453677\n",
            "\n",
            "Kernel: poly, C: 0.6, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04308727600627957\n",
            "[Train] RMSE = 0.9680604038000086\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05326835117828514\n",
            "[Val] RMSE = 0.958595408350347\n",
            "\n",
            "Kernel: poly, C: 0.6, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042400095142721125\n",
            "[Train] RMSE = 0.9642110732630104\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05128059111843478\n",
            "[Val] RMSE = 0.9545180992787226\n",
            "\n",
            "Kernel: poly, C: 0.6, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04181733356456091\n",
            "[Train] RMSE = 0.948274531050735\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052179123699238224\n",
            "[Val] RMSE = 0.9365304710996769\n",
            "\n",
            "Kernel: poly, C: 0.6, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04182770989629686\n",
            "[Train] RMSE = 0.9279897090248765\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.058942405297804736\n",
            "[Val] RMSE = 0.9082994176337809\n",
            "\n",
            "Kernel: poly, C: 1, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042607395933532695\n",
            "[Train] RMSE = 0.9703918450486876\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04691444381909415\n",
            "[Val] RMSE = 0.9614238067837385\n",
            "\n",
            "Kernel: poly, C: 1, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04309820987476968\n",
            "[Train] RMSE = 0.968041498514731\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05317653526299828\n",
            "[Val] RMSE = 0.9585800352780964\n",
            "\n",
            "Kernel: poly, C: 1, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04245310185626994\n",
            "[Train] RMSE = 0.9642555293289575\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05164069884144308\n",
            "[Val] RMSE = 0.9545500854633917\n",
            "\n",
            "Kernel: poly, C: 1, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04181955918879603\n",
            "[Train] RMSE = 0.9482735615429696\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052173445035633224\n",
            "[Val] RMSE = 0.9365296792121142\n",
            "\n",
            "Kernel: poly, C: 1, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04179494468158547\n",
            "[Train] RMSE = 0.9280062697019777\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.058933102060034694\n",
            "[Val] RMSE = 0.9083109975393077\n",
            "\n",
            "Kernel: poly, C: 2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04260683673478627\n",
            "[Train] RMSE = 0.9703542646399937\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04698095184206546\n",
            "[Val] RMSE = 0.9613835595600712\n",
            "\n",
            "Kernel: poly, C: 2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.043075231295330405\n",
            "[Train] RMSE = 0.9680478827476369\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05325810770597151\n",
            "[Val] RMSE = 0.958582665045979\n",
            "\n",
            "Kernel: poly, C: 2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04243243092424286\n",
            "[Train] RMSE = 0.9642708451322594\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05150145674989573\n",
            "[Val] RMSE = 0.9545738242417448\n",
            "\n",
            "Kernel: poly, C: 2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.041893198410499856\n",
            "[Train] RMSE = 0.9483261377530798\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052207776643912164\n",
            "[Val] RMSE = 0.9365881882446432\n",
            "\n",
            "Kernel: poly, C: 2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.041866041834714526\n",
            "[Train] RMSE = 0.9279767992203859\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.058983987517034875\n",
            "[Val] RMSE = 0.9082894382473381\n",
            "\n",
            "Kernel: poly, C: 4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042623077037451364\n",
            "[Train] RMSE = 0.9703786715187251\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.046970350883955375\n",
            "[Val] RMSE = 0.961407466824227\n",
            "\n",
            "Kernel: poly, C: 4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04305164439392337\n",
            "[Train] RMSE = 0.968060944650926\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05253057138591524\n",
            "[Val] RMSE = 0.9586377534278419\n",
            "\n",
            "Kernel: poly, C: 4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042375111634747074\n",
            "[Train] RMSE = 0.9642637563426683\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05140183500084416\n",
            "[Val] RMSE = 0.9545721349949863\n",
            "\n",
            "Kernel: poly, C: 4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04185492719212022\n",
            "[Train] RMSE = 0.9483029037612793\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052238106339500615\n",
            "[Val] RMSE = 0.9365602324859201\n",
            "\n",
            "Kernel: poly, C: 4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.041869440306978346\n",
            "[Train] RMSE = 0.9279729427280506\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05889690568405713\n",
            "[Val] RMSE = 0.9082940029351423\n",
            "\n",
            "Kernel: poly, C: 8, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042662518638472126\n",
            "[Train] RMSE = 0.9703620354963538\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047204136355829526\n",
            "[Val] RMSE = 0.9613821428220826\n",
            "\n",
            "Kernel: poly, C: 8, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04303840888755393\n",
            "[Train] RMSE = 0.9680142513415356\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0525733756376574\n",
            "[Val] RMSE = 0.9585828736257763\n",
            "\n",
            "Kernel: poly, C: 8, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.042357414479570234\n",
            "[Train] RMSE = 0.9643432331000973\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05119462154346981\n",
            "[Val] RMSE = 0.9546693897224551\n",
            "\n",
            "Kernel: poly, C: 8, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.041997330908793006\n",
            "[Train] RMSE = 0.9483887587529808\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052338815792413076\n",
            "[Val] RMSE = 0.9366532966761808\n",
            "\n",
            "Kernel: poly, C: 8, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.04176802830485476\n",
            "[Train] RMSE = 0.927989746922417\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.058879626696691854\n",
            "[Val] RMSE = 0.9083101558466533\n",
            "\n",
            "Kernel: rbf, C: 0.2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.06659493129226088\n",
            "[Train] RMSE = 0.9684447527168843\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04866308711501048\n",
            "[Val] RMSE = 0.9613491873033639\n",
            "\n",
            "Kernel: rbf, C: 0.2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.06959901537444309\n",
            "[Train] RMSE = 0.9666488300139775\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05552096039169736\n",
            "[Val] RMSE = 0.959112978090378\n",
            "\n",
            "Kernel: rbf, C: 0.2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0742353627770098\n",
            "[Train] RMSE = 0.9624684533596796\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.056429580226527165\n",
            "[Val] RMSE = 0.9544486015806136\n",
            "\n",
            "Kernel: rbf, C: 0.2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07193743511957312\n",
            "[Train] RMSE = 0.9466611177173363\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.050891758340203146\n",
            "[Val] RMSE = 0.9362328233350179\n",
            "\n",
            "Kernel: rbf, C: 0.2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.06731253424985124\n",
            "[Train] RMSE = 0.9268335734380292\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05427142373631772\n",
            "[Val] RMSE = 0.9084140195360588\n",
            "\n",
            "Kernel: rbf, C: 0.4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.06918324425538744\n",
            "[Train] RMSE = 0.9680628074035291\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047497966502035215\n",
            "[Val] RMSE = 0.9612381793187567\n",
            "\n",
            "Kernel: rbf, C: 0.4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.072647524042608\n",
            "[Train] RMSE = 0.9664066487714932\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04957767411985635\n",
            "[Val] RMSE = 0.9596824085864815\n",
            "\n",
            "Kernel: rbf, C: 0.4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07811478554241652\n",
            "[Train] RMSE = 0.9621090586761403\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.052847088371171934\n",
            "[Val] RMSE = 0.9545924486262976\n",
            "\n",
            "Kernel: rbf, C: 0.4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07483132400037873\n",
            "[Train] RMSE = 0.9466327972428777\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.044093951060809676\n",
            "[Val] RMSE = 0.9368214446898138\n",
            "\n",
            "Kernel: rbf, C: 0.4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07073960288268417\n",
            "[Train] RMSE = 0.9266099158974053\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04961136347934204\n",
            "[Val] RMSE = 0.9087029142962045\n",
            "\n",
            "Kernel: rbf, C: 0.6, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07194271799574539\n",
            "[Train] RMSE = 0.9680255208529018\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04292556347347773\n",
            "[Val] RMSE = 0.9616345507719047\n",
            "\n",
            "Kernel: rbf, C: 0.6, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07502823136607153\n",
            "[Train] RMSE = 0.9663456544263881\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04827094017546605\n",
            "[Val] RMSE = 0.9599449333926205\n",
            "\n",
            "Kernel: rbf, C: 0.6, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08013192051381929\n",
            "[Train] RMSE = 0.9617694065277348\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05240761287903918\n",
            "[Val] RMSE = 0.9544610224019695\n",
            "\n",
            "Kernel: rbf, C: 0.6, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0777090930501436\n",
            "[Train] RMSE = 0.9464637582920383\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04353080870370198\n",
            "[Val] RMSE = 0.9369150089541348\n",
            "\n",
            "Kernel: rbf, C: 0.6, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07360962420637658\n",
            "[Train] RMSE = 0.9263533766013731\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.05037638282097897\n",
            "[Val] RMSE = 0.908669663030469\n",
            "\n",
            "Kernel: rbf, C: 1, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07408572660887164\n",
            "[Train] RMSE = 0.9684404668199019\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.03799592683242384\n",
            "[Val] RMSE = 0.9626290307046796\n",
            "\n",
            "Kernel: rbf, C: 1, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07788761523037654\n",
            "[Train] RMSE = 0.9660354892926504\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04735541788139689\n",
            "[Val] RMSE = 0.959896292896783\n",
            "\n",
            "Kernel: rbf, C: 1, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08260138408681142\n",
            "[Train] RMSE = 0.9615435930709371\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.051972680649337806\n",
            "[Val] RMSE = 0.9545177410998936\n",
            "\n",
            "Kernel: rbf, C: 1, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08070789655485998\n",
            "[Train] RMSE = 0.9461457899591221\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.044500032963321175\n",
            "[Val] RMSE = 0.9370537458347963\n",
            "\n",
            "Kernel: rbf, C: 1, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07642429559243616\n",
            "[Train] RMSE = 0.9261256124613978\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04989301925274709\n",
            "[Val] RMSE = 0.9087508016754314\n",
            "\n",
            "Kernel: rbf, C: 2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.07818543613406223\n",
            "[Train] RMSE = 0.9674838293477345\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.03425635996331223\n",
            "[Val] RMSE = 0.9621701626239129\n",
            "\n",
            "Kernel: rbf, C: 2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0814582706773818\n",
            "[Train] RMSE = 0.9656171372731553\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04814767164037042\n",
            "[Val] RMSE = 0.9598243900428104\n",
            "\n",
            "Kernel: rbf, C: 2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0860665113180721\n",
            "[Train] RMSE = 0.9610919903518245\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04876613244172172\n",
            "[Val] RMSE = 0.954628047328202\n",
            "\n",
            "Kernel: rbf, C: 2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08451058434997835\n",
            "[Train] RMSE = 0.9456585567952187\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.041488522969908084\n",
            "[Val] RMSE = 0.9371546593419302\n",
            "\n",
            "Kernel: rbf, C: 2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08114529892837831\n",
            "[Train] RMSE = 0.9257650153656523\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04823144622682297\n",
            "[Val] RMSE = 0.9089814812092913\n",
            "\n",
            "Kernel: rbf, C: 4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08051128293580093\n",
            "[Train] RMSE = 0.9674043264703887\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.03747858128879022\n",
            "[Val] RMSE = 0.9624006592458962\n",
            "\n",
            "Kernel: rbf, C: 4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08489975516889632\n",
            "[Train] RMSE = 0.9650927593690736\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04351991490232342\n",
            "[Val] RMSE = 0.9600612261485598\n",
            "\n",
            "Kernel: rbf, C: 4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0905729386950556\n",
            "[Train] RMSE = 0.9606585046102878\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04919860566280708\n",
            "[Val] RMSE = 0.9545337591675729\n",
            "\n",
            "Kernel: rbf, C: 4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0888543398797358\n",
            "[Train] RMSE = 0.9456037622830493\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.03563408184684368\n",
            "[Val] RMSE = 0.9379466271661797\n",
            "\n",
            "Kernel: rbf, C: 4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08619155401346165\n",
            "[Train] RMSE = 0.9253278685987832\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.045886281331701646\n",
            "[Val] RMSE = 0.9092083676529684\n",
            "\n",
            "Kernel: rbf, C: 8, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08252694564903669\n",
            "[Train] RMSE = 0.9672426192152899\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047603202293330905\n",
            "[Val] RMSE = 0.9619569834294742\n",
            "\n",
            "Kernel: rbf, C: 8, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.08717338733284359\n",
            "[Train] RMSE = 0.9648078149103083\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.045571092151149455\n",
            "[Val] RMSE = 0.9599664394942837\n",
            "\n",
            "Kernel: rbf, C: 8, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.09429737189578494\n",
            "[Train] RMSE = 0.9603934812909312\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.044587070284775356\n",
            "[Val] RMSE = 0.955226341419708\n",
            "\n",
            "Kernel: rbf, C: 8, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.09114758551409204\n",
            "[Train] RMSE = 0.9453480519667672\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.03254015129640558\n",
            "[Val] RMSE = 0.9384074751381014\n",
            "\n",
            "Kernel: rbf, C: 8, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.09081434500141533\n",
            "[Train] RMSE = 0.9249391580591583\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04341236690329511\n",
            "[Val] RMSE = 0.909460435031895\n",
            "\n",
            "Kernel: sigmoid, C: 0.2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024693293514708684\n",
            "[Train] RMSE = 61.7368486363861\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04702808799660196\n",
            "[Val] RMSE = 64.1662422039176\n",
            "\n",
            "Kernel: sigmoid, C: 0.2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024681635029498886\n",
            "[Train] RMSE = 61.73637767713885\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04698890252611866\n",
            "[Val] RMSE = 64.16657462124282\n",
            "\n",
            "Kernel: sigmoid, C: 0.2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024699228903746095\n",
            "[Train] RMSE = 61.734411537224254\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04701329173749033\n",
            "[Val] RMSE = 64.15813867344664\n",
            "\n",
            "Kernel: sigmoid, C: 0.2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024696823341577755\n",
            "[Train] RMSE = 61.735384538830736\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04701337300569448\n",
            "[Val] RMSE = 64.15983205611069\n",
            "\n",
            "Kernel: sigmoid, C: 0.2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024693844947182433\n",
            "[Train] RMSE = 61.72699130876904\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04703503538286092\n",
            "[Val] RMSE = 64.14789779349054\n",
            "\n",
            "Kernel: sigmoid, C: 0.4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.02466984615236953\n",
            "[Train] RMSE = 123.45127111304576\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04697168058416341\n",
            "[Val] RMSE = 128.3128576514896\n",
            "\n",
            "Kernel: sigmoid, C: 0.4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024672468236760937\n",
            "[Train] RMSE = 123.4522166061267\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04698053693606023\n",
            "[Val] RMSE = 128.31058893680603\n",
            "\n",
            "Kernel: sigmoid, C: 0.4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024672468236760937\n",
            "[Train] RMSE = 123.45259212567828\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04698053693606023\n",
            "[Val] RMSE = 128.3108013018648\n",
            "\n",
            "Kernel: sigmoid, C: 0.4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.024679720099542272\n",
            "[Train] RMSE = 123.46099020106124\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04697829287508459\n",
            "[Val] RMSE = 128.30435585531188\n",
            "\n",
            "Kernel: sigmoid, C: 0.4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = -0.02468968476478268\n",
            "[Train] RMSE = 123.45267402878571\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = -0.04697995068663796\n",
            "[Val] RMSE = 128.28804910635793\n",
            "\n",
            "Kernel: sigmoid, C: 0.6, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469506492475698\n",
            "[Train] RMSE = 185.17370520248238\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04713677934598228\n",
            "[Val] RMSE = 192.36177125005648\n",
            "\n",
            "Kernel: sigmoid, C: 0.6, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024691859100612765\n",
            "[Train] RMSE = 185.16816493533653\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047102336233344415\n",
            "[Val] RMSE = 192.35981286718774\n",
            "\n",
            "Kernel: sigmoid, C: 0.6, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024691943019946462\n",
            "[Train] RMSE = 185.17610648191584\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04710650086184908\n",
            "[Val] RMSE = 192.3646839121219\n",
            "\n",
            "Kernel: sigmoid, C: 0.6, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024686958970906052\n",
            "[Train] RMSE = 185.1791609143445\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04710099855825252\n",
            "[Val] RMSE = 192.3767552297938\n",
            "\n",
            "Kernel: sigmoid, C: 0.6, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024680449595049687\n",
            "[Train] RMSE = 185.1858709472228\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047089620873116585\n",
            "[Val] RMSE = 192.39719215728573\n",
            "\n",
            "Kernel: sigmoid, C: 1, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024693236341079422\n",
            "[Train] RMSE = 308.59470594865695\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709611712556983\n",
            "[Val] RMSE = 320.6017198288455\n",
            "\n",
            "Kernel: sigmoid, C: 1, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469323761297028\n",
            "[Train] RMSE = 308.60255102763045\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709611294024859\n",
            "[Val] RMSE = 320.60601522904125\n",
            "\n",
            "Kernel: sigmoid, C: 1, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469323761297029\n",
            "[Train] RMSE = 308.616429137388\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709611294024859\n",
            "[Val] RMSE = 320.6139770748514\n",
            "\n",
            "Kernel: sigmoid, C: 1, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024686731731767206\n",
            "[Train] RMSE = 308.6352614354973\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04707330198763039\n",
            "[Val] RMSE = 320.641880746217\n",
            "\n",
            "Kernel: sigmoid, C: 1, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.0246838295317318\n",
            "[Train] RMSE = 308.6482536826698\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047078698471839646\n",
            "[Val] RMSE = 320.6692343495645\n",
            "\n",
            "Kernel: sigmoid, C: 2, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024690666989012768\n",
            "[Train] RMSE = 617.2534132621228\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.047092122034574344\n",
            "[Val] RMSE = 641.2841865481353\n",
            "\n",
            "Kernel: sigmoid, C: 2, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 617.2534132621226\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 641.2841865481352\n",
            "\n",
            "Kernel: sigmoid, C: 2, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 617.2534132621226\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 641.2841865481352\n",
            "\n",
            "Kernel: sigmoid, C: 2, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 617.2534132621226\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 641.2841865481352\n",
            "\n",
            "Kernel: sigmoid, C: 2, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024687355408861304\n",
            "[Train] RMSE = 617.2961976066052\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04708344004535474\n",
            "[Val] RMSE = 641.3283368425699\n",
            "\n",
            "Kernel: sigmoid, C: 4, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 1234.520278618825\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 1282.6033305939704\n",
            "\n",
            "Kernel: sigmoid, C: 4, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 1234.520278618825\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 1282.6033305939704\n",
            "\n",
            "Kernel: sigmoid, C: 4, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 1234.520278618825\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 1282.6033305939704\n",
            "\n",
            "Kernel: sigmoid, C: 4, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02469066698901277\n",
            "[Train] RMSE = 1234.520278618825\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 1282.6033305939704\n",
            "\n",
            "Kernel: sigmoid, C: 4, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02468793189460704\n",
            "[Train] RMSE = 1234.473961870762\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04706525900796514\n",
            "[Val] RMSE = 1282.590228784195\n",
            "\n",
            "Kernel: sigmoid, C: 8, epsilon: 0\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024690666989012768\n",
            "[Train] RMSE = 2469.1621960402754\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 2565.3038497242364\n",
            "\n",
            "Kernel: sigmoid, C: 8, epsilon: 0.1\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024690666989012768\n",
            "[Train] RMSE = 2469.1621960402754\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 2565.3038497242364\n",
            "\n",
            "Kernel: sigmoid, C: 8, epsilon: 0.2\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024690666989012768\n",
            "[Train] RMSE = 2469.1621960402754\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 2565.3038497242364\n",
            "\n",
            "Kernel: sigmoid, C: 8, epsilon: 0.4\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.024690666989012768\n",
            "[Train] RMSE = 2469.1621960402754\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.04709212203457435\n",
            "[Val] RMSE = 2565.3038497242364\n",
            "\n",
            "Kernel: sigmoid, C: 8, epsilon: 0.8\n",
            "====================\n",
            "Fitting...done!\n",
            "[Train] Predicting...done!\n",
            "[Train] Pearson = 0.02468907296211336\n",
            "[Train] RMSE = 2468.8523096692093\n",
            "[Val] Predicting...done!\n",
            "[Val] Pearson = 0.0470542783204084\n",
            "[Val] RMSE = 2565.1295535787244\n",
            "\n",
            "Best validation Pearson: 0.08184283791538666 with config ('linear', 8, 0.4)\n",
            "Best validation loss: 0.9071264206288959 with config ('linear', 2, 0.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NLHl5MGZafE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_val_sent_scores = torch.cat((train_sent_scores, val_sent_scores))\n",
        "train_val_scores = train_scores + val_scores\n",
        "\n",
        "kernel, C, epsilon = best_val_loss[1]\n",
        "final_clf = SVR(kernel=kernel, C=C, epsilon=epsilon)\n",
        "final_clf.fit(train_val_sent_scores, train_val_scores)\n",
        "\n",
        "predictions = final_clf.predict(test_sent_scores)\n",
        "with open('predictions.txt', 'w') as f:\n",
        "    for pred in predictions:\n",
        "        f.write(f'{pred}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ah79MPhKZO9v",
        "colab_type": "text"
      },
      "source": [
        "## BERT Baseline: Sentence Pairs\n",
        "\n",
        "* Multilingual tokeniser\n",
        "* Pretrained model to get sentence pair embeddings\n",
        "* Regression model on sentence pair embeddinsg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZvG5Mc2Zh6R",
        "colab_type": "text"
      },
      "source": [
        "### Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d1ac4bc4-de8a-4219-98cc-a3860df9da77",
        "id": "2GYOY1uxZkqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "BERT_PRETRAINED_MODEL = 'bert-base-multilingual-cased'\n",
        "\n",
        "# Load tokenizer\n",
        "print(f'Loading tokenizer <{BERT_PRETRAINED_MODEL}>...', end=' ')\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_MODEL,\n",
        "                                          do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "# Check tokenizer\n",
        "sample_sent_id = 42\n",
        "\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_zh[sample_sent_id]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading tokenizer <bert-base-multilingual-cased>... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 3159626.98B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done!\n",
            "\n",
            "English\n",
            "All 6 of the artillerymen recorded as wounded died).\n",
            "\n",
            "['All', '6', 'of', 'the', 'artillery', '##men', 'recorded', 'as', 'wounded', 'died', ')', '.']\n",
            "\n",
            "Chinese\n",
            "据记录 ， 所有 6 名炮兵都受伤了) 。\n",
            "\n",
            "['据', '记', '录', '，', '所', '有', '6', '名', '炮', '兵', '都', '受', '伤', '了', ')', '。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvbsh2hjZVk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = sentence_pairs_to_bert_input(tokenizer, train_en, train_zh, max_seq_length=132)\n",
        "val_inputs = sentence_pairs_to_bert_input(tokenizer, val_en, val_zh, max_seq_length=132)\n",
        "test_inputs = sentence_pairs_to_bert_input(tokenizer, test_en, test_zh, max_seq_length=132)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6YyJJHFQCiK",
        "colab_type": "code",
        "outputId": "315a86b1-b285-4849-d5b1-5cae2744dd5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bert = BertModel.from_pretrained(BERT_PRETRAINED_MODEL)\n",
        "bert.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 662804195/662804195 [00:19<00:00, 33707420.15B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dyuIS-raCRl",
        "colab_type": "text"
      },
      "source": [
        "### Sentence pair embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtwLH12QaIBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_bert_embeddings(bert, input_ids, *, batch_size=25):\n",
        "    num_batches = math.ceil(len(input_ids) / batch_size)\n",
        "\n",
        "    embs = []\n",
        "    for batch_id in range(num_batches):\n",
        "        print(f'Batch {batch_id + 1}/{num_batches}...', end='')\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        input_id_batch = input_ids[start_id:end_id]\n",
        "        _, emb = bert(input_id_batch.to(device))\n",
        "        embs.append(emb.detach().cpu())\n",
        "        print('done!')\n",
        "\n",
        "    return embs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9naCFrJKckUh",
        "colab_type": "code",
        "outputId": "a0d08807-1d9c-4359-f1b5-344dd66e127a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bert = BertModel.from_pretrained(BERT_PRETRAINED_MODEL)\n",
        "bert.to(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): BertLayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (1): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (2): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (3): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (4): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (5): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (6): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (7): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (8): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (9): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (10): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "      (11): BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): BertLayerNorm()\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Hr-JHZ8a5nC",
        "colab_type": "code",
        "outputId": "e71d8193-42c9-4557-ea6d-9ef971860a05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_embeddings = get_bert_embeddings(bert, train_inputs)\n",
        "train_embeddings_tensor = torch.cat(train_embeddings)\n",
        "\n",
        "print(train_embeddings_tensor.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1/280...done!\n",
            "Batch 2/280...done!\n",
            "Batch 3/280...done!\n",
            "Batch 4/280...done!\n",
            "Batch 5/280...done!\n",
            "Batch 6/280...done!\n",
            "Batch 7/280...done!\n",
            "Batch 8/280...done!\n",
            "Batch 9/280...done!\n",
            "Batch 10/280...done!\n",
            "Batch 11/280...done!\n",
            "Batch 12/280...done!\n",
            "Batch 13/280...done!\n",
            "Batch 14/280...done!\n",
            "Batch 15/280...done!\n",
            "Batch 16/280...done!\n",
            "Batch 17/280...done!\n",
            "Batch 18/280...done!\n",
            "Batch 19/280...done!\n",
            "Batch 20/280...done!\n",
            "Batch 21/280...done!\n",
            "Batch 22/280...done!\n",
            "Batch 23/280...done!\n",
            "Batch 24/280...done!\n",
            "Batch 25/280...done!\n",
            "Batch 26/280...done!\n",
            "Batch 27/280...done!\n",
            "Batch 28/280...done!\n",
            "Batch 29/280...done!\n",
            "Batch 30/280...done!\n",
            "Batch 31/280...done!\n",
            "Batch 32/280...done!\n",
            "Batch 33/280...done!\n",
            "Batch 34/280...done!\n",
            "Batch 35/280...done!\n",
            "Batch 36/280...done!\n",
            "Batch 37/280...done!\n",
            "Batch 38/280...done!\n",
            "Batch 39/280...done!\n",
            "Batch 40/280...done!\n",
            "Batch 41/280...done!\n",
            "Batch 42/280...done!\n",
            "Batch 43/280...done!\n",
            "Batch 44/280...done!\n",
            "Batch 45/280...done!\n",
            "Batch 46/280...done!\n",
            "Batch 47/280...done!\n",
            "Batch 48/280...done!\n",
            "Batch 49/280...done!\n",
            "Batch 50/280...done!\n",
            "Batch 51/280...done!\n",
            "Batch 52/280...done!\n",
            "Batch 53/280...done!\n",
            "Batch 54/280...done!\n",
            "Batch 55/280...done!\n",
            "Batch 56/280...done!\n",
            "Batch 57/280...done!\n",
            "Batch 58/280...done!\n",
            "Batch 59/280...done!\n",
            "Batch 60/280...done!\n",
            "Batch 61/280...done!\n",
            "Batch 62/280...done!\n",
            "Batch 63/280...done!\n",
            "Batch 64/280...done!\n",
            "Batch 65/280...done!\n",
            "Batch 66/280...done!\n",
            "Batch 67/280...done!\n",
            "Batch 68/280...done!\n",
            "Batch 69/280...done!\n",
            "Batch 70/280...done!\n",
            "Batch 71/280...done!\n",
            "Batch 72/280...done!\n",
            "Batch 73/280...done!\n",
            "Batch 74/280...done!\n",
            "Batch 75/280...done!\n",
            "Batch 76/280...done!\n",
            "Batch 77/280...done!\n",
            "Batch 78/280...done!\n",
            "Batch 79/280...done!\n",
            "Batch 80/280...done!\n",
            "Batch 81/280...done!\n",
            "Batch 82/280...done!\n",
            "Batch 83/280...done!\n",
            "Batch 84/280...done!\n",
            "Batch 85/280...done!\n",
            "Batch 86/280...done!\n",
            "Batch 87/280...done!\n",
            "Batch 88/280...done!\n",
            "Batch 89/280...done!\n",
            "Batch 90/280...done!\n",
            "Batch 91/280...done!\n",
            "Batch 92/280...done!\n",
            "Batch 93/280...done!\n",
            "Batch 94/280...done!\n",
            "Batch 95/280...done!\n",
            "Batch 96/280...done!\n",
            "Batch 97/280...done!\n",
            "Batch 98/280...done!\n",
            "Batch 99/280...done!\n",
            "Batch 100/280...done!\n",
            "Batch 101/280...done!\n",
            "Batch 102/280...done!\n",
            "Batch 103/280...done!\n",
            "Batch 104/280...done!\n",
            "Batch 105/280...done!\n",
            "Batch 106/280...done!\n",
            "Batch 107/280...done!\n",
            "Batch 108/280...done!\n",
            "Batch 109/280...done!\n",
            "Batch 110/280...done!\n",
            "Batch 111/280...done!\n",
            "Batch 112/280...done!\n",
            "Batch 113/280...done!\n",
            "Batch 114/280...done!\n",
            "Batch 115/280...done!\n",
            "Batch 116/280...done!\n",
            "Batch 117/280...done!\n",
            "Batch 118/280...done!\n",
            "Batch 119/280...done!\n",
            "Batch 120/280...done!\n",
            "Batch 121/280...done!\n",
            "Batch 122/280...done!\n",
            "Batch 123/280...done!\n",
            "Batch 124/280...done!\n",
            "Batch 125/280...done!\n",
            "Batch 126/280...done!\n",
            "Batch 127/280...done!\n",
            "Batch 128/280...done!\n",
            "Batch 129/280...done!\n",
            "Batch 130/280...done!\n",
            "Batch 131/280...done!\n",
            "Batch 132/280...done!\n",
            "Batch 133/280...done!\n",
            "Batch 134/280...done!\n",
            "Batch 135/280...done!\n",
            "Batch 136/280...done!\n",
            "Batch 137/280...done!\n",
            "Batch 138/280...done!\n",
            "Batch 139/280...done!\n",
            "Batch 140/280...done!\n",
            "Batch 141/280...done!\n",
            "Batch 142/280...done!\n",
            "Batch 143/280...done!\n",
            "Batch 144/280...done!\n",
            "Batch 145/280...done!\n",
            "Batch 146/280...done!\n",
            "Batch 147/280...done!\n",
            "Batch 148/280...done!\n",
            "Batch 149/280...done!\n",
            "Batch 150/280...done!\n",
            "Batch 151/280...done!\n",
            "Batch 152/280...done!\n",
            "Batch 153/280...done!\n",
            "Batch 154/280...done!\n",
            "Batch 155/280...done!\n",
            "Batch 156/280...done!\n",
            "Batch 157/280...done!\n",
            "Batch 158/280...done!\n",
            "Batch 159/280...done!\n",
            "Batch 160/280...done!\n",
            "Batch 161/280...done!\n",
            "Batch 162/280...done!\n",
            "Batch 163/280...done!\n",
            "Batch 164/280...done!\n",
            "Batch 165/280...done!\n",
            "Batch 166/280...done!\n",
            "Batch 167/280...done!\n",
            "Batch 168/280...done!\n",
            "Batch 169/280...done!\n",
            "Batch 170/280...done!\n",
            "Batch 171/280...done!\n",
            "Batch 172/280...done!\n",
            "Batch 173/280...done!\n",
            "Batch 174/280...done!\n",
            "Batch 175/280...done!\n",
            "Batch 176/280...done!\n",
            "Batch 177/280...done!\n",
            "Batch 178/280...done!\n",
            "Batch 179/280...done!\n",
            "Batch 180/280...done!\n",
            "Batch 181/280...done!\n",
            "Batch 182/280...done!\n",
            "Batch 183/280...done!\n",
            "Batch 184/280...done!\n",
            "Batch 185/280...done!\n",
            "Batch 186/280...done!\n",
            "Batch 187/280...done!\n",
            "Batch 188/280...done!\n",
            "Batch 189/280...done!\n",
            "Batch 190/280...done!\n",
            "Batch 191/280...done!\n",
            "Batch 192/280...done!\n",
            "Batch 193/280...done!\n",
            "Batch 194/280...done!\n",
            "Batch 195/280...done!\n",
            "Batch 196/280...done!\n",
            "Batch 197/280...done!\n",
            "Batch 198/280...done!\n",
            "Batch 199/280...done!\n",
            "Batch 200/280...done!\n",
            "Batch 201/280...done!\n",
            "Batch 202/280...done!\n",
            "Batch 203/280...done!\n",
            "Batch 204/280...done!\n",
            "Batch 205/280...done!\n",
            "Batch 206/280...done!\n",
            "Batch 207/280...done!\n",
            "Batch 208/280...done!\n",
            "Batch 209/280...done!\n",
            "Batch 210/280...done!\n",
            "Batch 211/280...done!\n",
            "Batch 212/280...done!\n",
            "Batch 213/280...done!\n",
            "Batch 214/280...done!\n",
            "Batch 215/280...done!\n",
            "Batch 216/280...done!\n",
            "Batch 217/280...done!\n",
            "Batch 218/280...done!\n",
            "Batch 219/280...done!\n",
            "Batch 220/280...done!\n",
            "Batch 221/280...done!\n",
            "Batch 222/280...done!\n",
            "Batch 223/280...done!\n",
            "Batch 224/280...done!\n",
            "Batch 225/280...done!\n",
            "Batch 226/280...done!\n",
            "Batch 227/280...done!\n",
            "Batch 228/280...done!\n",
            "Batch 229/280...done!\n",
            "Batch 230/280...done!\n",
            "Batch 231/280...done!\n",
            "Batch 232/280...done!\n",
            "Batch 233/280...done!\n",
            "Batch 234/280...done!\n",
            "Batch 235/280...done!\n",
            "Batch 236/280...done!\n",
            "Batch 237/280...done!\n",
            "Batch 238/280...done!\n",
            "Batch 239/280...done!\n",
            "Batch 240/280...done!\n",
            "Batch 241/280...done!\n",
            "Batch 242/280...done!\n",
            "Batch 243/280...done!\n",
            "Batch 244/280...done!\n",
            "Batch 245/280...done!\n",
            "Batch 246/280...done!\n",
            "Batch 247/280...done!\n",
            "Batch 248/280...done!\n",
            "Batch 249/280...done!\n",
            "Batch 250/280...done!\n",
            "Batch 251/280...done!\n",
            "Batch 252/280...done!\n",
            "Batch 253/280...done!\n",
            "Batch 254/280...done!\n",
            "Batch 255/280...done!\n",
            "Batch 256/280...done!\n",
            "Batch 257/280...done!\n",
            "Batch 258/280...done!\n",
            "Batch 259/280...done!\n",
            "Batch 260/280...done!\n",
            "Batch 261/280...done!\n",
            "Batch 262/280...done!\n",
            "Batch 263/280...done!\n",
            "Batch 264/280...done!\n",
            "Batch 265/280...done!\n",
            "Batch 266/280...done!\n",
            "Batch 267/280...done!\n",
            "Batch 268/280...done!\n",
            "Batch 269/280...done!\n",
            "Batch 270/280...done!\n",
            "Batch 271/280...done!\n",
            "Batch 272/280...done!\n",
            "Batch 273/280...done!\n",
            "Batch 274/280...done!\n",
            "Batch 275/280...done!\n",
            "Batch 276/280...done!\n",
            "Batch 277/280...done!\n",
            "Batch 278/280...done!\n",
            "Batch 279/280...done!\n",
            "Batch 280/280...done!\n",
            "torch.Size([7000, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5X2g2trWeCjF",
        "colab_type": "code",
        "outputId": "bb2af70e-eb1c-443e-840c-33be0a28717a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "val_embeddings = get_bert_embeddings(bert, val_inputs)\n",
        "val_embeddings_tensor = torch.cat(val_embeddings)\n",
        "\n",
        "print(f'Validation embeddings', val_embeddings_tensor.shape)\n",
        "\n",
        "test_embeddings = get_bert_embeddings(bert, test_inputs)\n",
        "test_embeddings_tensor = torch.cat(test_embeddings)\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "print(f'Test embeddings', test_embeddings_tensor.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n",
            "Validation embeddings torch.Size([1000, 768])\n",
            "Batch 1/40...done!\n",
            "Batch 2/40...done!\n",
            "Batch 3/40...done!\n",
            "Batch 4/40...done!\n",
            "Batch 5/40...done!\n",
            "Batch 6/40...done!\n",
            "Batch 7/40...done!\n",
            "Batch 8/40...done!\n",
            "Batch 9/40...done!\n",
            "Batch 10/40...done!\n",
            "Batch 11/40...done!\n",
            "Batch 12/40...done!\n",
            "Batch 13/40...done!\n",
            "Batch 14/40...done!\n",
            "Batch 15/40...done!\n",
            "Batch 16/40...done!\n",
            "Batch 17/40...done!\n",
            "Batch 18/40...done!\n",
            "Batch 19/40...done!\n",
            "Batch 20/40...done!\n",
            "Batch 21/40...done!\n",
            "Batch 22/40...done!\n",
            "Batch 23/40...done!\n",
            "Batch 24/40...done!\n",
            "Batch 25/40...done!\n",
            "Batch 26/40...done!\n",
            "Batch 27/40...done!\n",
            "Batch 28/40...done!\n",
            "Batch 29/40...done!\n",
            "Batch 30/40...done!\n",
            "Batch 31/40...done!\n",
            "Batch 32/40...done!\n",
            "Batch 33/40...done!\n",
            "Batch 34/40...done!\n",
            "Batch 35/40...done!\n",
            "Batch 36/40...done!\n",
            "Batch 37/40...done!\n",
            "Batch 38/40...done!\n",
            "Batch 39/40...done!\n",
            "Batch 40/40...done!\n",
            "Test embeddings torch.Size([1000, 768])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DG-aUD6l20q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target, *, numpy=False):\n",
        "    mean = np.mean if numpy else torch.mean\n",
        "    sqrt = np.sqrt if numpy else torch.sqrt\n",
        "    return sqrt(mean((pred - target) ** 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7kFZY6_Lkd9c",
        "colab_type": "text"
      },
      "source": [
        "### Regression Layer: SVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM5UpkaLfY-w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "\n",
        "for kernel in ('linear', 'poly', 'rbf', 'sigmoid'):\n",
        "    for epsilon in (0, 0.1, 0.2, 0.3):\n",
        "        print(f'Kernel: {kernel}, Epsilon: {epsilon}')\n",
        "        print('=' * 10)\n",
        "        clf_t = SVR(kernel=kernel, epsilon=epsilon)\n",
        "        print('Fitting...', end='')\n",
        "        clf_t.fit(train_embeddings_tensor.numpy(), train_scores)\n",
        "        print('done!')\n",
        "\n",
        "        print('Predicting...', end='')\n",
        "        predictions = clf_t.predict(val_embeddings_tensor.numpy())\n",
        "        print('done!')\n",
        "        pearson, _ = pearsonr(predictions, val_scores)\n",
        "        print(f'Pearson = {pearson}')\n",
        "        loss = RMSELoss(predictions, val_scores, numpy=True)\n",
        "        print(f'RMSE = {loss}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YjFuSpDsZkm",
        "colab_type": "code",
        "outputId": "9470e1ca-b7de-4763-fcfa-895f0fa76570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "clf_t = SVR(kernel='rbf', epsilon=0.3)\n",
        "print('Fitting...', end='')\n",
        "clf_t.fit(train_embeddings_tensor.numpy(), train_scores)\n",
        "print('done!')\n",
        "\n",
        "print('Predicting...', end='')\n",
        "predictions = clf_t.predict(val_embeddings_tensor.numpy())\n",
        "print('done!')\n",
        "\n",
        "plt.scatter(predictions, val_scores)\n",
        "plt.show()\n",
        "\n",
        "test_predictions = clf_t.predict(test_embeddings_tensor.numpy())\n",
        "with open('predictions_bert_svr.txt', 'w') as f:\n",
        "    for pred in test_predictions:\n",
        "        f.write(f'{pred}\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting...done!\n",
            "Predicting...done!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMCnk/wPGOdrJBInKKAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NdWepeVTkgwG",
        "colab_type": "text"
      },
      "source": [
        "### Regression Layer: FFNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ge8Godi0kmhi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNNRegression(nn.Module):\n",
        "\n",
        "    def __init__(self, *hidden_dims, input_dim=768, nonlin=F.relu):\n",
        "        super().__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dims = hidden_dims\n",
        "        self.nonlin = nonlin\n",
        "\n",
        "        prev_dim = input_dim\n",
        "        for i, hidden_dim in enumerate(self.hidden_dims):\n",
        "            setattr(self, f'hidden_{i}', nn.Linear(prev_dim, hidden_dim))\n",
        "            prev_dim = hidden_dim\n",
        "        \n",
        "        self.out = nn.Linear(prev_dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        act = x\n",
        "        for i, _ in enumerate(self.hidden_dims):\n",
        "            layer = getattr(self, f'hidden_{i}')\n",
        "            act = self.nonlin(layer(act))\n",
        "        return self.out(act)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bV9jew4lSTf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_mini_batches(inputs, scores, *, batch_size=8):\n",
        "\n",
        "    # idxs = np.arange(len(inputs))\n",
        "    # np.random.shuffle(idxs)\n",
        "\n",
        "    num_batches = math.ceil(len(inputs) / batch_size)\n",
        "\n",
        "    for batch_id in range(num_batches):\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        yield inputs[start_id:end_id], scores[start_id:end_id]\n",
        "\n",
        "def gradient_descent(model, loss_fn, optimiser, input_ids, scores):\n",
        "    model.train()\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    predictions = model(input_ids.to(device)).squeeze()\n",
        "    \n",
        "    loss = loss_fn(predictions, torch.Tensor(scores).to(device))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train(model, loss_fn, optimiser, train_inputs, train_scores, val_inputs, val_scores, *, num_epochs=10, batch_size=32, print=print, filename):\n",
        "\n",
        "    opt_pearson = None\n",
        "    opt_epoch = None\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        print(f'Epoch #{epoch_idx + 1}')\n",
        "\n",
        "        model.to(device)\n",
        "        \n",
        "        processed = 0\n",
        "        increment = 0.05\n",
        "        milestone = 0.05\n",
        "        print('Training', end='')\n",
        "        for input_ids, scores in get_mini_batches(train_inputs, train_scores, batch_size=batch_size):\n",
        "            loss = gradient_descent(model, loss_fn, optimiser, input_ids, scores)\n",
        "            processed += len(input_ids)\n",
        "\n",
        "            if processed / len(train_inputs) >= milestone:\n",
        "                print('.', end='')\n",
        "                milestone += increment\n",
        "        print('done!')\n",
        "        print('Recent loss', loss)\n",
        "\n",
        "        # Check validation loss\n",
        "        model.eval()\n",
        "        model.to('cpu')\n",
        "\n",
        "        print('Getting validation predictions...', end='')\n",
        "        val_preds = model(val_inputs).squeeze().detach()\n",
        "        print(f'done! <{val_preds[0]}, {val_scores[0]}>..<{val_preds[-1]}, {val_scores[-1]}>')\n",
        "        val_loss = loss_fn(val_preds, torch.Tensor(val_scores))\n",
        "        print('Validation loss', val_loss)\n",
        "\n",
        "        pearson, _ = pearsonr(val_preds.numpy(), np.array(val_scores))\n",
        "        print('Validation Pearson', pearson)\n",
        "\n",
        "        if opt_pearson is None or pearson > opt_pearson:\n",
        "            opt_pearson = pearson\n",
        "            opt_epoch = epoch_idx + 1\n",
        "            torch.save(model.state_dict(), f'{filename}.pt')\n",
        "\n",
        "        print()\n",
        "\n",
        "    return opt_epoch, opt_pearson"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYcm-hTKlF6t",
        "colab_type": "code",
        "outputId": "71171fa7-63b7-484a-eb69-98e28c021fad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "TUNE_LR = (1e-2, 3e-2, 1e-3, 3e-3)\n",
        "TUNE_LAYERS = (\n",
        "    tuple(),\n",
        "    (25,),\n",
        "    (50,),\n",
        "    (75,),\n",
        "    (100,),\n",
        "    (100, 25),\n",
        "    (100, 25, 25),\n",
        "    (100, 50),\n",
        "    (100, 50, 25),\n",
        "    (100, 50, 50),\n",
        "    (100, 75),\n",
        "    (100, 75, 25),\n",
        "    (100, 75, 50),\n",
        "    (100, 75, 75),\n",
        "    (100, 100),\n",
        "    (100, 100, 25),\n",
        "    (100, 100, 50),\n",
        "    (100, 100, 75),\n",
        "    (100, 100, 100),\n",
        ")\n",
        "TUNE_NONLIN = (\n",
        "    F.relu,\n",
        "    F.leaky_relu,\n",
        "    torch.tanh,\n",
        "    torch.sigmoid\n",
        ")\n",
        "\n",
        "def dummy_print(*args, **kwargs):\n",
        "    ...\n",
        "\n",
        "from collections import namedtuple\n",
        "OptimalConfig = namedtuple('OptimalConfig', ('Pearson', 'NumEpochs', 'Layers', 'LR', 'NonLin'))\n",
        "\n",
        "results = []\n",
        "for arch in TUNE_LAYERS:\n",
        "    for lr in TUNE_LR:\n",
        "        for nonlin in TUNE_NONLIN:\n",
        "\n",
        "            filename = '-'.join([str(x) for x in arch]) + f'_lr={lr}_nonlin={nonlin.__name__}'\n",
        "            filename = filename.replace('.', '-')\n",
        "\n",
        "            print(f'Arch={arch}, LR={lr}, NONLIN={nonlin}...', end='')\n",
        "            regressor = FFNNRegression(*arch, nonlin=nonlin)\n",
        "            opt = torch.optim.Adam(regressor.parameters(), lr=lr)\n",
        "\n",
        "            opt_epoch, opt_pearson = train(\n",
        "                regressor, RMSELoss, opt,\n",
        "                train_embeddings_tensor, train_scores,\n",
        "                val_embeddings_tensor, val_scores,\n",
        "                num_epochs=200,\n",
        "                batch_size=7000,\n",
        "                print=dummy_print,\n",
        "                filename=filename\n",
        "            )\n",
        "\n",
        "            results.append(OptimalConfig(opt_pearson, opt_epoch, arch, lr, nonlin))\n",
        "            print(f'done! ({opt_pearson})')\n",
        "\n",
        "results.sort(reverse=True)\n",
        "\n",
        "from pprint import PrettyPrinter\n",
        "\n",
        "PrettyPrinter().pprint(results)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Arch=(), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28105530234822496)\n",
            "Arch=(), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2860009364264516)\n",
            "Arch=(), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.28091874474750295)\n",
            "Arch=(), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2859342214312588)\n",
            "Arch=(), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2882250718981777)\n",
            "Arch=(), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28885140089478295)\n",
            "Arch=(), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29105985224556774)\n",
            "Arch=(), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28807133910127836)\n",
            "Arch=(), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2870112609614075)\n",
            "Arch=(), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2741912850708949)\n",
            "Arch=(), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2819567625478343)\n",
            "Arch=(), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27847668501403605)\n",
            "Arch=(), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2855538999966372)\n",
            "Arch=(), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27671555693911737)\n",
            "Arch=(), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2743147813559379)\n",
            "Arch=(), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2808766808871344)\n",
            "Arch=(25,), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.17095820027624245)\n",
            "Arch=(25,), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2792837472647055)\n",
            "Arch=(25,), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2883820156469059)\n",
            "Arch=(25,), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29638012333021807)\n",
            "Arch=(25,), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.07353031030884867)\n",
            "Arch=(25,), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2785091047259626)\n",
            "Arch=(25,), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.05432172159507307)\n",
            "Arch=(25,), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.282034898316176)\n",
            "Arch=(25,), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28362455467995684)\n",
            "Arch=(25,), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.29537034443821114)\n",
            "Arch=(25,), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2949903018597303)\n",
            "Arch=(25,), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2895302138376736)\n",
            "Arch=(25,), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28251553734214263)\n",
            "Arch=(25,), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28970961006671064)\n",
            "Arch=(25,), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.28919481597871877)\n",
            "Arch=(25,), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2869675004718936)\n",
            "Arch=(50,), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.25387922977027777)\n",
            "Arch=(50,), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28967368989867326)\n",
            "Arch=(50,), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2855391158236458)\n",
            "Arch=(50,), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2825938929665822)\n",
            "Arch=(50,), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2791819259820171)\n",
            "Arch=(50,), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28242195966757927)\n",
            "Arch=(50,), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.24241734240509502)\n",
            "Arch=(50,), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.25264694275524036)\n",
            "Arch=(50,), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28882128410342134)\n",
            "Arch=(50,), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28776013895128266)\n",
            "Arch=(50,), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29594786984621063)\n",
            "Arch=(50,), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2747001972840205)\n",
            "Arch=(50,), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2763446677831702)\n",
            "Arch=(50,), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2816802837151265)\n",
            "Arch=(50,), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2830470359911722)\n",
            "Arch=(50,), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2839919772290898)\n",
            "Arch=(75,), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2692707031840055)\n",
            "Arch=(75,), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2757499018895719)\n",
            "Arch=(75,), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2968752648130709)\n",
            "Arch=(75,), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2817765532855406)\n",
            "Arch=(75,), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2888825868081962)\n",
            "Arch=(75,), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.15048299981554863)\n",
            "Arch=(75,), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.06781484874426731)\n",
            "Arch=(75,), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2620356128524084)\n",
            "Arch=(75,), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2889656207141769)\n",
            "Arch=(75,), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.284347341328517)\n",
            "Arch=(75,), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2917512558022372)\n",
            "Arch=(75,), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2891589248084606)\n",
            "Arch=(75,), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28450420735008997)\n",
            "Arch=(75,), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2943112594854675)\n",
            "Arch=(75,), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2883584918655722)\n",
            "Arch=(75,), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2952930217385095)\n",
            "Arch=(100,), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27841771800682935)\n",
            "Arch=(100,), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.29156347695987983)\n",
            "Arch=(100,), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29099950675312536)\n",
            "Arch=(100,), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.286417414821136)\n",
            "Arch=(100,), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2911502622258315)\n",
            "Arch=(100,), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.29379717718107523)\n",
            "Arch=(100,), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2731071992377257)\n",
            "Arch=(100,), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29152348840464454)\n",
            "Arch=(100,), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28540054911458596)\n",
            "Arch=(100,), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28564814338775035)\n",
            "Arch=(100,), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2873249406092934)\n",
            "Arch=(100,), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.26224449315284504)\n",
            "Arch=(100,), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28272104287666605)\n",
            "Arch=(100,), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2886802017094327)\n",
            "Arch=(100,), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2896912689256792)\n",
            "Arch=(100,), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29062766027396636)\n",
            "Arch=(100, 25), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2665049989624473)\n",
            "Arch=(100, 25), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27637598487851484)\n",
            "Arch=(100, 25), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.26567805789643995)\n",
            "Arch=(100, 25), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27609699584193437)\n",
            "Arch=(100, 25), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.057018361813945276)\n",
            "Arch=(100, 25), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2849318843144597)\n",
            "Arch=(100, 25), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.02355835334742096)\n",
            "Arch=(100, 25), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.1730026679025851)\n",
            "Arch=(100, 25), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2784939383939364)\n",
            "Arch=(100, 25), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.29163654841405634)\n",
            "Arch=(100, 25), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2985014638857869)\n",
            "Arch=(100, 25), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28037652676839314)\n",
            "Arch=(100, 25), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27704520388701004)\n",
            "Arch=(100, 25), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27142396062636603)\n",
            "Arch=(100, 25), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29328882956355984)\n",
            "Arch=(100, 25), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2928069905309426)\n",
            "Arch=(100, 25, 25), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2635618285834192)\n",
            "Arch=(100, 25, 25), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26224130871432827)\n",
            "Arch=(100, 25, 25), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2804777311915576)\n",
            "Arch=(100, 25, 25), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28536472168059807)\n",
            "Arch=(100, 25, 25), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2759806988625327)\n",
            "Arch=(100, 25, 25), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26150139858182575)\n",
            "Arch=(100, 25, 25), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.05082435939516899)\n",
            "Arch=(100, 25, 25), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2714828802504253)\n",
            "Arch=(100, 25, 25), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2800837654806712)\n",
            "Arch=(100, 25, 25), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28211538960154214)\n",
            "Arch=(100, 25, 25), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2970280340976121)\n",
            "Arch=(100, 25, 25), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2897843546177016)\n",
            "Arch=(100, 25, 25), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2756007224687517)\n",
            "Arch=(100, 25, 25), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28183089721120275)\n",
            "Arch=(100, 25, 25), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2846631189502018)\n",
            "Arch=(100, 25, 25), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28902967759697)\n",
            "Arch=(100, 50), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.26201559310731465)\n",
            "Arch=(100, 50), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2626763274588418)\n",
            "Arch=(100, 50), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2792729004307802)\n",
            "Arch=(100, 50), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2859094711478082)\n",
            "Arch=(100, 50), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.21520024980436347)\n",
            "Arch=(100, 50), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2698781264070087)\n",
            "Arch=(100, 50), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.04871032948562512)\n",
            "Arch=(100, 50), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2455469626805747)\n",
            "Arch=(100, 50), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27437957277322084)\n",
            "Arch=(100, 50), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2872145981871874)\n",
            "Arch=(100, 50), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2985413735129883)\n",
            "Arch=(100, 50), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29114461944772047)\n",
            "Arch=(100, 50), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27550778591688685)\n",
            "Arch=(100, 50), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27300337281506365)\n",
            "Arch=(100, 50), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2949053197041216)\n",
            "Arch=(100, 50), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2909759372837723)\n",
            "Arch=(100, 50, 25), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2640405679041724)\n",
            "Arch=(100, 50, 25), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26491160754434373)\n",
            "Arch=(100, 50, 25), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2802649517544417)\n",
            "Arch=(100, 50, 25), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2746834380896651)\n",
            "Arch=(100, 50, 25), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>..."
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done! (0.18087049976270508)\n",
            "Arch=(100, 50, 25), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2820851580049851)\n",
            "Arch=(100, 50, 25), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.0201158533612958)\n",
            "Arch=(100, 50, 25), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2671838613370639)\n",
            "Arch=(100, 50, 25), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.28376101887546046)\n",
            "Arch=(100, 50, 25), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2811858608160359)\n",
            "Arch=(100, 50, 25), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29647297294226255)\n",
            "Arch=(100, 50, 25), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2723193991748301)\n",
            "Arch=(100, 50, 25), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.273314510238957)\n",
            "Arch=(100, 50, 25), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26390257698829883)\n",
            "Arch=(100, 50, 25), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29348860226588347)\n",
            "Arch=(100, 50, 25), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28718766650677907)\n",
            "Arch=(100, 50, 50), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2554773775022402)\n",
            "Arch=(100, 50, 50), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27359330396902803)\n",
            "Arch=(100, 50, 50), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.27942709048328895)\n",
            "Arch=(100, 50, 50), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27312493022074813)\n",
            "Arch=(100, 50, 50), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2874920321235159)\n",
            "Arch=(100, 50, 50), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.24217981830711247)\n",
            "Arch=(100, 50, 50), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.030137751394287874)\n",
            "Arch=(100, 50, 50), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27357372495649546)\n",
            "Arch=(100, 50, 50), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2793467246894504)\n",
            "Arch=(100, 50, 50), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2756274194407922)\n",
            "Arch=(100, 50, 50), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29667400120031523)\n",
            "Arch=(100, 50, 50), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.290035032807076)\n",
            "Arch=(100, 50, 50), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27781044921088893)\n",
            "Arch=(100, 50, 50), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2720628769245214)\n",
            "Arch=(100, 50, 50), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2953090745982414)\n",
            "Arch=(100, 50, 50), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2875748648554637)\n",
            "Arch=(100, 75), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2685178913584547)\n",
            "Arch=(100, 75), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27803646425128553)\n",
            "Arch=(100, 75), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.28842479232118184)\n",
            "Arch=(100, 75), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29128740660923613)\n",
            "Arch=(100, 75), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27098765159902494)\n",
            "Arch=(100, 75), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28236140438474727)\n",
            "Arch=(100, 75), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.08325908424119058)\n",
            "Arch=(100, 75), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.25339859724754116)\n",
            "Arch=(100, 75), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2817241594220118)\n",
            "Arch=(100, 75), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2804130511276762)\n",
            "Arch=(100, 75), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2988673613154449)\n",
            "Arch=(100, 75), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.23523961861653547)\n",
            "Arch=(100, 75), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2715942942580975)\n",
            "Arch=(100, 75), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28204189990317446)\n",
            "Arch=(100, 75), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.295349789198072)\n",
            "Arch=(100, 75), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2912782417873248)\n",
            "Arch=(100, 75, 25), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.25749815584139824)\n",
            "Arch=(100, 75, 25), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2730277695427651)\n",
            "Arch=(100, 75, 25), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.24693667513489684)\n",
            "Arch=(100, 75, 25), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27548850356337906)\n",
            "Arch=(100, 75, 25), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.1454691479484813)\n",
            "Arch=(100, 75, 25), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27677685331344054)\n",
            "Arch=(100, 75, 25), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.02923895498605772)\n",
            "Arch=(100, 75, 25), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.02027895010554185)\n",
            "Arch=(100, 75, 25), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27252334382361443)\n",
            "Arch=(100, 75, 25), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28400633707287265)\n",
            "Arch=(100, 75, 25), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.297411409754686)\n",
            "Arch=(100, 75, 25), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2906105165902436)\n",
            "Arch=(100, 75, 25), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.26481193171391165)\n",
            "Arch=(100, 75, 25), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27247985687993126)\n",
            "Arch=(100, 75, 25), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29511995772787564)\n",
            "Arch=(100, 75, 25), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2857982444487699)\n",
            "Arch=(100, 75, 50), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.24417410785578195)\n",
            "Arch=(100, 75, 50), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2766211485811319)\n",
            "Arch=(100, 75, 50), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.284304904989693)\n",
            "Arch=(100, 75, 50), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2823693407276205)\n",
            "Arch=(100, 75, 50), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.17003363706576094)\n",
            "Arch=(100, 75, 50), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2783011030582417)\n",
            "Arch=(100, 75, 50), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.21505708799488685)\n",
            "Arch=(100, 75, 50), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.26616334474848413)\n",
            "Arch=(100, 75, 50), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2733442558602003)\n",
            "Arch=(100, 75, 50), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2794307358371012)\n",
            "Arch=(100, 75, 50), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29812127208852407)\n",
            "Arch=(100, 75, 50), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2833963710282882)\n",
            "Arch=(100, 75, 50), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.26448027693877396)\n",
            "Arch=(100, 75, 50), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2789631559081635)\n",
            "Arch=(100, 75, 50), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2915245107184388)\n",
            "Arch=(100, 75, 50), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2875595226339283)\n",
            "Arch=(100, 75, 75), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.26408996754554465)\n",
            "Arch=(100, 75, 75), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.25691989396605547)\n",
            "Arch=(100, 75, 75), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.28408109158869044)\n",
            "Arch=(100, 75, 75), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28704392258797956)\n",
            "Arch=(100, 75, 75), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2814533949656334)\n",
            "Arch=(100, 75, 75), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.16686106447171087)\n",
            "Arch=(100, 75, 75), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.07487745462099712)\n",
            "Arch=(100, 75, 75), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.24817533097003092)\n",
            "Arch=(100, 75, 75), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.276655997244485)\n",
            "Arch=(100, 75, 75), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2848336459339889)\n",
            "Arch=(100, 75, 75), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.3013955752326213)\n",
            "Arch=(100, 75, 75), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2901127142709879)\n",
            "Arch=(100, 75, 75), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2661932976443531)\n",
            "Arch=(100, 75, 75), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2725679394044081)\n",
            "Arch=(100, 75, 75), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2918868750973074)\n",
            "Arch=(100, 75, 75), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28709176899409766)\n",
            "Arch=(100, 100), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2755416067717938)\n",
            "Arch=(100, 100), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27412383938701423)\n",
            "Arch=(100, 100), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.19227197442750016)\n",
            "Arch=(100, 100), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2903919905034526)\n",
            "Arch=(100, 100), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2719717853150056)\n",
            "Arch=(100, 100), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2866222220207056)\n",
            "Arch=(100, 100), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.03564108835797456)\n",
            "Arch=(100, 100), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.21851519721477744)\n",
            "Arch=(100, 100), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2758637144391603)\n",
            "Arch=(100, 100), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2894430210908701)\n",
            "Arch=(100, 100), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29587119807316725)\n",
            "Arch=(100, 100), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.255254644672678)\n",
            "Arch=(100, 100), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2740664847372465)\n",
            "Arch=(100, 100), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2713661853923833)\n",
            "Arch=(100, 100), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.293101186857309)\n",
            "Arch=(100, 100), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.29057096016345674)\n",
            "Arch=(100, 100, 25), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27616505471327263)\n",
            "Arch=(100, 100, 25), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26536990248182446)\n",
            "Arch=(100, 100, 25), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2849622598874191)\n",
            "Arch=(100, 100, 25), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2768017245430395)\n",
            "Arch=(100, 100, 25), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.27976588394132074)\n",
            "Arch=(100, 100, 25), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2721583788197788)\n",
            "Arch=(100, 100, 25), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.052313131858380886)\n",
            "Arch=(100, 100, 25), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2044490583737785)\n",
            "Arch=(100, 100, 25), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2741111477663866)\n",
            "Arch=(100, 100, 25), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28130623542309086)\n",
            "Arch=(100, 100, 25), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.3004868715585328)\n",
            "Arch=(100, 100, 25), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.20714913466917836)\n",
            "Arch=(100, 100, 25), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2702557529373012)\n",
            "Arch=(100, 100, 25), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26687474362986335)\n",
            "Arch=(100, 100, 25), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2935696929258705)\n",
            "Arch=(100, 100, 25), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28760135368695544)\n",
            "Arch=(100, 100, 50), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2595292826256175)\n",
            "Arch=(100, 100, 50), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2791227637609148)\n",
            "Arch=(100, 100, 50), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.280338151982088)\n",
            "Arch=(100, 100, 50), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.27666203107307824)\n",
            "Arch=(100, 100, 50), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.13225981544827944)\n",
            "Arch=(100, 100, 50), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.28143951104778275)\n",
            "Arch=(100, 100, 50), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.0011667468938153507)\n",
            "Arch=(100, 100, 50), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.194652959023591)\n",
            "Arch=(100, 100, 50), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2803170856115924)\n",
            "Arch=(100, 100, 50), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27868657316344575)\n",
            "Arch=(100, 100, 50), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29599230280455474)\n",
            "Arch=(100, 100, 50), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.290902961503756)\n",
            "Arch=(100, 100, 50), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2667764054193849)\n",
            "Arch=(100, 100, 50), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2718596955459009)\n",
            "Arch=(100, 100, 50), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2953416176059212)\n",
            "Arch=(100, 100, 50), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2872505787196264)\n",
            "Arch=(100, 100, 75), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.24701259477866977)\n",
            "Arch=(100, 100, 75), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.25527890923328095)\n",
            "Arch=(100, 100, 75), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.28688668996532757)\n",
            "Arch=(100, 100, 75), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2717155971259742)\n",
            "Arch=(100, 100, 75), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2771428830595677)\n",
            "Arch=(100, 100, 75), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2859120295359068)\n",
            "Arch=(100, 100, 75), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.03456417920106858)\n",
            "Arch=(100, 100, 75), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.0693454922183015)\n",
            "Arch=(100, 100, 75), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2771835655853804)\n",
            "Arch=(100, 100, 75), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2827994975816811)\n",
            "Arch=(100, 100, 75), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29887408795604914)\n",
            "Arch=(100, 100, 75), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2784518894986238)\n",
            "Arch=(100, 100, 75), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2634336468563384)\n",
            "Arch=(100, 100, 75), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2734521090723479)\n",
            "Arch=(100, 100, 75), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.295961742589423)\n",
            "Arch=(100, 100, 75), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28599870288803364)\n",
            "Arch=(100, 100, 100), LR=0.01, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2702382236919746)\n",
            "Arch=(100, 100, 100), LR=0.01, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.2605401921221696)\n",
            "Arch=(100, 100, 100), LR=0.01, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2891311134468025)\n",
            "Arch=(100, 100, 100), LR=0.01, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.2735753291451884)\n",
            "Arch=(100, 100, 100), LR=0.03, NONLIN=<function relu at 0x7f334da8b598>...done! (0.17648976108221093)\n",
            "Arch=(100, 100, 100), LR=0.03, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27923221024446093)\n",
            "Arch=(100, 100, 100), LR=0.03, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.08668454944557942)\n",
            "Arch=(100, 100, 100), LR=0.03, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.25715114845741693)\n",
            "Arch=(100, 100, 100), LR=0.001, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2675351863539133)\n",
            "Arch=(100, 100, 100), LR=0.001, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.26795696733218166)\n",
            "Arch=(100, 100, 100), LR=0.001, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.2973547562667057)\n",
            "Arch=(100, 100, 100), LR=0.001, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.28971261123098235)\n",
            "Arch=(100, 100, 100), LR=0.003, NONLIN=<function relu at 0x7f334da8b598>...done! (0.2625341499778508)\n",
            "Arch=(100, 100, 100), LR=0.003, NONLIN=<function leaky_relu at 0x7f334da8b950>...done! (0.27495971657392354)\n",
            "Arch=(100, 100, 100), LR=0.003, NONLIN=<built-in method tanh of type object at 0x7f3399e57860>...done! (0.29522797051158706)\n",
            "Arch=(100, 100, 100), LR=0.003, NONLIN=<built-in method sigmoid of type object at 0x7f3399e57860>...done! (0.287119812259312)\n",
            "[OptimalConfig(Pearson=0.3013955752326213, NumEpochs=154, Layers=(100, 75, 75), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.3004868715585328, NumEpochs=189, Layers=(100, 100, 25), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29887408795604914, NumEpochs=198, Layers=(100, 100, 75), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2988673613154449, NumEpochs=164, Layers=(100, 75), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2985413735129883, NumEpochs=195, Layers=(100, 50), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2985014638857869, NumEpochs=174, Layers=(100, 25), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29812127208852407, NumEpochs=196, Layers=(100, 75, 50), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.297411409754686, NumEpochs=169, Layers=(100, 75, 25), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2973547562667057, NumEpochs=185, Layers=(100, 100, 100), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2970280340976121, NumEpochs=200, Layers=(100, 25, 25), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2968752648130709, NumEpochs=184, Layers=(75,), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29667400120031523, NumEpochs=174, Layers=(100, 50, 50), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29647297294226255, NumEpochs=199, Layers=(100, 50, 25), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29638012333021807, NumEpochs=198, Layers=(25,), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29599230280455474, NumEpochs=198, Layers=(100, 100, 50), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.295961742589423, NumEpochs=198, Layers=(100, 100, 75), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29594786984621063, NumEpochs=200, Layers=(50,), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29587119807316725, NumEpochs=168, Layers=(100, 100), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29537034443821114, NumEpochs=158, Layers=(25,), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.295349789198072, NumEpochs=170, Layers=(100, 75), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2953416176059212, NumEpochs=157, Layers=(100, 100, 50), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2953090745982414, NumEpochs=168, Layers=(100, 50, 50), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2952930217385095, NumEpochs=177, Layers=(75,), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29522797051158706, NumEpochs=147, Layers=(100, 100, 100), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29511995772787564, NumEpochs=137, Layers=(100, 75, 25), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2949903018597303, NumEpochs=197, Layers=(25,), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2949053197041216, NumEpochs=186, Layers=(100, 50), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2943112594854675, NumEpochs=169, Layers=(75,), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.29379717718107523, NumEpochs=196, Layers=(100,), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2935696929258705, NumEpochs=157, Layers=(100, 100, 25), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29348860226588347, NumEpochs=133, Layers=(100, 50, 25), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29328882956355984, NumEpochs=192, Layers=(100, 25), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.293101186857309, NumEpochs=169, Layers=(100, 100), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2928069905309426, NumEpochs=169, Layers=(100, 25), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2918868750973074, NumEpochs=168, Layers=(100, 75, 75), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2917512558022372, NumEpochs=196, Layers=(75,), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29163654841405634, NumEpochs=106, Layers=(100, 25), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.29156347695987983, NumEpochs=155, Layers=(100,), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2915245107184388, NumEpochs=119, Layers=(100, 75, 50), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29152348840464454, NumEpochs=200, Layers=(100,), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29128740660923613, NumEpochs=185, Layers=(100, 75), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2912782417873248, NumEpochs=152, Layers=(100, 75), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2911502622258315, NumEpochs=147, Layers=(100,), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.29114461944772047, NumEpochs=184, Layers=(100, 50), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29105985224556774, NumEpochs=200, Layers=(), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29099950675312536, NumEpochs=183, Layers=(100,), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2909759372837723, NumEpochs=147, Layers=(100, 50), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.290902961503756, NumEpochs=176, Layers=(100, 100, 50), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29062766027396636, NumEpochs=200, Layers=(100,), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2906105165902436, NumEpochs=178, Layers=(100, 75, 25), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.29057096016345674, NumEpochs=174, Layers=(100, 100), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2903919905034526, NumEpochs=185, Layers=(100, 100), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2901127142709879, NumEpochs=195, Layers=(100, 75, 75), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.290035032807076, NumEpochs=167, Layers=(100, 50, 50), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2897843546177016, NumEpochs=174, Layers=(100, 25, 25), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28971261123098235, NumEpochs=200, Layers=(100, 100, 100), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28970961006671064, NumEpochs=87, Layers=(25,), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2896912689256792, NumEpochs=199, Layers=(100,), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28967368989867326, NumEpochs=131, Layers=(50,), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2895302138376736, NumEpochs=199, Layers=(25,), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2894430210908701, NumEpochs=95, Layers=(100, 100), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28919481597871877, NumEpochs=200, Layers=(25,), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2891589248084606, NumEpochs=200, Layers=(75,), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2891311134468025, NumEpochs=199, Layers=(100, 100, 100), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28902967759697, NumEpochs=148, Layers=(100, 25, 25), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2889656207141769, NumEpochs=108, Layers=(75,), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2888825868081962, NumEpochs=190, Layers=(75,), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28885140089478295, NumEpochs=200, Layers=(), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28882128410342134, NumEpochs=154, Layers=(50,), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2886802017094327, NumEpochs=85, Layers=(100,), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28842479232118184, NumEpochs=199, Layers=(100, 75), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2883820156469059, NumEpochs=195, Layers=(25,), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2883584918655722, NumEpochs=200, Layers=(75,), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2882250718981777, NumEpochs=200, Layers=(), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28807133910127836, NumEpochs=200, Layers=(), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28776013895128266, NumEpochs=138, Layers=(50,), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28760135368695544, NumEpochs=133, Layers=(100, 100, 25), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2875748648554637, NumEpochs=137, Layers=(100, 50, 50), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2875595226339283, NumEpochs=138, Layers=(100, 75, 50), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2874920321235159, NumEpochs=187, Layers=(100, 50, 50), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2873249406092934, NumEpochs=200, Layers=(100,), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2872505787196264, NumEpochs=117, Layers=(100, 100, 50), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2872145981871874, NumEpochs=88, Layers=(100, 50), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28718766650677907, NumEpochs=154, Layers=(100, 50, 25), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.287119812259312, NumEpochs=159, Layers=(100, 100, 100), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28709176899409766, NumEpochs=124, Layers=(100, 75, 75), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28704392258797956, NumEpochs=138, Layers=(100, 75, 75), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2870112609614075, NumEpochs=200, Layers=(), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2869675004718936, NumEpochs=200, Layers=(25,), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28688668996532757, NumEpochs=172, Layers=(100, 100, 75), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2866222220207056, NumEpochs=163, Layers=(100, 100), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.286417414821136, NumEpochs=199, Layers=(100,), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2860009364264516, NumEpochs=200, Layers=(), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28599870288803364, NumEpochs=164, Layers=(100, 100, 75), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2859342214312588, NumEpochs=200, Layers=(), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2859120295359068, NumEpochs=182, Layers=(100, 100, 75), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2859094711478082, NumEpochs=200, Layers=(100, 50), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2857982444487699, NumEpochs=123, Layers=(100, 75, 25), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28564814338775035, NumEpochs=101, Layers=(100,), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2855538999966372, NumEpochs=200, Layers=(), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2855391158236458, NumEpochs=176, Layers=(50,), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28540054911458596, NumEpochs=116, Layers=(100,), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28536472168059807, NumEpochs=89, Layers=(100, 25, 25), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2849622598874191, NumEpochs=198, Layers=(100, 100, 25), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2849318843144597, NumEpochs=178, Layers=(100, 25), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2848336459339889, NumEpochs=68, Layers=(100, 75, 75), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2846631189502018, NumEpochs=110, Layers=(100, 25, 25), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28450420735008997, NumEpochs=151, Layers=(75,), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.284347341328517, NumEpochs=119, Layers=(75,), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.284304904989693, NumEpochs=188, Layers=(100, 75, 50), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28408109158869044, NumEpochs=175, Layers=(100, 75, 75), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28400633707287265, NumEpochs=85, Layers=(100, 75, 25), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2839919772290898, NumEpochs=200, Layers=(50,), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28376101887546046, NumEpochs=94, Layers=(100, 50, 25), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28362455467995684, NumEpochs=102, Layers=(25,), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2833963710282882, NumEpochs=200, Layers=(100, 75, 50), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2830470359911722, NumEpochs=200, Layers=(50,), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2827994975816811, NumEpochs=60, Layers=(100, 100, 75), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28272104287666605, NumEpochs=67, Layers=(100,), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2825938929665822, NumEpochs=200, Layers=(50,), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28251553734214263, NumEpochs=102, Layers=(25,), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28242195966757927, NumEpochs=191, Layers=(50,), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2823693407276205, NumEpochs=139, Layers=(100, 75, 50), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28236140438474727, NumEpochs=104, Layers=(100, 75), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28211538960154214, NumEpochs=136, Layers=(100, 25, 25), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2820851580049851, NumEpochs=179, Layers=(100, 50, 25), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28204189990317446, NumEpochs=73, Layers=(100, 75), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.282034898316176, NumEpochs=140, Layers=(25,), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2819567625478343, NumEpochs=200, Layers=(), LR=0.001, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.28183089721120275, NumEpochs=61, Layers=(100, 25, 25), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2817765532855406, NumEpochs=200, Layers=(75,), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2817241594220118, NumEpochs=75, Layers=(100, 75), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2816802837151265, NumEpochs=95, Layers=(50,), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2814533949656334, NumEpochs=173, Layers=(100, 75, 75), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28143951104778275, NumEpochs=199, Layers=(100, 100, 50), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28130623542309086, NumEpochs=63, Layers=(100, 100, 25), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2811858608160359, NumEpochs=83, Layers=(100, 50, 25), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28105530234822496, NumEpochs=200, Layers=(), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.28091874474750295, NumEpochs=200, Layers=(), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2808766808871344, NumEpochs=200, Layers=(), LR=0.003, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2804777311915576, NumEpochs=121, Layers=(100, 25, 25), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2804130511276762, NumEpochs=67, Layers=(100, 75), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.28037652676839314, NumEpochs=200, Layers=(100, 25), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.280338151982088, NumEpochs=184, Layers=(100, 100, 50), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2803170856115924, NumEpochs=68, Layers=(100, 100, 50), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2802649517544417, NumEpochs=131, Layers=(100, 50, 25), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2800837654806712, NumEpochs=72, Layers=(100, 25, 25), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27976588394132074, NumEpochs=121, Layers=(100, 100, 25), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2794307358371012, NumEpochs=75, Layers=(100, 75, 50), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27942709048328895, NumEpochs=120, Layers=(100, 50, 50), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2793467246894504, NumEpochs=83, Layers=(100, 50, 50), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2792837472647055, NumEpochs=109, Layers=(25,), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2792729004307802, NumEpochs=163, Layers=(100, 50), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27923221024446093, NumEpochs=123, Layers=(100, 100, 100), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2791819259820171, NumEpochs=192, Layers=(50,), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2791227637609148, NumEpochs=102, Layers=(100, 100, 50), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2789631559081635, NumEpochs=44, Layers=(100, 75, 50), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27868657316344575, NumEpochs=61, Layers=(100, 100, 50), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2785091047259626, NumEpochs=197, Layers=(25,), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2784939383939364, NumEpochs=91, Layers=(100, 25), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27847668501403605, NumEpochs=200, Layers=(), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2784518894986238, NumEpochs=199, Layers=(100, 100, 75), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27841771800682935, NumEpochs=168, Layers=(100,), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2783011030582417, NumEpochs=101, Layers=(100, 75, 50), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27803646425128553, NumEpochs=63, Layers=(100, 75), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27781044921088893, NumEpochs=54, Layers=(100, 50, 50), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2771835655853804, NumEpochs=63, Layers=(100, 100, 75), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2771428830595677, NumEpochs=135, Layers=(100, 100, 75), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27704520388701004, NumEpochs=45, Layers=(100, 25), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2768017245430395, NumEpochs=109, Layers=(100, 100, 25), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27677685331344054, NumEpochs=142, Layers=(100, 75, 25), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27671555693911737, NumEpochs=200, Layers=(), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27666203107307824, NumEpochs=144, Layers=(100, 100, 50), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.276655997244485, NumEpochs=72, Layers=(100, 75, 75), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2766211485811319, NumEpochs=138, Layers=(100, 75, 50), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27637598487851484, NumEpochs=83, Layers=(100, 25), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2763446677831702, NumEpochs=68, Layers=(50,), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27616505471327263, NumEpochs=187, Layers=(100, 100, 25), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27609699584193437, NumEpochs=131, Layers=(100, 25), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2759806988625327, NumEpochs=123, Layers=(100, 25, 25), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2758637144391603, NumEpochs=67, Layers=(100, 100), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2757499018895719, NumEpochs=122, Layers=(75,), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2756274194407922, NumEpochs=74, Layers=(100, 50, 50), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2756007224687517, NumEpochs=61, Layers=(100, 25, 25), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2755416067717938, NumEpochs=63, Layers=(100, 100), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27550778591688685, NumEpochs=42, Layers=(100, 50), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27548850356337906, NumEpochs=101, Layers=(100, 75, 25), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27495971657392354, NumEpochs=50, Layers=(100, 100, 100), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2747001972840205, NumEpochs=200, Layers=(50,), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2746834380896651, NumEpochs=110, Layers=(100, 50, 25), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27437957277322084, NumEpochs=77, Layers=(100, 50), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2743147813559379, NumEpochs=200, Layers=(), LR=0.003, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2741912850708949, NumEpochs=200, Layers=(), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27412383938701423, NumEpochs=191, Layers=(100, 100), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2741111477663866, NumEpochs=73, Layers=(100, 100, 25), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2740664847372465, NumEpochs=62, Layers=(100, 100), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27359330396902803, NumEpochs=79, Layers=(100, 50, 50), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2735753291451884, NumEpochs=200, Layers=(100, 100, 100), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27357372495649546, NumEpochs=178, Layers=(100, 50, 50), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2734521090723479, NumEpochs=43, Layers=(100, 100, 75), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2733442558602003, NumEpochs=67, Layers=(100, 75, 50), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.273314510238957, NumEpochs=46, Layers=(100, 50, 25), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27312493022074813, NumEpochs=176, Layers=(100, 50, 50), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2731071992377257, NumEpochs=116, Layers=(100,), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2730277695427651, NumEpochs=78, Layers=(100, 75, 25), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27300337281506365, NumEpochs=62, Layers=(100, 50), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2725679394044081, NumEpochs=48, Layers=(100, 75, 75), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27252334382361443, NumEpochs=64, Layers=(100, 75, 25), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.27247985687993126, NumEpochs=49, Layers=(100, 75, 25), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2723193991748301, NumEpochs=200, Layers=(100, 50, 25), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2721583788197788, NumEpochs=182, Layers=(100, 100, 25), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2720628769245214, NumEpochs=47, Layers=(100, 50, 50), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2719717853150056, NumEpochs=173, Layers=(100, 100), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2718596955459009, NumEpochs=45, Layers=(100, 100, 50), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2717155971259742, NumEpochs=199, Layers=(100, 100, 75), LR=0.01, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2715942942580975, NumEpochs=50, Layers=(100, 75), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2714828802504253, NumEpochs=159, Layers=(100, 25, 25), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.27142396062636603, NumEpochs=49, Layers=(100, 25), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2713661853923833, NumEpochs=55, Layers=(100, 100), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.27098765159902494, NumEpochs=163, Layers=(100, 75), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2702557529373012, NumEpochs=54, Layers=(100, 100, 25), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2702382236919746, NumEpochs=170, Layers=(100, 100, 100), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2698781264070087, NumEpochs=122, Layers=(100, 50), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2692707031840055, NumEpochs=62, Layers=(75,), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2685178913584547, NumEpochs=181, Layers=(100, 75), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26795696733218166, NumEpochs=69, Layers=(100, 100, 100), LR=0.001, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2675351863539133, NumEpochs=51, Layers=(100, 100, 100), LR=0.001, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2671838613370639, NumEpochs=170, Layers=(100, 50, 25), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.26687474362986335, NumEpochs=48, Layers=(100, 100, 25), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2667764054193849, NumEpochs=43, Layers=(100, 100, 50), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2665049989624473, NumEpochs=65, Layers=(100, 25), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2661932976443531, NumEpochs=52, Layers=(100, 75, 75), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26616334474848413, NumEpochs=172, Layers=(100, 75, 50), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.26567805789643995, NumEpochs=200, Layers=(100, 25), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.26536990248182446, NumEpochs=52, Layers=(100, 100, 25), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.26491160754434373, NumEpochs=73, Layers=(100, 50, 25), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.26481193171391165, NumEpochs=41, Layers=(100, 75, 25), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26448027693877396, NumEpochs=43, Layers=(100, 75, 50), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26408996754554465, NumEpochs=55, Layers=(100, 75, 75), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2640405679041724, NumEpochs=52, Layers=(100, 50, 25), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26390257698829883, NumEpochs=41, Layers=(100, 50, 25), LR=0.003, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2635618285834192, NumEpochs=51, Layers=(100, 25, 25), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2634336468563384, NumEpochs=46, Layers=(100, 100, 75), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.2626763274588418, NumEpochs=76, Layers=(100, 50), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2625341499778508, NumEpochs=46, Layers=(100, 100, 100), LR=0.003, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26224449315284504, NumEpochs=200, Layers=(100,), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.26224130871432827, NumEpochs=67, Layers=(100, 25, 25), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2620356128524084, NumEpochs=200, Layers=(75,), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.26201559310731465, NumEpochs=76, Layers=(100, 50), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.26150139858182575, NumEpochs=160, Layers=(100, 25, 25), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2605401921221696, NumEpochs=38, Layers=(100, 100, 100), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2595292826256175, NumEpochs=182, Layers=(100, 100, 50), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.25749815584139824, NumEpochs=66, Layers=(100, 75, 25), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.25715114845741693, NumEpochs=197, Layers=(100, 100, 100), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.25691989396605547, NumEpochs=140, Layers=(100, 75, 75), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.2554773775022402, NumEpochs=50, Layers=(100, 50, 50), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.25527890923328095, NumEpochs=54, Layers=(100, 100, 75), LR=0.01, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.255254644672678, NumEpochs=200, Layers=(100, 100), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.25387922977027777, NumEpochs=119, Layers=(50,), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.25339859724754116, NumEpochs=138, Layers=(100, 75), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.25264694275524036, NumEpochs=200, Layers=(50,), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.24817533097003092, NumEpochs=190, Layers=(100, 75, 75), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.24701259477866977, NumEpochs=54, Layers=(100, 100, 75), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.24693667513489684, NumEpochs=200, Layers=(100, 75, 25), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2455469626805747, NumEpochs=197, Layers=(100, 50), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.24417410785578195, NumEpochs=194, Layers=(100, 75, 50), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.24241734240509502, NumEpochs=154, Layers=(50,), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.24217981830711247, NumEpochs=57, Layers=(100, 50, 50), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.23523961861653547, NumEpochs=200, Layers=(100, 75), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.21851519721477744, NumEpochs=200, Layers=(100, 100), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.21520024980436347, NumEpochs=38, Layers=(100, 50), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.21505708799488685, NumEpochs=189, Layers=(100, 75, 50), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.20714913466917836, NumEpochs=200, Layers=(100, 100, 25), LR=0.001, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.2044490583737785, NumEpochs=200, Layers=(100, 100, 25), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.194652959023591, NumEpochs=199, Layers=(100, 100, 50), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.19227197442750016, NumEpochs=200, Layers=(100, 100), LR=0.01, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.18087049976270508, NumEpochs=187, Layers=(100, 50, 25), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.17648976108221093, NumEpochs=61, Layers=(100, 100, 100), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.1730026679025851, NumEpochs=200, Layers=(100, 25), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.17095820027624245, NumEpochs=195, Layers=(25,), LR=0.01, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.17003363706576094, NumEpochs=26, Layers=(100, 75, 50), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.16686106447171087, NumEpochs=55, Layers=(100, 75, 75), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.15048299981554863, NumEpochs=123, Layers=(75,), LR=0.03, NonLin=<function leaky_relu at 0x7f334da8b950>),\n",
            " OptimalConfig(Pearson=0.1454691479484813, NumEpochs=140, Layers=(100, 75, 25), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.13225981544827944, NumEpochs=168, Layers=(100, 100, 50), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.08668454944557942, NumEpochs=5, Layers=(100, 100, 100), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.08325908424119058, NumEpochs=186, Layers=(100, 75), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.07487745462099712, NumEpochs=51, Layers=(100, 75, 75), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.07353031030884867, NumEpochs=41, Layers=(25,), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.0693454922183015, NumEpochs=21, Layers=(100, 100, 75), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.06781484874426731, NumEpochs=200, Layers=(75,), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.057018361813945276, NumEpochs=10, Layers=(100, 25), LR=0.03, NonLin=<function relu at 0x7f334da8b598>),\n",
            " OptimalConfig(Pearson=0.05432172159507307, NumEpochs=200, Layers=(25,), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.052313131858380886, NumEpochs=1, Layers=(100, 100, 25), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.05082435939516899, NumEpochs=161, Layers=(100, 25, 25), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.04871032948562512, NumEpochs=104, Layers=(100, 50), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.03564108835797456, NumEpochs=155, Layers=(100, 100), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.03456417920106858, NumEpochs=82, Layers=(100, 100, 75), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.030137751394287874, NumEpochs=4, Layers=(100, 50, 50), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.02923895498605772, NumEpochs=200, Layers=(100, 75, 25), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.02355835334742096, NumEpochs=2, Layers=(100, 25), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.02027895010554185, NumEpochs=2, Layers=(100, 75, 25), LR=0.03, NonLin=<built-in method sigmoid of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.0201158533612958, NumEpochs=87, Layers=(100, 50, 25), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>),\n",
            " OptimalConfig(Pearson=0.0011667468938153507, NumEpochs=2, Layers=(100, 100, 50), LR=0.03, NonLin=<built-in method tanh of type object at 0x7f3399e57860>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUm6vRaylktd",
        "colab_type": "code",
        "outputId": "0c06bead-1f64-4a9b-d8af-8d15ed41b30b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "_, num_epochs, layers, lr, fn = results[0]\n",
        "\n",
        "final_regressor = FFNNRegression(*layers, nonlin=fn)\n",
        "final_regressor.load_state_dict(torch.load('100-75-75_lr=0-001_nonlin=tanh.pt'))\n",
        "print(final_regressor)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNNRegression(\n",
            "  (hidden_0): Linear(in_features=768, out_features=100, bias=True)\n",
            "  (hidden_1): Linear(in_features=100, out_features=75, bias=True)\n",
            "  (hidden_2): Linear(in_features=75, out_features=75, bias=True)\n",
            "  (out): Linear(in_features=75, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EPS1cG9pzfQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_predictions = final_regressor(test_embeddings_tensor).squeeze()\n",
        "with open('predictions.txt', 'w') as f:\n",
        "    for pred in test_predictions:\n",
        "        f.write(f'{pred}\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F94yQV2HkmyX",
        "colab_type": "text"
      },
      "source": [
        "### Other"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zrSFbr_SvM6",
        "colab_type": "code",
        "outputId": "d391318a-6885-4d8a-dbe7-899e2929b78c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "BERT_PRETRAINED_MODEL = 'bert-base-multilingual-cased'\n",
        "\n",
        "# Load tokenizer\n",
        "print(f'Loading tokenizer <{BERT_PRETRAINED_MODEL}>...', end=' ')\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_MODEL,\n",
        "                                          do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "# Check tokenizer\n",
        "sample_sent_id = 42\n",
        "\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_zh[sample_sent_id]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading tokenizer <bert-base-multilingual-cased>... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 995526/995526 [00:00<00:00, 2564866.59B/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "done!\n",
            "\n",
            "English\n",
            "All 6 of the artillerymen recorded as wounded died).\n",
            "\n",
            "['All', '6', 'of', 'the', 'artillery', '##men', 'recorded', 'as', 'wounded', 'died', ')', '.']\n",
            "\n",
            "Chinese\n",
            "据记录 ， 所有 6 名炮兵都受伤了) 。\n",
            "\n",
            "['据', '记', '录', '，', '所', '有', '6', '名', '炮', '兵', '都', '受', '伤', '了', ')', '。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnhlGJz8klTp",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwHlUgIdYbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_mini_batches(inputs, scores, *, batch_size=8):\n",
        "\n",
        "    idxs = np.arange(len(inputs))\n",
        "    np.random.shuffle(idxs)\n",
        "\n",
        "    num_batches = math.ceil(len(inputs) / batch_size)\n",
        "\n",
        "    for batch_id in range(num_batches):\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        yield inputs[idxs[start_id:end_id]], scores[idxs[start_id:end_id]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-yHLtLaRuK7",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4aXOvi_blZ7",
        "colab_type": "code",
        "outputId": "f962364c-8226-4e49-cf02-f0b4cae021d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        }
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "print(torch.cuda.memory_summary(device=device))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |  696405 KB |    9052 MB |    3207 GB |    3206 GB |\n",
            "|       from large pool |  694528 KB |    9051 MB |    3167 GB |    3167 GB |\n",
            "|       from small pool |    1877 KB |       3 MB |      39 GB |      39 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |  696405 KB |    9052 MB |    3207 GB |    3206 GB |\n",
            "|       from large pool |  694528 KB |    9051 MB |    3167 GB |    3167 GB |\n",
            "|       from small pool |    1877 KB |       3 MB |      39 GB |      39 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |  751616 KB |    9296 MB |    9296 MB |    8562 MB |\n",
            "|       from large pool |  749568 KB |    9292 MB |    9292 MB |    8560 MB |\n",
            "|       from small pool |    2048 KB |       4 MB |       4 MB |       2 MB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |   55211 KB |    1001 MB |    1914 GB |    1914 GB |\n",
            "|       from large pool |   55040 KB |    1000 MB |    1819 GB |    1819 GB |\n",
            "|       from small pool |     171 KB |       2 MB |      95 GB |      95 GB |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |     251    |     801    |    1769 K  |    1769 K  |\n",
            "|       from large pool |      75    |     616    |     231 K  |     231 K  |\n",
            "|       from small pool |     176    |     195    |    1538 K  |    1537 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |     251    |     801    |    1769 K  |    1769 K  |\n",
            "|       from large pool |      75    |     616    |     231 K  |     231 K  |\n",
            "|       from small pool |     176    |     195    |    1538 K  |    1537 K  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |      21    |     329    |     329    |     308    |\n",
            "|       from large pool |      20    |     327    |     327    |     307    |\n",
            "|       from small pool |       1    |       2    |       2    |       1    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |      24    |     169    |     862 K  |     862 K  |\n",
            "|       from large pool |      19    |     156    |     179 K  |     179 K  |\n",
            "|       from small pool |       5    |      14    |     683 K  |     683 K  |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzJ3LQfVXMcr",
        "colab_type": "text"
      },
      "source": [
        "### BERT fine-tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlJHziqpRwT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig(vocab_size_or_config_json_file=30522)\n",
        "\n",
        "class BertForQE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained(BERT_PRETRAINED_MODEL)\n",
        "        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        self.out = nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        _, pooled_output = self.bert(input_ids)\n",
        "        # pooled = self.dropout(pooled_output)\n",
        "        score = self.out(pooled_output)\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRC6uyOgUOM",
        "colab_type": "code",
        "outputId": "32f885f9-0312-489e-ac80-a34470e1ca0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = BertForQE()\n",
        "print(model)\n",
        "\n",
        "LR = 0.001\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# optimiser = BertAdam(model.parameters(), lr=LR, schedule='warmup_linear', warmup=0.1, t_total=1000)\n",
        "\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertForQE(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): BertLayerNorm()\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): BertLayerNorm()\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (out): Linear(in_features=768, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCGWXTLNZ0tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(model, loss_fn, optimiser, input_ids, scores):\n",
        "    model.train()\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    predictions = model(input_ids.to(device)).squeeze()\n",
        "    \n",
        "    loss = loss_fn(predictions, torch.Tensor(scores).to(device))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train(model, loss_fn, optimiser, train_inputs, train_scores, val_inputs, val_scores, *, num_epochs=10, batch_size=32):\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        print(f'Epoch #{epoch_idx + 1}')\n",
        "\n",
        "        model.to(device)\n",
        "        \n",
        "        processed = 0\n",
        "        increment = 0.05\n",
        "        milestone = 0.05\n",
        "        print('Training', end='')\n",
        "        for input_ids, scores in get_mini_batches(train_inputs, train_scores, batch_size=batch_size):\n",
        "            loss = gradient_descent(model, loss_fn, optimiser, input_ids, scores)\n",
        "            processed += len(input_ids)\n",
        "\n",
        "            if processed / len(train_inputs) >= milestone:\n",
        "                print('.', end='')\n",
        "                milestone += increment\n",
        "        print('done!')\n",
        "        print('Recent loss', loss)\n",
        "\n",
        "        # Check validation loss\n",
        "        model.eval()\n",
        "        model.to('cpu')\n",
        "\n",
        "        print('Getting validation predictions...', end='')\n",
        "        val_preds = model(val_inputs[:50]).squeeze().detach()\n",
        "        print(f'done! {val_preds[1]},{val_preds[3]},...{val_preds[-1]}')\n",
        "        val_loss = loss_fn(val_preds, torch.Tensor(val_scores[:50]))\n",
        "        print('Validation loss', val_loss)\n",
        "\n",
        "        pearson, _ = pearsonr(val_preds.numpy(), np.array(val_scores[:50]))\n",
        "        print('Validation Pearson', pearson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSoCgQ7YmKvW",
        "colab_type": "code",
        "outputId": "226c1713-ee27-444c-8f9c-0f622c063cb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        }
      },
      "source": [
        "train(model, loss_fn, optimiser, train_inputs[:1000], train_scores[:1000], val_inputs, val_scores, batch_size=8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "Training...................done!\n",
            "Recent loss tensor(1.0798, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.4001631736755371,0.40016311407089233,...0.4001631736755371\n",
            "Validation loss tensor(0.7833)\n",
            "Validation Pearson -0.11256493147018685\n",
            "Epoch #2\n",
            "Training...................done!\n",
            "Recent loss tensor(1.0776, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.3445858359336853,0.3445858359336853,...0.3445858359336853\n",
            "Validation loss tensor(0.7661)\n",
            "Validation Pearson nan\n",
            "Epoch #3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training.."
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-18b2624ac773>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-aa7a4b700081>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loss_fn, optimiser, train_inputs, train_scores, val_inputs, val_scores, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_mini_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimiser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mprocessed\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-50-aa7a4b700081>\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(model, loss_fn, optimiser, input_ids, scores)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQJ06kXdK-qc",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZU6c-b6Lgp1",
        "colab_type": "text"
      },
      "source": [
        "### English\n",
        "\n",
        "1. Tokenise with spaCy language model\n",
        "2. Remove stop words and punctuation\n",
        "3. Normalise - lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYS01soSJ8DP",
        "colab_type": "code",
        "outputId": "11dbb763-1100-40f7-b603-d45194c5c7a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Downloading spacy models for English\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300 --force"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 78.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=23895519225c05941575a08fb0e866165e23bab8626baa761c44bbd91c99504b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-7ik_891b/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysk8sSgwOMNJ",
        "colab_type": "code",
        "outputId": "4cb0d399-305f-4a9a-f286-c171e1ed8e4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Downloading stop words for English\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download('stopwords')\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFh-oANJOv9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp_en = spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh5Bst_uRXzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_en(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        text = sentence.lower()\n",
        "        processed = [token.lemma_ for token in nlp_en.tokenizer(text)]\n",
        "        processed = [token for token in processed if token.isalpha()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_en]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UsvjK3mMGEW",
        "colab_type": "text"
      },
      "source": [
        "### Chinese\n",
        "\n",
        "1. Tokenise with jieba\n",
        "2. Remove stop words and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaaRTU3XMPmA",
        "colab_type": "code",
        "outputId": "8b1e1efd-cb51-4c0c-d5e9-9fd4a72da2df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        "# Download stop words\n",
        "FILE_STOP_WORDS_ZH = './chinese_stop_words.txt'\n",
        "\n",
        "if not os.path.exists(FILE_STOP_WORDS_ZH):\n",
        "    !wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "with open(FILE_STOP_WORDS_ZH, 'r', encoding='utf-8') as f:\n",
        "    stop_words_zh = [line.rstrip() for line in f]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-17 10:41:47--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 140.82.118.3\n",
            "Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "\rchinese_stop_words.     [<=>                 ]       0  --.-KB/s               \rchinese_stop_words.     [ <=>                ] 416.75K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2020-02-17 10:41:47 (17.8 MB/s) - ‘chinese_stop_words.txt’ saved [426748]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmS0Q6fOUO2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "\n",
        "def preprocess_zh(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        tokens = jieba.cut(sentence, cut_all=True)\n",
        "        processed = [token for token in tokens if token.isalnum()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meeee7ttmJD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn3Ar3-6MZWV",
        "colab_type": "text"
      },
      "source": [
        "## Language Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPvP2XYMr5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Language(object):\n",
        "\n",
        "    SOS_TOKEN = '<SOS>'\n",
        "    EOS_TOKEN = '<EOS>'\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.word2count = {}\n",
        "        self.idx2word = {0: self.SOS_TOKEN,\n",
        "                         1: self.EOS_TOKEN,\n",
        "                         2: self.UNK_TOKEN}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for token in sentence:\n",
        "            self.add_word(token)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            idx = len(self)\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "        \n",
        "        count = self.word2count.get(word, 0)\n",
        "        self.word2count[word] = count + 1\n",
        "\n",
        "    def sent_to_idxs(self, sent):\n",
        "        return [self.word2idx.get(word, 2) for word in sent]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f'Language(name={self.name}) with {len(self)} words'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZWJs-CQMIb",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aaR6q37RMsO",
        "colab_type": "code",
        "outputId": "501a8e94-04f1-4e92-ca4b-b5b6bc0453f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# English data\n",
        "\n",
        "preprocess_english = preprocess_en(keep_stopwords=True)\n",
        "\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "EN = Language('EN')\n",
        "for sent in train_en_sents:\n",
        "    EN.add_sentence(sent)\n",
        "\n",
        "print(EN)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_en = train_en_sents[42]\n",
        "print(sample_sent_en)\n",
        "print(EN.sent_to_idxs(sample_sent_en))\n",
        "\n",
        "train_en_idxs = [EN.sent_to_idxs(sent) for sent in train_en_sents]\n",
        "val_en_idxs = [EN.sent_to_idxs(sent) for sent in val_en_sents]\n",
        "test_en_idxs = [EN.sent_to_idxs(sent) for sent in test_en_sents]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language(name=EN) with 19248 words\n",
            "\n",
            "Sample sentence\n",
            "['all', 'of', 'the', 'artilleryman', 'record', 'a', 'wound', 'die']\n",
            "[340, 31, 3, 341, 342, 59, 343, 344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEZK9El_U9v3",
        "outputId": "5de6464f-c983-4f7e-f988-5340ccca075e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Chinese data\n",
        "\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=True)\n",
        "\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "ZH = Language('ZH')\n",
        "for sent in train_zh_sents:\n",
        "    ZH.add_sentence(sent)\n",
        "\n",
        "print(ZH)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_zh = train_zh_sents[42]\n",
        "print(sample_sent_zh)\n",
        "print(ZH.sent_to_idxs(sample_sent_zh))\n",
        "\n",
        "train_zh_idxs = [ZH.sent_to_idxs(sent) for sent in train_zh_sents]\n",
        "val_zh_idxs = [ZH.sent_to_idxs(sent) for sent in val_zh_sents]\n",
        "test_zh_idxs = [ZH.sent_to_idxs(sent) for sent in test_zh_sents]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.921 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Language(name=ZH) with 23851 words\n",
            "\n",
            "Sample sentence\n",
            "['据', '记录', '所有', '6', '名', '炮兵', '都', '受伤', '了']\n",
            "[483, 484, 485, 267, 486, 487, 488, 489, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCR41KviW6Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process scores\n",
        "\n",
        "def prepare_score(score):\n",
        "    return float(score)\n",
        "\n",
        "train_scores = [prepare_score(score) for score in train_scores]\n",
        "val_scores = [prepare_score(score) for score in val_scores]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qYQlzaEWViN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasets\n",
        "\n",
        "train_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_en_idxs]\n",
        "train_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_zh_idxs]\n",
        "\n",
        "train_pairs = list(zip(train_en_tensors, train_zh_tensors))\n",
        "train_set = list(zip(train_pairs, train_scores))\n",
        "\n",
        "val_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_en_idxs]\n",
        "val_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_zh_idxs]\n",
        "\n",
        "val_pairs = list(zip(val_en_tensors, val_zh_tensors))\n",
        "val_set = list(zip(val_pairs, val_scores))\n",
        "\n",
        "test_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in test_en_idxs]\n",
        "test_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in test_zh_idxs]\n",
        "\n",
        "test_pairs = list(zip(test_en_tensors, test_zh_tensors))\n",
        "\n",
        "\n",
        "# val_pairs = list(zip(val_en_idxs, val_zh_idxs))\n",
        "# test_pairs = list(zip(test_en_idxs, test_zh_idxs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBU5dUInLx-R",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtsfA_hdPmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def unzip(args):\n",
        "    return zip(*args)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFiF4FSRlCx",
        "colab_type": "text"
      },
      "source": [
        "### FFNN with trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oWCA9Mdbbta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_hidden = nn.Linear(self.emb_dim, 1)\n",
        "        self.zh_hidden = nn.Linear(self.emb_dim, 1)\n",
        "\n",
        "        self.out = nn.Linear(2, 1)\n",
        "    \n",
        "    def forward(self, en_tensors, zh_tensors):\n",
        "        en_emb = self.en_embedding(en_tensors)\n",
        "        zh_emb = self.zh_embedding(zh_tensors)\n",
        "\n",
        "        en_hid = F.relu(self.en_hidden(en_emb))\n",
        "        zh_hid = F.relu(self.zh_hidden(en_emb))\n",
        "\n",
        "        hid_concat = torch.stack((en_hid, zh_hid), axis=1).squeeze()\n",
        "        score = self.out(hid_concat)\n",
        "        return score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1SoBa5csKg",
        "colab_type": "code",
        "outputId": "6fb3fc7f-8e45-494d-bc20-ec352a0efeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "ffnn = FFNN(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=200)\n",
        "ffnn.to(device)\n",
        "print(ffnn)\n",
        "\n",
        "ffnn_opt = torch.optim.Adam(ffnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (en_embedding): Embedding(19248, 200)\n",
            "  (zh_embedding): Embedding(23851, 200)\n",
            "  (en_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (zh_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (out): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9MTNFHdTJ4",
        "colab_type": "code",
        "outputId": "9914e71c-2679-4927-a496-bec543c87efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "NUM_EPOCHS = 100\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_pearson = []\n",
        "\n",
        "for eidx in range(NUM_EPOCHS):\n",
        "    print(f'Epoch {eidx + 1}: \\t', end=' ')\n",
        "    ffnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        loss += loss_fn(pred, score)\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    train_losses.append(loss)\n",
        "    \n",
        "    print(f'train loss = {loss:.5f}\\t', end='')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    for (en_tensor, zh_tensor), score in val_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'validation loss = {val_loss:.5f}\\t', end='')\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(ffnn(en_tensor.to(device), zh_tensor.to(device)).detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    \n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    val_pearson.append(pearson_score)\n",
        "    print(f'validation pearson = {pearson_score:.5f}\\t')\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    ffnn_opt.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: \t train loss = 0.87688\tvalidation loss = 0.88592\tvalidation pearson = 0.01748\t\n",
            "Epoch 2: \t train loss = 0.86025\tvalidation loss = 0.87088\tvalidation pearson = 0.02019\t\n",
            "Epoch 3: \t train loss = 0.84733\tvalidation loss = 0.85943\tvalidation pearson = 0.01939\t\n",
            "Epoch 4: \t train loss = 0.83801\tvalidation loss = 0.85154\tvalidation pearson = 0.02470\t\n",
            "Epoch 5: \t train loss = 0.82957\tvalidation loss = 0.84433\tvalidation pearson = 0.03254\t\n",
            "Epoch 6: \t train loss = 0.82264\tvalidation loss = 0.83841\tvalidation pearson = 0.03838\t\n",
            "Epoch 7: \t train loss = 0.81701\tvalidation loss = 0.83367\tvalidation pearson = 0.04050\t\n",
            "Epoch 8: \t train loss = 0.81212\tvalidation loss = 0.82953\tvalidation pearson = 0.04263\t\n",
            "Epoch 9: \t train loss = 0.80755\tvalidation loss = 0.82555\tvalidation pearson = 0.04476\t\n",
            "Epoch 10: \t train loss = 0.80332\tvalidation loss = 0.82175\tvalidation pearson = 0.04683\t\n",
            "Epoch 11: \t train loss = 0.79937\tvalidation loss = 0.81817\tvalidation pearson = 0.04816\t\n",
            "Epoch 12: \t train loss = 0.79570\tvalidation loss = 0.81483\tvalidation pearson = 0.04975\t\n",
            "Epoch 13: \t train loss = 0.79230\tvalidation loss = 0.81172\tvalidation pearson = 0.05156\t\n",
            "Epoch 14: \t train loss = 0.78910\tvalidation loss = 0.80876\tvalidation pearson = 0.05291\t\n",
            "Epoch 15: \t train loss = 0.78611\tvalidation loss = 0.80595\tvalidation pearson = 0.05509\t\n",
            "Epoch 16: \t train loss = 0.78332\tvalidation loss = 0.80328\tvalidation pearson = 0.05735\t\n",
            "Epoch 17: \t train loss = 0.78071\tvalidation loss = 0.80075\tvalidation pearson = 0.05934\t\n",
            "Epoch 18: \t train loss = 0.77822\tvalidation loss = 0.79836\tvalidation pearson = 0.06081\t\n",
            "Epoch 19: \t train loss = 0.77587\tvalidation loss = 0.79610\tvalidation pearson = 0.06205\t\n",
            "Epoch 20: \t train loss = 0.77364\tvalidation loss = 0.79395\tvalidation pearson = 0.06280\t\n",
            "Epoch 21: \t train loss = 0.77155\tvalidation loss = 0.79191\tvalidation pearson = 0.06318\t\n",
            "Epoch 22: \t train loss = 0.76956\tvalidation loss = 0.78997\tvalidation pearson = 0.06354\t\n",
            "Epoch 23: \t train loss = 0.76765\tvalidation loss = 0.78811\tvalidation pearson = 0.06419\t\n",
            "Epoch 24: \t train loss = 0.76582\tvalidation loss = 0.78636\tvalidation pearson = 0.06420\t\n",
            "Epoch 25: \t train loss = 0.76406\tvalidation loss = 0.78469\tvalidation pearson = 0.06371\t\n",
            "Epoch 26: \t train loss = 0.76236\tvalidation loss = 0.78310\tvalidation pearson = 0.06218\t\n",
            "Epoch 27: \t train loss = 0.76072\tvalidation loss = 0.78159\tvalidation pearson = 0.06035\t\n",
            "Epoch 28: \t train loss = 0.75912\tvalidation loss = 0.78014\tvalidation pearson = 0.05821\t\n",
            "Epoch 29: \t train loss = 0.75758\tvalidation loss = 0.77875\tvalidation pearson = 0.05548\t\n",
            "Epoch 30: \t train loss = 0.75608\tvalidation loss = 0.77741\tvalidation pearson = 0.05306\t\n",
            "Epoch 31: \t train loss = 0.75461\tvalidation loss = 0.77611\tvalidation pearson = 0.05023\t\n",
            "Epoch 32: \t train loss = 0.75317\tvalidation loss = 0.77483\tvalidation pearson = 0.04724\t\n",
            "Epoch 33: \t train loss = 0.75175\tvalidation loss = 0.77359\tvalidation pearson = 0.04478\t\n",
            "Epoch 34: \t train loss = 0.75036\tvalidation loss = 0.77236\tvalidation pearson = 0.04302\t\n",
            "Epoch 35: \t "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUlPsvWsL4mp",
        "colab_type": "text"
      },
      "source": [
        "### RNN Chain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UkdfLZMoI5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "        self.zh_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, en_tensor, zh_tensor):\n",
        "        en_emb = self.en_embedding(en_tensor)\n",
        "        zh_emb = self.zh_embedding(zh_tensor)\n",
        "\n",
        "        en_hidden = torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "        for word_idx in en_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, en_hidden = self.en_rnn(word_idx, en_hidden)\n",
        "    \n",
        "        zh_hidden = en_hidden\n",
        "        for word_idx in zh_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, zh_hidden = self.zh_rnn(word_idx, zh_hidden)\n",
        "\n",
        "        score = self.out(F.relu(self.hidden(zh_hidden[-1])))\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u68m8cGjuZcJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rnn = RNNChain(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100)\n",
        "\n",
        "rnn.load_state_dict(torch.load(in_gdrive('rnn.pt')))\n",
        "rnn.to(device)\n",
        "\n",
        "preds = []\n",
        "for idx, (en_tensor, zh_tensor) in enumerate(test_pairs):\n",
        "    pred = rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze()\n",
        "    preds.append(pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfG9o6GCv3su",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('predictions.txt', 'w') as f:\n",
        "    for score in preds:\n",
        "        f.write(f'{score}\\n')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDPzyUWzp4ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_PREV = True\n",
        "\n",
        "rnn = RNNChain(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100)\n",
        "rnn.to(device)\n",
        "\n",
        "rnn_opt = torch.optim.Adam(rnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "state = {\n",
        "    'curr_epoch': 1,\n",
        "    'train_losses': [],\n",
        "    'val_losses': [],\n",
        "    'val_pearson': [],\n",
        "}\n",
        "\n",
        "if USE_PREV and os.path.exists(in_gdrive('rnn.pt')):\n",
        "    print('Loading from Google Drive...', end=' ')\n",
        "    rnn.load_state_dict(torch.load(in_gdrive('rnn.pt')))\n",
        "\n",
        "    with open(in_gdrive('rnn.json'), 'r') as f:\n",
        "        state = json.load(f)\n",
        "    print('done!')\n",
        "\n",
        "\n",
        "while state['curr_epoch'] <= NUM_EPOCHS:\n",
        "    print(f'Epoch {state[\"curr_epoch\"]}:')\n",
        "    rnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    print(f'Training {len(train_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(train_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze()\n",
        "        curr_loss = loss_fn(pred, score) \n",
        "        loss += curr_loss\n",
        "        if idx % 500 == 0:\n",
        "            print('.', end='')\n",
        "    print()\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    state['train_losses'].append(loss.detach().cpu().numpy().tolist())\n",
        "    \n",
        "    print(f'==>train loss = {loss:.5f}')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    print(f'Validating loss {len(val_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(val_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('.', end='')\n",
        "    print()    \n",
        "\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'==>validation loss = {val_loss:.5f}')\n",
        "    state['val_losses'].append(val_loss.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze().detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    state['val_pearson'].append(pearson_score)\n",
        "    print(f'==>validation pearson = {pearson_score:.5f}')\n",
        "\n",
        "    # Backpropagation\n",
        "    print('Backpropagation...', end=' ')\n",
        "    loss.backward()\n",
        "    rnn_opt.step()\n",
        "    print('done!')\n",
        "\n",
        "    # Save\n",
        "    print('Saving to Google Drive...', end=' ')\n",
        "    torch.save(rnn.state_dict(), in_gdrive('rnn.pt'))\n",
        "\n",
        "    state['curr_epoch'] += 1\n",
        "    with open(in_gdrive('rnn.json'), 'w') as f:\n",
        "        json.dump(state, f)\n",
        "\n",
        "    print('done!\\n')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxsp-O3FL3si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        output = emb.view(1, 1, -1)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "class RegressorLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, *, emb_dim):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.out(F.relu(self.hidden(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ZnU2SMa9hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_model = RNNChain(vocab_size=len(EN), emb_dim=200)\n",
        "zh_model = RNNChain(vocab_size=len(ZH), emb_dim=200)\n",
        "regressor = RegressorLayer(emb_dim=200)\n",
        "\n",
        "en_model.to(device)\n",
        "zh_model.to(device)\n",
        "regressor.to(device)\n",
        "\n",
        "print(en_model)\n",
        "print(zh_model)\n",
        "\n",
        "LR = 0.003\n",
        "\n",
        "en_opt = torch.optim.Adam(en_model.parameters(), lr=LR)\n",
        "zh_opt = torch.optim.Adam(zh_model.parameters(), lr=LR)\n",
        "regressor_opt = torch.optim.Adam(regressor.parameters(), lr=LR)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MOiNoElbLD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(en_tensor, zh_tensor, score):\n",
        "    en_model.zero_grad()\n",
        "    zh_model.zero_grad()\n",
        "\n",
        "    en_hidden = en_model.init_hidden()\n",
        "\n",
        "    for word_idx in en_tensor:\n",
        "        hids, en_hidden = en_model(word_idx, en_hidden)\n",
        "        print('Hids', hids.shape)\n",
        "    \n",
        "    # print('EN final hidden state', en_hidden)\n",
        "\n",
        "    zh_hidden = en_hidden\n",
        "    for word_idx in zh_tensor:\n",
        "        _, zh_hidden = zh_model(word_idx, zh_hidden)\n",
        "    \n",
        "    # print('ZH final hidden state', zh_hidden)\n",
        "\n",
        "    pred_score = regressor(zh_hidden).squeeze()\n",
        "\n",
        "    loss = loss_fn(pred_score, score)\n",
        "    \n",
        "    # print('Loss', loss)    \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    regressor_opt.step()\n",
        "    zh_opt.step()\n",
        "    en_opt.step()\n",
        "\n",
        "    return loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzmHLS82c8Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for eidx in range(100):\n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set[:100]:\n",
        "        loss += train(en_tensor.to(device), zh_tensor.to(device), score)\n",
        "    loss /= 100\n",
        "    print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW6b5QrLdOnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}