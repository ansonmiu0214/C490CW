{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QEV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonmiu0214/C490CW/blob/master/QEV_BiRNN_wholeDataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEKvQGwiJhlX",
        "colab_type": "text"
      },
      "source": [
        "# Coursework: Quality Estimation Vectors\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSN72uyXX8zr",
        "colab_type": "code",
        "outputId": "82365e5f-0f2a-47a7-8571-1531881ed314",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        }
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'gpu')\n",
        "print(f'DEVICE={device}')\n",
        "  torch.manual_seed(0)\n",
        "  torch.cuda.manual_seed(0)\n",
        "  np.random.seed(0)\n",
        "# PyTorch version\n",
        "print(torch.__version__)\n",
        "\n",
        "# Disable warnings :)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4c684bbfd65e>\"\u001b[0;36m, line \u001b[0;32m14\u001b[0m\n\u001b[0;31m    torch.manual_seed(0)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0tBzjD6zEw",
        "colab_type": "code",
        "outputId": "9ea5fa5a-e684-491c-90a0-de572a2b161d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        }
      },
      "source": [
        "# Google Drive authorisation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "def in_gdrive(path):\n",
        "    return f'/content/gdrive/My Drive/Colab Notebooks/{path}'\n",
        "\n",
        "# !ls /content/gdrive/My\\ Drive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    729\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-819003751be4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0min_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34mf'/content/gdrive/My Drive/Colab Notebooks/{path}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    236\u001b[0m       \u001b[0mauth_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\nEnter your authorization code:\\n'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfifo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfifo_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mfifo_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_getpass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauth_prompt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m       \u001b[0mwrote_to_fifo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mwrote_to_fifo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mgetpass\u001b[0;34m(self, prompt, stream)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m         )\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    737\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JV59lAFJ2Tv",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rjr6T2qJlxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n",
        "\n",
        "TRAIN_EN = 'train.enzh.src'\n",
        "TRAIN_ZH = 'train.enzh.mt'\n",
        "TRAIN_SCORES = 'train.enzh.scores'\n",
        "VAL_EN = 'dev.enzh.src'\n",
        "VAL_ZH = 'dev.enzh.mt'\n",
        "VAL_SCORES = 'dev.enzh.scores'\n",
        "TEST_EN = 'test.enzh.src'\n",
        "TEST_ZH = 'test.enzh.mt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQJ06kXdK-qc",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZU6c-b6Lgp1",
        "colab_type": "text"
      },
      "source": [
        "### English\n",
        "\n",
        "1. Tokenise with spaCy language model\n",
        "2. Remove stop words and punctuation\n",
        "3. Normalise - lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYS01soSJ8DP",
        "colab_type": "code",
        "outputId": "2f16a009-23f2-4bf2-90f3-1eda52679bea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        }
      },
      "source": [
        "# Downloading spacy models for English\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300 --force"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysk8sSgwOMNJ",
        "colab_type": "code",
        "outputId": "091692e3-3855-4977-d2d6-03ad82882b7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# Downloading stop words for English\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download('stopwords')\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFh-oANJOv9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp_en = spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh5Bst_uRXzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_en(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        text = sentence.lower()\n",
        "        processed = [token.lemma_ for token in nlp_en.tokenizer(text)]\n",
        "        processed = [token for token in processed if token.isalpha()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_en]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ibZzfNvIvOma",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "80905e7e-decc-4676-dfb3-3a01baa12365"
      },
      "source": [
        "def outlier_remove(en_data, zh_data, scores):\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-10-6e6d125f1d98>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UsvjK3mMGEW",
        "colab_type": "text"
      },
      "source": [
        "### Chinese\n",
        "\n",
        "1. Tokenise with jieba\n",
        "2. Remove stop words and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaaRTU3XMPmA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download stop words\n",
        "FILE_STOP_WORDS_ZH = './chinese_stop_words.txt'\n",
        "\n",
        "if not os.path.exists(FILE_STOP_WORDS_ZH):\n",
        "    !wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "with open(FILE_STOP_WORDS_ZH, 'r', encoding='utf-8') as f:\n",
        "    stop_words_zh = [line.rstrip() for line in f]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6feYfNRYYTJk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmS0Q6fOUO2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "\n",
        "def preprocess_zh(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        tokens = jieba.cut(sentence, cut_all=True)\n",
        "        processed = [token for token in tokens if token.isalnum()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_zh]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn3Ar3-6MZWV",
        "colab_type": "text"
      },
      "source": [
        "## Language Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPvP2XYMr5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Language(object):\n",
        "\n",
        "    SOS_TOKEN = '<SOS>'\n",
        "    EOS_TOKEN = '<EOS>'\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.word2count = {}\n",
        "        self.idx2word = {0: self.SOS_TOKEN,\n",
        "                         1: self.EOS_TOKEN,\n",
        "                         2: self.UNK_TOKEN}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for token in sentence:\n",
        "            self.add_word(token)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            idx = len(self)\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "        \n",
        "        count = self.word2count.get(word, 0)\n",
        "        self.word2count[word] = count + 1\n",
        "\n",
        "    def sent_to_idxs(self, sent):\n",
        "        return [self.word2idx.get(word, 2) for word in sent]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f'Language(name={self.name}) with {len(self)} words'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZWJs-CQMIb",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBmQxeIQOPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read from file\n",
        "\n",
        "with open(TRAIN_EN) as f:\n",
        "    train_en = f.readlines()\n",
        "with open(TRAIN_ZH) as f:\n",
        "    train_zh = f.readlines()\n",
        "with open(TRAIN_SCORES) as f:\n",
        "    train_scores = f.readlines()\n",
        "with open(VAL_EN) as f:\n",
        "    val_en = f.readlines()\n",
        "with open(VAL_ZH) as f:\n",
        "    val_zh = f.readlines()\n",
        "with open(VAL_SCORES) as f:\n",
        "    val_scores = f.readlines()\n",
        "with open(TEST_EN) as f:\n",
        "    test_en = f.readlines()\n",
        "with open(TEST_ZH) as f:\n",
        "    test_zh = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aaR6q37RMsO",
        "colab_type": "code",
        "outputId": "3d64632a-e54a-4d80-f984-a625c19f0b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "# English data\n",
        "\n",
        "preprocess_english = preprocess_en(keep_stopwords=False)\n",
        "\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "EN = Language('EN')\n",
        "for sent in train_en_sents:\n",
        "    EN.add_sentence(sent)\n",
        "\n",
        "print(EN)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_en = train_en_sents[42]\n",
        "print(sample_sent_en)\n",
        "print(EN.sent_to_idxs(sample_sent_en))\n",
        "\n",
        "train_en_idxs = [EN.sent_to_idxs(sent) for sent in train_en_sents]\n",
        "val_en_idxs = [EN.sent_to_idxs(sent) for sent in val_en_sents]\n",
        "test_en_idxs = [EN.sent_to_idxs(sent) for sent in test_en_sents]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language(name=EN) with 19142 words\n",
            "\n",
            "Sample sentence\n",
            "['artilleryman', 'record', 'wound', 'die']\n",
            "[293, 294, 295, 296]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEZK9El_U9v3",
        "outputId": "83f39fbb-8ecc-495e-daef-3251bd8a6468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "# Chinese data\n",
        "\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=False)\n",
        "\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "ZH = Language('ZH')\n",
        "for sent in train_zh_sents:\n",
        "    ZH.add_sentence(sent)\n",
        "\n",
        "print(ZH)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_zh = train_zh_sents[42]\n",
        "print(sample_sent_zh)\n",
        "print(ZH.sent_to_idxs(sample_sent_zh))\n",
        "\n",
        "train_zh_idxs = [ZH.sent_to_idxs(sent) for sent in train_zh_sents]\n",
        "val_zh_idxs = [ZH.sent_to_idxs(sent) for sent in val_zh_sents]\n",
        "test_zh_idxs = [ZH.sent_to_idxs(sent) for sent in test_zh_sents]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.610 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Language(name=ZH) with 23851 words\n",
            "\n",
            "Sample sentence\n",
            "['据', '记录', '所有', '6', '名', '炮兵', '都', '受伤', '了']\n",
            "[483, 484, 485, 267, 486, 487, 488, 489, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCR41KviW6Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process scores\n",
        "\n",
        "def prepare_score(score):\n",
        "    return float(score)\n",
        "\n",
        "train_scores = [prepare_score(score) for score in train_scores]\n",
        "val_scores = [prepare_score(score) for score in val_scores]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qYQlzaEWViN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasets\n",
        "\n",
        "train_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_en_idxs]\n",
        "train_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_zh_idxs]\n",
        "\n",
        "train_pairs = list(zip(train_en_tensors, train_zh_tensors))\n",
        "train_set = list(zip(train_pairs, train_scores))\n",
        "\n",
        "val_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_en_idxs]\n",
        "val_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_zh_idxs]\n",
        "\n",
        "val_pairs = list(zip(val_en_tensors, val_zh_tensors))\n",
        "val_set = list(zip(val_pairs, val_scores))\n",
        "\n",
        "# val_pairs = list(zip(val_en_idxs, val_zh_idxs))\n",
        "# test_pairs = list(zip(test_en_idxs, test_zh_idxs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBU5dUInLx-R",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtsfA_hdPmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def unzip(args):\n",
        "    return zip(*args)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmQwblc_WAOT",
        "colab_type": "text"
      },
      "source": [
        "### Bi-Direction NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJ7rerILiNZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_context_vec(hidden_outputs, zh_emb):\n",
        "    def activation(zh_emb, hidden):\n",
        "        return zh_emb.squeeze().dot(hidden.squeeze())\n",
        "\n",
        "    e_s = torch.Tensor([\n",
        "        activation(zh_emb, hid)\n",
        "        for hid in hidden_outputs\n",
        "    ])\n",
        "\n",
        "    a_s = F.softmax(e_s)\n",
        "\n",
        "    ctx = torch.zeros(1, 100, device=device)\n",
        "    for a, h in zip(a_s, hidden_outputs):\n",
        "        ctx += a * h\n",
        "    return ctx"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mobMXC_V_0S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import deque\n",
        "\n",
        "class BiRNN(nn.Module):\n",
        "    def __init__(self, *, vocab_size, emb_dim=100, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "\n",
        "        self.forward_gru = torch.nn.GRU(\n",
        "            input_size=self.emb_dim, hidden_size=self.emb_dim, num_layers=self.num_layers,batch_first=False, bidirectional=True)\n",
        "        self.backward_gru = torch.nn.GRU(\n",
        "            input_size=self.emb_dim, hidden_size=self.emb_dim, num_layers=self.num_layers, batch_first=False, bidirectional=False)\n",
        "        \n",
        "        self.backward_gru.weight_ih_l0 = self.forward_gru.weight_ih_l0_reverse\n",
        "        self.backward_gru.weight_hh_l0 = self.forward_gru.weight_hh_l0_reverse\n",
        "        self.backward_gru.bias_ih_l0 = self.forward_gru.bias_ih_l0_reverse\n",
        "        self.backward_gru.bias_hh_l0 = self.forward_gru.bias_hh_l0_reverse\n",
        "\n",
        "    def forward(self, tensor):\n",
        "        \"\"\"Return hidden states of backward RNN.\"\"\"\n",
        "        sent_len = len(tensor)\n",
        "        emb = self.embedding(tensor).view(sent_len, 1, -1)\n",
        "\n",
        "        # self.forward_gru.flatten_parameters()\n",
        "        bi_output, bi_hidden = self.forward_gru(emb)\n",
        "        rev_emb = emb[np.arange(sent_len - 1, -1, -1), :, :]\n",
        "\n",
        "        # self.backward_gru.flatten_parameters()\n",
        "        rev_output, rev_hidden = self.backward_gru(rev_emb)\n",
        "        return rev_output\n",
        "\n",
        "class BiRNNAttention(nn.Module):\n",
        "    def __init__(self, *, vocab_size, emb_dim=100, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "\n",
        "        self.forward_gru = torch.nn.GRU(\n",
        "            input_size=self.emb_dim, hidden_size=self.emb_dim, num_layers=self.num_layers,batch_first=False, bidirectional=True)\n",
        "        self.backward_gru = torch.nn.GRU(\n",
        "            input_size=self.emb_dim, hidden_size=self.emb_dim, num_layers=self.num_layers, batch_first=False, bidirectional=False)\n",
        "        \n",
        "        self.backward_gru.weight_ih_l0 = self.forward_gru.weight_ih_l0_reverse\n",
        "        self.backward_gru.weight_hh_l0 = self.forward_gru.weight_hh_l0_reverse\n",
        "        self.backward_gru.bias_ih_l0 = self.forward_gru.bias_ih_l0_reverse\n",
        "        self.backward_gru.bias_hh_l0 = self.forward_gru.bias_hh_l0_reverse\n",
        "\n",
        "    def forward(self, tensor, prev_hiddens):\n",
        "        \"\"\"Return hidden states of backward RNN.\"\"\"\n",
        "        sent_len = len(tensor)\n",
        "\n",
        "        embs = self.embedding(tensor).view(sent_len, 1, -1)\n",
        "\n",
        "        ctxs = torch.stack([get_context_vec(prev_hiddens, zh_emb)\n",
        "                            for zh_emb in embs])\n",
        "\n",
        "        # self.forward_gru.flatten_parameters()\n",
        "        bi_output, bi_hidden = self.forward_gru(ctxs)\n",
        "\n",
        "        rev_ctxs = ctxs[np.arange(sent_len - 1, -1, -1), :, :]\n",
        "\n",
        "        # self.backward_gru.flatten_parameters()\n",
        "        rev_output, rev_hidden = self.backward_gru(rev_ctxs)\n",
        "        return rev_output\n",
        "\n",
        "class QualVecRNN(nn.Module):\n",
        "    def __init__(self, *, emb_dim=100, num_layers=1):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.lstm = nn.LSTM(input_size=self.emb_dim, hidden_size=1, num_layers=self.num_layers)\n",
        "    \n",
        "    def forward(self, tensor):\n",
        "        # self.lstm.flatten_parameters()\n",
        "        output, hidden = self.lstm(tensor)\n",
        "        return hidden[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SB63jQN5h-Us",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(num_epochs):\n",
        "    for eidx in range(num_epochs):\n",
        "        print(f'Epoch {eidx + 1}')\n",
        "\n",
        "        for comp in components:\n",
        "            comp.zero_grad()\n",
        "\n",
        "        loss = 0\n",
        "\n",
        "\n",
        "        print(f'Training: {len(train_set)}', end=' ')\n",
        "        for idx, ((en_tensor, zh_tensor), score) in enumerate(train_set):\n",
        "            # Forward pass to get \n",
        "            en_hiddens = en_rnn(en_tensor.to(device))\n",
        "            qual_vecs = zh_rnn(zh_tensor.to(device), en_hiddens)  \n",
        "            pred_score = regressor(qual_vecs).squeeze()\n",
        "\n",
        "            loss += loss_fn(pred_score, score)\n",
        "            if idx % 500 == 0:\n",
        "                print('.', end='')\n",
        "        \n",
        "        print()\n",
        "        loss /= len(train_set)\n",
        "        print(f'Loss={loss}')\n",
        "\n",
        "        val_pred_scores = []\n",
        "\n",
        "        val_loss = 0\n",
        "        for idx, ((en_tensor, zh_tensor), score) in enumerate(val_set):\n",
        "            en_hiddens = en_rnn(en_tensor.to(device))\n",
        "            qual_vecs = zh_rnn(zh_tensor.to(device), en_hiddens)  \n",
        "            pred_score = regressor(qual_vecs).squeeze()\n",
        "            val_pred_scores.append(pred_score.data.cpu().numpy())\n",
        "\n",
        "            val_loss += loss_fn(pred_score, score)\n",
        "            if idx % 500 == 0:\n",
        "                print('.', end='')\n",
        "\n",
        "        val_loss /= len(val_set)\n",
        "        print(f'validation loss = {val_loss:.5f}\\t', end='')\n",
        "\n",
        "        pearson_score, _ = pearsonr(np.array(val_pred_scores), np.array(val_scores))\n",
        "        print(f'validation pearson = {pearson_score:.5f}\\t')\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "\n",
        "        for opt in opts:\n",
        "            opt.step()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFxnzWrOfgxw",
        "colab_type": "code",
        "outputId": "6977ab85-9919-41b9-e533-171fc0247817",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "en_rnn = BiRNN(vocab_size=len(EN))\n",
        "en_rnn.to(device)\n",
        "\n",
        "zh_rnn = BiRNNAttention(vocab_size=len(ZH))\n",
        "zh_rnn.to(device)\n",
        "\n",
        "regressor = QualVecRNN()\n",
        "regressor.to(device)\n",
        "\n",
        "LR = 0.003\n",
        "\n",
        "en_opt = torch.optim.Adam(en_rnn.parameters(), lr=LR)\n",
        "zh_opt = torch.optim.Adam(zh_rnn.parameters(), lr=LR)\n",
        "regr_opt = torch.optim.Adam(regressor.parameters(), lr=LR)\n",
        "\n",
        "loss_fn = RMSELoss\n",
        "\n",
        "print(en_rnn)\n",
        "print(zh_rnn)\n",
        "print(regressor)\n",
        "\n",
        "components = (en_rnn, zh_rnn, regressor)\n",
        "opts = (en_opt, zh_opt, regr_opt)\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BiRNN(\n",
            "  (embedding): Embedding(19142, 100)\n",
            "  (forward_gru): GRU(100, 100, bidirectional=True)\n",
            "  (backward_gru): GRU(100, 100)\n",
            ")\n",
            "BiRNNAttention(\n",
            "  (embedding): Embedding(23851, 100)\n",
            "  (forward_gru): GRU(100, 100, bidirectional=True)\n",
            "  (backward_gru): GRU(100, 100)\n",
            ")\n",
            "QualVecRNN(\n",
            "  (lstm): LSTM(100, 1)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5NmpKE9rRgZ",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRYTwX04iecH",
        "colab_type": "code",
        "outputId": "131e45c2-a147-42f0-cd1e-a9fc7ec16558",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        }
      },
      "source": [
        "train(40) #max noticed: 0.14/0.16"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Training: 7000 ..............\n",
            "Loss=0.8162736892700195\n",
            "..validation loss = 0.78711\tvalidation pearson = -0.04118\t\n",
            "Epoch 2\n",
            "Training: 7000 ..............\n",
            "Loss=0.7002050876617432\n",
            "..validation loss = 0.69896\tvalidation pearson = 0.01286\t\n",
            "Epoch 3\n",
            "Training: 7000 ..............\n",
            "Loss=0.7010735273361206\n",
            "..validation loss = 0.70184\tvalidation pearson = 0.07286\t\n",
            "Epoch 4\n",
            "Training: 7000 ..............\n",
            "Loss=0.6951229572296143\n",
            "..validation loss = 0.69867\tvalidation pearson = 0.09685\t\n",
            "Epoch 5\n",
            "Training: 7000 ..............\n",
            "Loss=0.6840256452560425\n",
            "..validation loss = 0.69313\tvalidation pearson = 0.09686\t\n",
            "Epoch 6\n",
            "Training: 7000 ..............\n",
            "Loss=0.6857578158378601\n",
            "..validation loss = 0.69874\tvalidation pearson = 0.08600\t\n",
            "Epoch 7\n",
            "Training: 7000 ..............\n",
            "Loss=0.6785259246826172\n",
            "..validation loss = 0.69680\tvalidation pearson = 0.09386\t\n",
            "Epoch 8\n",
            "Training: 7000 ..............\n",
            "Loss=0.6694183945655823\n",
            "..validation loss = 0.69169\tvalidation pearson = 0.10776\t\n",
            "Epoch 9\n",
            "Training: 7000 ."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFiF4FSRlCx",
        "colab_type": "text"
      },
      "source": [
        "### FFNN with trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oWCA9Mdbbta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_hidden = nn.Linear(self.emb_dim, 1)\n",
        "        self.zh_hidden = nn.Linear(self.emb_dim, 1)\n",
        "\n",
        "        self.out = nn.Linear(2, 1)\n",
        "    \n",
        "    def forward(self, en_tensors, zh_tensors):\n",
        "        en_emb = self.en_embedding(en_tensors)\n",
        "        zh_emb = self.zh_embedding(zh_tensors)\n",
        "\n",
        "        en_hid = F.relu(self.en_hidden(en_emb))\n",
        "        zh_hid = F.relu(self.zh_hidden(en_emb))\n",
        "\n",
        "        hid_concat = torch.stack((en_hid, zh_hid), axis=1).squeeze()\n",
        "        score = self.out(hid_concat)\n",
        "        return score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1SoBa5csKg",
        "colab_type": "code",
        "outputId": "b03d5c81-c47a-4522-f499-972fde72bc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "ffnn = FFNN(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=200)\n",
        "ffnn.to(device)\n",
        "print(ffnn)\n",
        "\n",
        "ffnn_opt = torch.optim.Adam(ffnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (en_embedding): Embedding(19142, 200)\n",
            "  (zh_embedding): Embedding(23851, 200)\n",
            "  (en_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (zh_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (out): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9MTNFHdTJ4",
        "colab_type": "code",
        "outputId": "01b7c68b-2944-419b-b756-2911a80d20e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "NUM_EPOCHS = 20 #0.06 best around E30\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_pearson = []\n",
        "\n",
        "for eidx in range(NUM_EPOCHS):\n",
        "    print(f'Epoch {eidx + 1}: \\t', end=' ')\n",
        "    ffnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        loss += loss_fn(pred, score)\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    train_losses.append(loss)\n",
        "    \n",
        "    print(f'train loss = {loss:.5f}\\t', end='')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    for (en_tensor, zh_tensor), score in val_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'validation loss = {val_loss:.5f}\\t', end='')\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(ffnn(en_tensor.to(device), zh_tensor.to(device)).detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    \n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    val_pearson.append(pearson_score)\n",
        "    print(f'validation pearson = {pearson_score:.5f}\\t')\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    ffnn_opt.step()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: \t train loss = 0.78949\tvalidation loss = 0.79252\tvalidation pearson = 0.06212\t\n",
            "Epoch 2: \t train loss = 0.77863\tvalidation loss = 0.78406\tvalidation pearson = 0.06094\t\n",
            "Epoch 3: \t train loss = 0.76857\tvalidation loss = 0.77620\tvalidation pearson = 0.05827\t\n",
            "Epoch 4: \t train loss = 0.75928\tvalidation loss = 0.76868\tvalidation pearson = 0.05525\t\n",
            "Epoch 5: \t train loss = 0.75061\tvalidation loss = 0.76155\tvalidation pearson = 0.05286\t\n",
            "Epoch 6: \t train loss = 0.74243\tvalidation loss = 0.75489\tvalidation pearson = 0.05114\t\n",
            "Epoch 7: \t train loss = 0.73475\tvalidation loss = 0.74872\tvalidation pearson = 0.04932\t\n",
            "Epoch 8: \t train loss = 0.72747\tvalidation loss = 0.74284\tvalidation pearson = 0.04736\t\n",
            "Epoch 9: \t train loss = 0.72060\tvalidation loss = 0.73736\tvalidation pearson = 0.04458\t\n",
            "Epoch 10: \t train loss = 0.71403\tvalidation loss = 0.73226\tvalidation pearson = 0.04218\t\n",
            "Epoch 11: \t train loss = 0.70770\tvalidation loss = 0.72748\tvalidation pearson = 0.04059\t\n",
            "Epoch 12: \t train loss = 0.70156\tvalidation loss = 0.72291\tvalidation pearson = 0.03937\t\n",
            "Epoch 13: \t train loss = 0.69570\tvalidation loss = 0.71878\tvalidation pearson = 0.03837\t\n",
            "Epoch 14: \t train loss = 0.69009\tvalidation loss = 0.71504\tvalidation pearson = 0.03793\t\n",
            "Epoch 15: \t train loss = 0.68469\tvalidation loss = 0.71157\tvalidation pearson = 0.03794\t\n",
            "Epoch 16: \t train loss = 0.67947\tvalidation loss = 0.70855\tvalidation pearson = 0.03838\t\n",
            "Epoch 17: \t train loss = 0.67440\tvalidation loss = 0.70586\tvalidation pearson = 0.03916\t\n",
            "Epoch 18: \t train loss = 0.66949\tvalidation loss = 0.70350\tvalidation pearson = 0.04049\t\n",
            "Epoch 19: \t train loss = 0.66468\tvalidation loss = 0.70150\tvalidation pearson = 0.04229\t\n",
            "Epoch 20: \t train loss = 0.65990\tvalidation loss = 0.69979\tvalidation pearson = 0.04450\t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUlPsvWsL4mp",
        "colab_type": "text"
      },
      "source": [
        "### RNN Chain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UkdfLZMoI5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "        self.zh_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, en_tensor, zh_tensor):\n",
        "        en_emb = self.en_embedding(en_tensor)\n",
        "        zh_emb = self.zh_embedding(zh_tensor)\n",
        "\n",
        "        en_hidden = torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "        for word_idx in en_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, en_hidden = self.en_rnn(word_idx, en_hidden)\n",
        "    \n",
        "        zh_hidden = en_hidden\n",
        "        for word_idx in zh_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, zh_hidden = self.zh_rnn(word_idx, zh_hidden)\n",
        "\n",
        "        score = self.out(F.relu(self.hidden(zh_hidden[-1])))\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDPzyUWzp4ZY",
        "colab_type": "code",
        "outputId": "9e3e81d1-a186-4574-c6ef-e7df5cbad577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "source": [
        "USE_PREV = True\n",
        "\n",
        "rnn = RNNChain(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100)\n",
        "rnn.to(device)\n",
        "\n",
        "rnn_opt = torch.optim.Adam(rnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "state = {\n",
        "    'curr_epoch': 1,\n",
        "    'train_losses': [],\n",
        "    'val_losses': [],\n",
        "    'val_pearson': [],\n",
        "}\n",
        "\n",
        "if USE_PREV and os.path.exists(in_gdrive('rnn.pt')):\n",
        "    print('Loading from Google Drive...', end=' ')\n",
        "    rnn.load_state_dict(torch.load(in_gdrive('rnn.pt')))\n",
        "\n",
        "    with open(in_gdrive('rnn.json'), 'r') as f:\n",
        "        state = json.load(f)\n",
        "    print('done!')\n",
        "\n",
        "\n",
        "while state['curr_epoch'] <= NUM_EPOCHS:\n",
        "    print(f'Epoch {state[\"curr_epoch\"]}:')\n",
        "    rnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    print(f'Training {len(train_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(train_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze()\n",
        "        curr_loss = loss_fn(pred, score) \n",
        "        loss += curr_loss\n",
        "        if idx % 500 == 0:\n",
        "            print('.', end='')\n",
        "    print()\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    state['train_losses'].append(loss.detach().cpu().numpy().tolist())\n",
        "    \n",
        "    print(f'==>train loss = {loss:.5f}')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    print(f'Validating loss {len(val_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(val_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('.', end='')\n",
        "    print()    \n",
        "\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'==>validation loss = {val_loss:.5f}')\n",
        "    state['val_losses'].append(val_loss.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze().detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    state['val_pearson'].append(pearson_score)\n",
        "    print(f'==>validation pearson = {pearson_score:.5f}')\n",
        "\n",
        "    # Backpropagation\n",
        "    print('Backpropagation...', end=' ')\n",
        "    loss.backward()\n",
        "    rnn_opt.step()\n",
        "    print('done!')\n",
        "\n",
        "    # Save\n",
        "    print('Saving to Google Drive...', end=' ')\n",
        "    torch.save(rnn.state_dict(), in_gdrive('rnn.pt'))\n",
        "\n",
        "    state['curr_epoch'] += 1\n",
        "    with open(in_gdrive('rnn.json'), 'w') as f:\n",
        "        json.dump(state, f)\n",
        "\n",
        "    print('done!\\n')\n",
        "    "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1:\n",
            "Training 7000: ..............\n",
            "==>train loss = 0.69984\n",
            "Validating loss 1000: ..........\n",
            "==>validation loss = 0.69330\n",
            "==>validation pearson = 0.04330\n",
            "Backpropagation... done!\n",
            "Saving to Google Drive... "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1c95e0e78f97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;31m# Save\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Saving to Google Drive...'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_gdrive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rnn.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'curr_epoch'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/gdrive/My Drive/Colab Notebooks/rnn.pt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxsp-O3FL3si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        output = emb.view(1, 1, -1)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "class RegressorLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, *, emb_dim):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.out(F.relu(self.hidden(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ZnU2SMa9hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_model = RNNChain(vocab_size=len(EN), emb_dim=200)\n",
        "zh_model = RNNChain(vocab_size=len(ZH), emb_dim=200)\n",
        "regressor = RegressorLayer(emb_dim=200)\n",
        "\n",
        "en_model.to(device)\n",
        "zh_model.to(device)\n",
        "regressor.to(device)\n",
        "\n",
        "#print(en_model)\n",
        "#print(zh_model)\n",
        "\n",
        "LR = 0.003\n",
        "\n",
        "en_opt = torch.optim.Adam(en_model.parameters(), lr=LR)\n",
        "zh_opt = torch.optim.Adam(zh_model.parameters(), lr=LR)\n",
        "regressor_opt = torch.optim.Adam(regressor.parameters(), lr=LR)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MOiNoElbLD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(en_tensor, zh_tensor, score):\n",
        "    en_model.zero_grad()\n",
        "    zh_model.zero_grad()\n",
        "\n",
        "    en_hidden = en_model.init_hidden()\n",
        "\n",
        "    for word_idx in en_tensor:\n",
        "        hids, en_hidden = en_model(word_idx, en_hidden)\n",
        "        #print('Hids', hids.shape)\n",
        "    \n",
        "    # print('EN final hidden state', en_hidden)\n",
        "\n",
        "    zh_hidden = en_hidden\n",
        "    for word_idx in zh_tensor:\n",
        "        _, zh_hidden = zh_model(word_idx, zh_hidden)\n",
        "    \n",
        "    # print('ZH final hidden state', zh_hidden)\n",
        "\n",
        "    pred_score = regressor(zh_hidden).squeeze()\n",
        "\n",
        "    loss = loss_fn(pred_score, score)\n",
        "    \n",
        "    # print('Loss', loss)    \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    regressor_opt.step()\n",
        "    zh_opt.step()\n",
        "    en_opt.step()\n",
        "\n",
        "    return loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzmHLS82c8Yu",
        "colab_type": "code",
        "outputId": "dababb52-3bee-4eda-b6fa-b4ea6f0e5f18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 608
        }
      },
      "source": [
        "\n",
        "for eidx in range(100):\n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set[:100]:\n",
        "        loss += train(en_tensor.to(device), zh_tensor.to(device), score)\n",
        "    loss /= 100\n",
        "    print(loss)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.8550, device='cuda:0')\n",
            "tensor(2.4649, device='cuda:0')\n",
            "tensor(0.9812, device='cuda:0')\n",
            "tensor(6.9700, device='cuda:0')\n",
            "tensor(1.0203, device='cuda:0')\n",
            "tensor(1.1656, device='cuda:0')\n",
            "tensor(1.9127, device='cuda:0')\n",
            "tensor(0.8538, device='cuda:0')\n",
            "tensor(0.7714, device='cuda:0')\n",
            "tensor(0.8021, device='cuda:0')\n",
            "tensor(0.7792, device='cuda:0')\n",
            "tensor(0.7273, device='cuda:0')\n",
            "tensor(0.8187, device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-c9838b9858d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0men_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0men_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-51-4bc6b4e6d586>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(en_tensor, zh_tensor, score)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# print('Loss', loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mregressor_opt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     98\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW6b5QrLdOnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}