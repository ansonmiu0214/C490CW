{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursework_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEQHVdOS61G",
        "colab_type": "text"
      },
      "source": [
        "# Coursework: Baseline Model\n",
        "\n",
        "This notebook takes you step by step to the implementation of a simple baseline model to get you started on the coursework. You have a section for the English-German task and another for English-Chinese. They are made to be standalone so feel free to check only one of the sections. However, as the tasks require slighlty different approaches, going through both sections could help you to get inspired for your chosen task, especially each task processes english in a slighlty different way.\n",
        "\n",
        "Enjoy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lweXud1Wpemd",
        "colab_type": "text"
      },
      "source": [
        "## A. English-German"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu6s3YOf_C93",
        "colab_type": "text"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scs7ICZrPFcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip the data\n",
        "from os.path import exists\n",
        "if not exists('ende_data.zip'):\n",
        "    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
        "    !unzip ende_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPy_iwHnOSAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the files\n",
        "import io\n",
        "\n",
        "#English-German\n",
        "print(\"---EN-DE---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.ende.src\", \"r\") as ende_src:\n",
        "  print(\"Source: \",ende_src.readline())\n",
        "with open(\"./train.ende.mt\", \"r\") as ende_mt:\n",
        "  print(\"Translation: \",ende_mt.readline())\n",
        "with open(\"./train.ende.scores\", \"r\") as ende_scores:\n",
        "  print(\"Score: \",ende_scores.readline())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiFHVnfH_Jpv",
        "colab_type": "text"
      },
      "source": [
        "### Computing Sentence Embeddings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g05fv5GiSyQ4",
        "colab_type": "text"
      },
      "source": [
        "For this baseline model, we will simply use pre-trained GloVe embeddings via the Spacy module and compute the vector for each word and take the global mean for each sentence. We will do the same for both source and translation sentences. For chinese tokenization and embeddings we will have to find other tools.\n",
        "\n",
        "This is a very simplistic approach so feel free to be more creative and play around with how the sentence embeddings are computed for example ;)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjZpNlra8TD",
        "colab_type": "text"
      },
      "source": [
        "GloVe embeddings do not support the Chinese language so in the section of the English-Chinese task we will have to download pretrained Chinese embeddings from word2vec repositories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96bRtBbuZLJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading spacy models for english and german\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300\n",
        "\n",
        "!spacy download de_core_news_md\n",
        "!spacy link de_core_news_md de300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om6kQX5bX2mB",
        "colab_type": "text"
      },
      "source": [
        "We can now write our functions that will return the average embeddings for a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhT2I6WYavY4",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing with Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19gsNCgnW8ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "stop_words_de = set(stopwords.words('german'))\n",
        "\n",
        "def get_sentence_emb(line,nlp,lang):\n",
        "  if lang == 'en':\n",
        "    text = line.lower()\n",
        "    l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "    l = ' '.join([word for word in l if word not in stop_words_en])\n",
        "\n",
        "  elif lang == 'de':\n",
        "    text = line.lower()\n",
        "    l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "    l= ' '.join([word for word in l if word not in stop_words_de])\n",
        "\n",
        "  sen = nlp(l)\n",
        "  return sen.vector\n",
        "\n",
        "def get_embeddings(f,nlp,lang):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "      vec = get_sentence_emb(l,nlp,lang)\n",
        "      if vec is not None:\n",
        "        vec = np.mean(vec)\n",
        "        sentences_vectors.append(vec)\n",
        "      else:\n",
        "        print(\"didn't work :\", l)\n",
        "        sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUKMgbo2sreI",
        "colab_type": "text"
      },
      "source": [
        "#### Getting Training and Validation Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXqZamIKs30T",
        "colab_type": "text"
      },
      "source": [
        "We will now run the code fo the English-German translations and getting our training and validation sets ready for the regression task.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyJr7cIkQ3E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp_de =spacy.load('de300')\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwoUIDj0otbf",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "#EN-DE files\n",
        "de_train_src = get_embeddings(\"./train.ende.src\",nlp_en,'en')\n",
        "de_train_mt = get_embeddings(\"./train.ende.mt\",nlp_de,'de')\n",
        "\n",
        "f_train_scores = open(\"./train.ende.scores\",'r')\n",
        "de_train_scores = f_train_scores.readlines()\n",
        "\n",
        "de_val_src = get_embeddings(\"./dev.ende.src\",nlp_en,'en')\n",
        "de_val_mt = get_embeddings(\"./dev.ende.mt\",nlp_de,'de')\n",
        "f_val_scores = open(\"./dev.ende.scores\",'r')\n",
        "de_val_scores = f_val_scores.readlines()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_K1CHl5VxiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#EN-DE\n",
        "print(f\"Training mt: {len(de_train_mt)} Training src: {len(de_train_src)}\")\n",
        "print()\n",
        "print(f\"Validation mt: {len(de_val_mt)} Validation src: {len(de_val_src)}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px7ikaGoy9r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Put the features into a list\n",
        "X_train= [np.array(de_train_src),np.array(de_train_mt)]\n",
        "X_train_de = np.array(X_train).transpose()\n",
        "\n",
        "X_val = [np.array(de_val_src),np.array(de_val_mt)]\n",
        "X_val_de = np.array(X_val).transpose()\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(de_train_scores).astype(float)\n",
        "y_train_de =train_scores\n",
        "\n",
        "val_scores = np.array(de_val_scores).astype(float)\n",
        "y_val_de =val_scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFp6yyBl4Kgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# RUN IF WANT TO HAVE AVERAGE VECTOR(AND NOT GLOBAL MEAN), THIS GAVE WORSE PERFORMANCE THAN GLOBAL MEAN\n",
        "'''\n",
        "\n",
        "X_train= [np.array(train_src),np.array(train_mt)]\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "\n",
        "X_test = [np.array(test_src),np.array(test_mt)]\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "#Reshaping if using shape >3\n",
        "nsamples, nx, ny = X_train.shape\n",
        "X_train = X_train.reshape((nx,ny*nsamples))\n",
        "\n",
        "nsamples, nx, ny = X_test.shape\n",
        "X_test = X_test.reshape((nx,ny*nsamples))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(train_scores).astype(float)\n",
        "y_train =train_scores\n",
        "\n",
        "test_scores = np.array(test_scores).astype(float)\n",
        "y_test =test_scores\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSIE7d8HCTpi",
        "colab_type": "text"
      },
      "source": [
        "### Training the Regressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eoY14lNCTe3",
        "colab_type": "text"
      },
      "source": [
        "At this point,  will try SVM and Random Tree Forests and choose the model with the highest Pearson correlation.\n",
        "\n",
        "First we will define our RMSE function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcegRvW2F2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IerDa2251swL",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exHbrWtq14jm",
        "colab_type": "text"
      },
      "source": [
        "SVM have many parameters such as the kernel and the regularizating constant C. Here we will use C = 1 and compare kernels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiHCkGUgsJ8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_de, y_train_de)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_de)\n",
        "    pearson = pearsonr(y_val_de, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_de)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1Fr1RLm3-Kc",
        "colab_type": "text"
      },
      "source": [
        "Here the best kernel seems to be the polynomial one as it gives us the highest pearson correlation at 0.062."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg9YSBUG1zaL",
        "colab_type": "text"
      },
      "source": [
        "#### Random Tree Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au88fVS33K4W",
        "colab_type": "text"
      },
      "source": [
        "Another powerful regressor is the Random Tree Forest. Here we have to choose the number of trees we want to compute and we will pick n_estimators = 1000. The higher the number the longer it will compute. To fine tune that number you could compute the error per number of trees and select the number for which there is no more significant improvement( the \"elbow\" of the graph)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOld4zbmsOGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the model we are using\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666)\n",
        "\n",
        "rf.fit(X_train_de, y_train_de);\n",
        "\n",
        "\n",
        "predictions = rf.predict(X_val_de)\n",
        "\n",
        "pearson = pearsonr(y_val_de, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_de))\n",
        "print(f\"Pearson {pearson[0]}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L73jhAc6ZoM",
        "colab_type": "text"
      },
      "source": [
        "In this case, it seems like the SVM with a linear kernel performed the best on our validation set so we will save that model for the test set predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9puD_0zkC2c",
        "colab_type": "text"
      },
      "source": [
        "### Writing Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvvIhPDkUnR",
        "colab_type": "text"
      },
      "source": [
        "Here is our function to write the scores into a txt file. We can follow the <Method> <ID> <SCORE> template but having only the scores will work too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN3NtkF4kPxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVss_RLBkFei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EN-DE\n",
        "\n",
        "de_test_src = get_embeddings(\"./test.ende.src\",nlp_en,'en')\n",
        "de_test_mt = get_embeddings(\"./test.ende.mt\",nlp_de,'de')\n",
        "\n",
        "X= [np.array(de_test_src),np.array(de_test_mt)]\n",
        "X_test = np.array(X).transpose()\n",
        "\n",
        "#Predict\n",
        "clf_de = SVR(kernel='rbf')\n",
        "clf_de.fit(X_train_de, y_train_de)\n",
        "\n",
        "predictions_de = clf_de.predict(X_val_de)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWnNUR0Gku_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"SVR\",predictions_de)\n",
        "\n",
        "with ZipFile(\"en-de_svr.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-de_svr.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyaM_P0bynB-",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "Once submitted to codalab, the pearson correlation is 0.0052."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3obhUYW5ptUS",
        "colab_type": "text"
      },
      "source": [
        "##B. English-Chinese\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE9wypehaLrZ",
        "colab_type": "text"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5y34iNipyr3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "4b1649df-0c70-46ab-c8e5-35b19cb2a11c"
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-10 10:27:51--  https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
            "Resolving competitions.codalab.org (competitions.codalab.org)... 129.175.22.230\n",
            "Connecting to competitions.codalab.org (competitions.codalab.org)|129.175.22.230|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7c9ba42ec27e2e2cf7919b5316df9891b3f8e75d9d9d6f5bb10fb59bbd0fd532&X-Amz-Date=20200210T102757Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200210%2Fnewcodalab%2Fs3%2Faws4_request [following]\n",
            "--2020-02-10 10:27:57--  https://newcodalab.lri.fr/prod-private/dataset_data_file/None/630ec/en-zh.zip?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-Signature=7c9ba42ec27e2e2cf7919b5316df9891b3f8e75d9d9d6f5bb10fb59bbd0fd532&X-Amz-Date=20200210T102757Z&X-Amz-Credential=AZIAIOSAODNN7EX123LE%2F20200210%2Fnewcodalab%2Fs3%2Faws4_request\n",
            "Resolving newcodalab.lri.fr (newcodalab.lri.fr)... 129.175.15.11\n",
            "Connecting to newcodalab.lri.fr (newcodalab.lri.fr)|129.175.15.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 870893 (850K) [application/zip]\n",
            "Saving to: ‘enzh_data.zip’\n",
            "\n",
            "enzh_data.zip       100%[===================>] 850.48K   553KB/s    in 1.5s    \n",
            "\n",
            "2020-02-10 10:28:00 (553 KB/s) - ‘enzh_data.zip’ saved [870893/870893]\n",
            "\n",
            "Archive:  enzh_data.zip\n",
            "  inflating: dev.enzh.mt             \n",
            "  inflating: dev.enzh.scores         \n",
            "  inflating: dev.enzh.src            \n",
            "  inflating: test.enzh.mt            \n",
            "  inflating: test.enzh.src           \n",
            "  inflating: train.enzh.mt           \n",
            "  inflating: train.enzh.src          \n",
            "  inflating: train.enzh.scores       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlXMiqJXq8fy",
        "colab_type": "code",
        "outputId": "54a2d0fb-6f89-4110-b4f8-79b3f0592d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "#English-Chinese\n",
        "#Checking Data\n",
        "print(\"---EN-ZH---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---EN-ZH---\n",
            "\n",
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlOd_5a6aTVP",
        "colab_type": "text"
      },
      "source": [
        "### Computing Sentence Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqjMa_wu0xz",
        "colab_type": "text"
      },
      "source": [
        "For this task, we will compute the embeddings for words in a sentence in one language and compute the global mean for that sentence, and do the same for the other language. However, we will have to find and download pre-traind embeddings for Chinese as Spacy nor GloVe handle it. The embeddings we will be using for Chinese are of dimension 100, therefore we need to adapt the embeddings for english from the dim 300 to 100. Glove does have English embeddings of dim 100 but Spacy does not have that model. So, we will tokenize the sentences using Spacy tokenizer and use GloVe directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsKYMxCSolrx",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing English with GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd24p41jkv7N",
        "colab_type": "text"
      },
      "source": [
        "With GloVe's function *stoi()* (string to int) we can get the index corresponding to a given word and with the function *itos()* we get the word given its index. To obtain the vector of a word we first get the integer associated with it and then index it into the word embedding tensor with that index. Note that glove takes words in a lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lc4rdJnrE_Q",
        "colab_type": "code",
        "outputId": "71487f53-2c2d-4d4b-d956-491c76c65cd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# DON'T RUN IF YOU ALREADY RAN IT IN THE ENGLISH-GERMAN SECTION\n",
        "# Downloading spacy models for english\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 756kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=9b8662736f5e782ec0cac61555a00c5359a81114cfa753b9eddac2455b69f366\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-5q853y0w/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx3Ja9zWFDj2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4db40190-8122-41c9-841b-e1ee3e1e7c75"
      },
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "#Embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "#tokenizer model\n",
        "nlp_en =spacy.load('en300')\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [06:30, 2.21MB/s]                          \n",
            "100%|█████████▉| 399975/400000 [00:30<00:00, 25667.01it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxjmj7vUv08E",
        "colab_type": "text"
      },
      "source": [
        "We can now write our functions that will return the average embeddings for a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUi2QiCIi9y",
        "colab_type": "code",
        "outputId": "993e9944-a509-4b66-ab6f-3b45d3f6dff6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#ENGLISH EMBEDDINGS methods from the section GERMAN-ENGLISH\n",
        "# The difference from previous section is that we will use Glove embeddings directly because we are using a smaller model that spacy doesn't have\n",
        "# We add a method to compute the word embedding and a method to compute the sentence embedding by averaging the word vectors\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocess(sentence,nlp):\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
        "    return doc\n",
        "\n",
        "def get_word_vector(embeddings, word):\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      # print(f\"Word {word} does not exist\")\n",
        "      pass\n",
        "\n",
        "def get_sentence_vector(embeddings,line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector(embeddings,w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "   \n",
        "  return torch.mean(torch.stack(vectors), 0).numpy()\n",
        "\n",
        "\n",
        "def get_embeddings(f,embeddings,lang):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence= preprocess(l,lang)\n",
        "    try:\n",
        "      vec = get_sentence_vector(embeddings,sentence)\n",
        "      if vec is None:\n",
        "        vec = np.zeros(100)\n",
        "      sentences_vectors.append(vec)\n",
        "    except Exception as e:\n",
        "      print(e)\n",
        "\n",
        "  return sentences_vectors\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4JnbxSaaasu",
        "colab_type": "text"
      },
      "source": [
        "#### Loading Chinese Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3-NpUxd52nP",
        "colab_type": "text"
      },
      "source": [
        "We now have to download the pre-trained embeddings for Chinese. We will get them from the University of Oslo NLPL repository (http://vectors.nlpl.eu/repository/), which has word2vec vectors of dimension 100.\n",
        "\n",
        " We will also get Chinese stop words from https://github.com/Tony607/Chinese_sentiment_analysis.\n",
        "\n",
        "For embeddings of dimensions 300 you can find them searching on github repositories. One example is https://github.com/Kyubyong/wordvectors.\n",
        "\n",
        "If you want to work on colab and download other embeddings I would suggest you download the file and upload it on your dropbox and get the link from there.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jW3S2-rs6BV",
        "colab_type": "code",
        "outputId": "35a91e72-8d84-4476-c5fa-6d9af1cb6850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "\n",
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "!wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "\n",
        "!unzip zh.zip \n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-10 10:50:39--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "chinese_stop_words.     [    <=>             ] 416.62K   459KB/s    in 0.9s    \n",
            "\n",
            "2020-02-10 10:50:41 (459 KB/s) - ‘chinese_stop_words.txt’ saved [426624]\n",
            "\n",
            "--2020-02-10 10:50:43--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh.zip’\n",
            "\n",
            "zh.zip              100%[===================>]   1.36G  9.53MB/s    in 2m 35s  \n",
            "\n",
            "2020-02-10 10:53:19 (8.98 MB/s) - ‘zh.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh.zip\n",
            "  inflating: LIST                    \n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQM6Go4rEe9N",
        "colab_type": "text"
      },
      "source": [
        "We now load the pre-trained word2vec embeddings we downloaded using the gensim package. More info on gensim and how to use it to load models and embeddings here https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUbXQ4aMv1K",
        "colab_type": "code",
        "outputId": "655bf694-bd43-44bd-9f5c-3632bb2bd5c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhZ3HtrdodcW",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing Chinese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "her8c6oJFWAa",
        "colab_type": "text"
      },
      "source": [
        "For pre-processing chinese sentence we will use the tokenizer package for chinese called jieba and use the downloaded list of chinese stop words to remove them from our tokens. More info on jieba and its options at https://github.com/fxsjy/jieba. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LA9N1zgsSQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "stop_words = [ line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
        "\n",
        "\n",
        "def get_sentence_vector_zh(line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = wv_from_bin[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    vectors = np.array(vectors)\n",
        "    return np.mean(vectors, axis=0)  \n",
        "\n",
        "\n",
        "def processing_zh(sentence):\n",
        "  seg_list = jieba.lcut(sentence,cut_all=True)\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  docs = [e for e in doc if e.isalnum()]\n",
        "  return docs\n",
        "\n",
        "\n",
        "def get_sentence_embeddings_zh(f):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_sentence_vector_zh(sent)\n",
        "\n",
        "    if vec is None:\n",
        "      vec = np.zeros(100)\n",
        "    sentences_vectors.append(vec)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zVjor64tR8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "0215ea52-632a-4424-94f7-66c073b55c00"
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "\n",
        "zh_train_mt = get_sentence_embeddings_zh(\"./train.enzh.mt\")\n",
        "zh_train_src = get_embeddings(\"./train.enzh.src\",glove,nlp_en)\n",
        "f_train_scores = open(\"./train.enzh.scores\",'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "\n",
        "zh_val_src = get_embeddings(\"./dev.enzh.src\",glove,nlp_en)\n",
        "zh_val_mt = get_sentence_embeddings_zh(\"./dev.enzh.mt\")\n",
        "f_val_scores = open(\"./dev.enzh.scores\",'r')\n",
        "zh_val_scores = f_val_scores.readlines()\n",
        "\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.919 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-pXbaJzExaE",
        "colab_type": "code",
        "outputId": "3742b084-41cb-4fd6-bb36-a0a01c78efd3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(f\"Training mt: {len(zh_train_mt)} Training src: {len(zh_train_src)}\")\n",
        "print()\n",
        "print(f\"Validation mt: {len(zh_val_mt)} Validation src: {len(zh_val_src)}\")\n",
        "\n",
        "print(f\"CHI Dimension: {zh_train_mt[0].shape}\")\n",
        "print(f\"ENG Dimension: {zh_train_src[0].shape}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training mt: 7000 Training src: 7000\n",
            "\n",
            "Validation mt: 1000 Validation src: 1000\n",
            "CHI Dimension: (100,)\n",
            "ENG Dimension: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljBHJpa9ATNf",
        "colab_type": "code",
        "outputId": "b11a5fe1-01a5-4e1a-c74d-feae341077c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X_train= [zh_train_src, zh_train_mt]\n",
        "# X_train_zh = np.array(X_train).transpose()\n",
        "X_train_zh = np.array([np.concatenate((src, mt)) for src, mt in zip(*X_train)])\n",
        "print('X_train_zh.shape', X_train_zh.shape)\n",
        "\n",
        "X_val = [np.array(zh_val_src),np.array(zh_val_mt)]\n",
        "# X_val_zh = np.array(X_val).transpose()\n",
        "X_val_zh = np.array([np.concatenate((src, mt)) for src, mt in zip(*X_val)])\n",
        "print('X_val_zh.shape', X_val_zh.shape)\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh = train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh =val_scores\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train_zh.shape (7000, 200)\n",
            "X_val_zh.shape (1000, 200)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFDUyJdecIzw",
        "colab_type": "text"
      },
      "source": [
        "### Feed-Forward Neural Network\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jw2OmJRQARoz",
        "colab_type": "text"
      },
      "source": [
        "#### Early stopping\n",
        "Sourced from https://github.com/Bjarten/early-stopping-pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NcCagQgATdz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class EarlyStopping:\n",
        "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
        "    def __init__(self, patience=7, verbose=False, delta=0):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            patience (int): How long to wait after last time validation loss improved.\n",
        "                            Default: 7\n",
        "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
        "                            Default: False\n",
        "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
        "                            Default: 0\n",
        "        \"\"\"\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = np.Inf\n",
        "        self.delta = delta\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "\n",
        "        score = -val_loss\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        '''Saves model when validation loss decrease.'''\n",
        "        if self.verbose:\n",
        "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
        "        torch.save(model.state_dict(), 'checkpoint.pt')\n",
        "        self.val_loss_min = val_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvNt77KGcPYf",
        "colab_type": "text"
      },
      "source": [
        "#### Defining the network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QfJJmzkcSZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class FFNN(torch.nn.Module):\n",
        "    def __init__(self, n_features, *hidden_layers):\n",
        "        super().__init__()\n",
        "        prev = n_features\n",
        "        self.hidden_layers = []\n",
        "        for i, hidden in enumerate(hidden_layers):\n",
        "            layer = torch.nn.Linear(prev, hidden)\n",
        "            self.hidden_layers.append(layer)\n",
        "            setattr(self, f'hidden_{i}', layer)\n",
        "\n",
        "            prev = hidden\n",
        "        self.predict = torch.nn.Linear(prev, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        for hidden in self.hidden_layers:\n",
        "            x = F.relu(hidden(x))\n",
        "        return self.predict(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CC8WC64ydBhU",
        "colab_type": "text"
      },
      "source": [
        "#### Construct network with hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4vpzg2rdBII",
        "colab_type": "code",
        "outputId": "e899a0e2-4d11-4057-943f-e4aab2628e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "def RMSELoss(yhat,y):\n",
        "    return torch.sqrt(torch.mean((yhat-y)**2))\n",
        "\n",
        "def PearsonLoss(x, y):\n",
        "    vx = x - torch.mean(x)\n",
        "    vy = y - torch.mean(y)\n",
        "    cost = torch.sum(vx * vy) / (torch.sqrt(torch.sum(vx ** 2)) * torch.sqrt(torch.sum(vy ** 2)))\n",
        "    return -cost\n",
        "\n",
        "EMBEDDING_DIMENSION = 100\n",
        "HIDDEN_LAYERS = [100]\n",
        "LR = 0.001\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "model = FFNN(2 * EMBEDDING_DIMENSION, *HIDDEN_LAYERS)\n",
        "print(model)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "print(optimizer)\n",
        "\n",
        "# loss_fn = torch.nn.MSELoss()\n",
        "# loss_fn = RMSELoss\n",
        "loss_fn = PearsonLoss\n",
        "print(loss_fn)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (hidden_0): Linear(in_features=200, out_features=100, bias=True)\n",
            "  (predict): Linear(in_features=100, out_features=1, bias=True)\n",
            ")\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    eps: 1e-08\n",
            "    lr: 0.001\n",
            "    weight_decay: 0\n",
            ")\n",
            "<function PearsonLoss at 0x7f9d55b021e0>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI01KF3JdW9U",
        "colab_type": "text"
      },
      "source": [
        "#### Train network\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnf4yv-wdYF4",
        "colab_type": "code",
        "outputId": "6aa3f525-d7d9-4f0f-ed5a-e55661b4f129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "X_train_zh_tensor = torch.from_numpy(X_train_zh).type(torch.FloatTensor)\n",
        "Y_train_zh = torch.from_numpy(train_scores).type(torch.FloatTensor)\n",
        "\n",
        "X_val_zh_tensor = torch.from_numpy(X_val_zh).type(torch.FloatTensor)\n",
        "Y_val_zh = torch.from_numpy(val_scores).type(torch.FloatTensor)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "pearsons = []\n",
        "\n",
        "early_stop = EarlyStopping(patience=5, verbose=True)\n",
        "\n",
        "final_epoch_count = 0\n",
        "for t in range(NUM_EPOCHS):\n",
        "    final_epoch_count += 1\n",
        "    prediction = model(X_train_zh_tensor).squeeze()\n",
        "    loss = loss_fn(prediction, Y_train_zh)\n",
        "    train_losses.append(loss.data.numpy())\n",
        "\n",
        "    # Clear gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Propagate loss\n",
        "    loss.backward()\n",
        "\n",
        "    # Apply gradients\n",
        "    optimizer.step()\n",
        "\n",
        "    # Compute validation loss\n",
        "    val_prediction = model(X_val_zh_tensor).squeeze()\n",
        "    val_loss = loss_fn(val_prediction, Y_val_zh)\n",
        "    val_losses.append(val_loss.data.numpy())\n",
        "\n",
        "    pearson_coeff = pearsonr(Y_val_zh.detach(), val_prediction.detach())\n",
        "    pearsons.append(pearson_coeff[0])\n",
        "\n",
        "    early_stop(val_loss, model)\n",
        "    if early_stop.early_stop:\n",
        "        print('early stopping')\n",
        "        print('Val loss:', val_losses[-1])\n",
        "        print('Val Pearson:', pearson_coeff[0])\n",
        "        break\n",
        "    \n",
        "epochs = np.arange(final_epoch_count)\n",
        "plt.figure(figsize=(10, 20))\n",
        "plt.subplot(2, 1, 1)\n",
        "ax1 = plt.gca()\n",
        "ax1.set_xlabel('epochs')\n",
        "ax1.set_ylabel('training MSE', color='tab:red')\n",
        "ax1.plot(epochs, train_losses, color='tab:red', label='training loss')\n",
        "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.set_ylabel('validation MSE', color='tab:blue')\n",
        "ax2.plot(epochs, val_losses, color='tab:blue', label='validation loss')\n",
        "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "ax = plt.gca()\n",
        "ax.set_xlabel('epochs')\n",
        "ax.set_ylabel('pearson')\n",
        "ax.plot(epochs, pearsons, label='validation')\n",
        "ax.tick_params(axis='y')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss decreased (inf --> -0.081698).  Saving model ...\n",
            "Validation loss decreased (-0.081698 --> -0.140743).  Saving model ...\n",
            "Validation loss decreased (-0.140743 --> -0.175919).  Saving model ...\n",
            "Validation loss decreased (-0.175919 --> -0.199532).  Saving model ...\n",
            "Validation loss decreased (-0.199532 --> -0.216694).  Saving model ...\n",
            "Validation loss decreased (-0.216694 --> -0.230098).  Saving model ...\n",
            "Validation loss decreased (-0.230098 --> -0.241341).  Saving model ...\n",
            "Validation loss decreased (-0.241341 --> -0.250709).  Saving model ...\n",
            "Validation loss decreased (-0.250709 --> -0.258606).  Saving model ...\n",
            "Validation loss decreased (-0.258606 --> -0.265461).  Saving model ...\n",
            "Validation loss decreased (-0.265461 --> -0.271598).  Saving model ...\n",
            "Validation loss decreased (-0.271598 --> -0.277231).  Saving model ...\n",
            "Validation loss decreased (-0.277231 --> -0.282605).  Saving model ...\n",
            "Validation loss decreased (-0.282605 --> -0.287849).  Saving model ...\n",
            "Validation loss decreased (-0.287849 --> -0.293034).  Saving model ...\n",
            "Validation loss decreased (-0.293034 --> -0.297978).  Saving model ...\n",
            "Validation loss decreased (-0.297978 --> -0.302652).  Saving model ...\n",
            "Validation loss decreased (-0.302652 --> -0.306871).  Saving model ...\n",
            "Validation loss decreased (-0.306871 --> -0.310744).  Saving model ...\n",
            "Validation loss decreased (-0.310744 --> -0.314415).  Saving model ...\n",
            "Validation loss decreased (-0.314415 --> -0.317806).  Saving model ...\n",
            "Validation loss decreased (-0.317806 --> -0.320933).  Saving model ...\n",
            "Validation loss decreased (-0.320933 --> -0.323990).  Saving model ...\n",
            "Validation loss decreased (-0.323990 --> -0.326951).  Saving model ...\n",
            "Validation loss decreased (-0.326951 --> -0.329700).  Saving model ...\n",
            "Validation loss decreased (-0.329700 --> -0.332163).  Saving model ...\n",
            "Validation loss decreased (-0.332163 --> -0.334533).  Saving model ...\n",
            "Validation loss decreased (-0.334533 --> -0.336787).  Saving model ...\n",
            "Validation loss decreased (-0.336787 --> -0.338671).  Saving model ...\n",
            "Validation loss decreased (-0.338671 --> -0.340180).  Saving model ...\n",
            "Validation loss decreased (-0.340180 --> -0.341459).  Saving model ...\n",
            "Validation loss decreased (-0.341459 --> -0.342717).  Saving model ...\n",
            "Validation loss decreased (-0.342717 --> -0.344051).  Saving model ...\n",
            "Validation loss decreased (-0.344051 --> -0.344967).  Saving model ...\n",
            "Validation loss decreased (-0.344967 --> -0.345706).  Saving model ...\n",
            "Validation loss decreased (-0.345706 --> -0.346315).  Saving model ...\n",
            "Validation loss decreased (-0.346315 --> -0.346727).  Saving model ...\n",
            "Validation loss decreased (-0.346727 --> -0.347093).  Saving model ...\n",
            "Validation loss decreased (-0.347093 --> -0.347125).  Saving model ...\n",
            "EarlyStopping counter: 1 out of 5\n",
            "EarlyStopping counter: 2 out of 5\n",
            "EarlyStopping counter: 3 out of 5\n",
            "EarlyStopping counter: 4 out of 5\n",
            "EarlyStopping counter: 5 out of 5\n",
            "early stopping\n",
            "Val loss: -0.3452872\n",
            "Val Pearson: 0.3452871765344765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAp0AAARsCAYAAADcyy24AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/X9Rw4gjDIX6ZQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x1440 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luNEyefram7Z",
        "colab_type": "text"
      },
      "source": [
        "### Training the Regressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvCS6pa-yIIB",
        "colab_type": "text"
      },
      "source": [
        "At this point,  will try SVM and Random Tree Forests and choose the model with the highest Pearson correlation.\n",
        "\n",
        "First we will define our RMSE function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USalvKtRAvQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0wOEUhXgteG",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rY29AeVyM1n",
        "colab_type": "text"
      },
      "source": [
        "SVM have many parameters such as the kernel and the regularizating constant C. Here we will use default C = 1 and compare kernels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf_aJK0QK8jx",
        "colab_type": "code",
        "outputId": "04dfcc6c-585c-4723-f684-31ecd78c1eb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "bestPearson = None\n",
        "bestConfig = None\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    for C in (0.2, 0.4, 1, 2, 4):\n",
        "        clf_t = SVR(kernel=k, C=C)\n",
        "        clf_t.fit(X_train_zh, y_train_zh)\n",
        "        print(k, C)\n",
        "        predictions = clf_t.predict(X_val_zh)\n",
        "        pearson = pearsonr(y_val_zh, predictions)[0]\n",
        "        print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson}')\n",
        "\n",
        "        if bestPearson is None or pearson > bestPearson:\n",
        "            bestPearson = pearson\n",
        "            bestConfig = k, C\n",
        "        print()\n",
        "\n",
        "bestK, bestC = bestConfig\n",
        "clf_t = SVR(kernel=bestK, C=bestC)\n",
        "clf_t.fit(X_train_zh, y_train_zh)\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear 0.2\n",
            "RMSE: 0.9035320509012135 Pearson 0.30622008178817545\n",
            "\n",
            "linear 0.4\n",
            "RMSE: 0.9040521351105631 Pearson 0.3033623379930261\n",
            "\n",
            "linear 1\n",
            "RMSE: 0.9044962563186333 Pearson 0.3017781690203462\n",
            "\n",
            "linear 2\n",
            "RMSE: 0.9048260331567677 Pearson 0.3008472264774782\n",
            "\n",
            "linear 4\n",
            "RMSE: 0.9049826458624196 Pearson 0.30042163788659104\n",
            "\n",
            "poly 0.2\n",
            "RMSE: 0.9043605671606837 Pearson 0.31586252037459067\n",
            "\n",
            "poly 0.4\n",
            "RMSE: 0.8995699211236549 Pearson 0.3118372903581591\n",
            "\n",
            "poly 1\n",
            "RMSE: 0.8990697909416231 Pearson 0.3032902746054339\n",
            "\n",
            "poly 2\n",
            "RMSE: 0.9075715964937792 Pearson 0.286510128849544\n",
            "\n",
            "poly 4\n",
            "RMSE: 0.929952123966458 Pearson 0.2678421875950589\n",
            "\n",
            "rbf 0.2\n",
            "RMSE: 0.9018144373665977 Pearson 0.3442131860207905\n",
            "\n",
            "rbf 0.4\n",
            "RMSE: 0.8954964929623576 Pearson 0.3484684017053316\n",
            "\n",
            "rbf 1\n",
            "RMSE: 0.8900985622788053 Pearson 0.3403404558003603\n",
            "\n",
            "rbf 2\n",
            "RMSE: 0.8887542020561985 Pearson 0.3287840952404997\n",
            "\n",
            "rbf 4\n",
            "RMSE: 0.8928514327571292 Pearson 0.3132071159701992\n",
            "\n",
            "sigmoid 0.2\n",
            "RMSE: 1.2448504776711637 Pearson 0.08636310069714556\n",
            "\n",
            "sigmoid 0.4\n",
            "RMSE: 2.7101436589662655 Pearson -0.023866260932673765\n",
            "\n",
            "sigmoid 1\n",
            "RMSE: 7.152607007355879 Pearson -0.03977439348067312\n",
            "\n",
            "sigmoid 2\n",
            "RMSE: 14.463860427106784 Pearson -0.042871941184928375\n",
            "\n",
            "sigmoid 4\n",
            "RMSE: 29.06551603802235 Pearson -0.04629851336496812\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVR(C=0.4, cache_size=200, coef0=0.0, degree=3, epsilon=0.1, gamma='scale',\n",
              "    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaOP4zpOgkFP",
        "colab_type": "text"
      },
      "source": [
        "In this case, the radial basis function kernel performed the best with a Pearson correlation of 0.1147. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtg69eGbgmHI",
        "colab_type": "text"
      },
      "source": [
        "#### Random Tree Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD22DmWvyPs-",
        "colab_type": "text"
      },
      "source": [
        "Another powerful regressor is the Random Tree Forest. Here we have to choose the number of trees we want to compute and we will pick n_estimators = 1000. The higher the number the longer it will compute. To fine tune that number you could compute the error per number of trees and select the number for which there is no more significant improvement( the \"elbow\" of the graph)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wEoExkggqHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the model we are using\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666)\n",
        "rf.fit(X_train_zh, y_train_zh);\n",
        "predictions = rf.predict(X_val_zh)\n",
        "\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_zh))\n",
        "print(f\"Pearson {pearson[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWiQ2X6Lj3iG",
        "colab_type": "text"
      },
      "source": [
        "Finally, we see that SVM with RBF kernel is the best model here. We will now use it to predict on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuIsX8LNiOJm",
        "colab_type": "text"
      },
      "source": [
        "### Writing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQlcfiCITuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC3ALWVEXYVi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fefd85b0-b198-498d-870a-b14b10887a82"
      },
      "source": [
        "#EN_ZH\n",
        "\n",
        "zh_test_mt = get_sentence_embeddings_zh(\"./test.enzh.mt\")\n",
        "zh_test_src = get_embeddings(\"./test.enzh.src\",glove,nlp_en)\n",
        "\n",
        "X_test = [np.array(zh_test_mt),np.array(zh_test_src)]\n",
        "\n",
        "X_test_zh = np.array([np.concatenate((src, mt)) for src, mt in zip(*X_test)])\n",
        "print(X_test_zh.shape)\n",
        "\n",
        "#Predict\n",
        "# clf_zh = SVR(kernel='rbf')\n",
        "# clf_zh.fit(X_train_zh, y_train_zh)\n",
        "\n",
        "X_test_zh_tensor = torch.from_numpy(X_test_zh).type(torch.FloatTensor)\n",
        "predictions_zh = model(X_test_zh_tensor).squeeze()\n",
        "writeScores('', predictions_zh)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 200)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-nDAsi3Xt-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EN_ZH\n",
        "\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"SVR\",predictions_zh)\n",
        "\n",
        "with ZipFile(\"en-zh_svr.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-zh_svr.zip') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlGblmKPyUFr",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWUSJ7kAyXxC",
        "colab_type": "text"
      },
      "source": [
        "Once submitted to codalab, the pearson correlation is 0.0795"
      ]
    }
  ]
}