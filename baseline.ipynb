{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coursework_baseline.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omEQHVdOS61G",
        "colab_type": "text"
      },
      "source": [
        "# Coursework: Baseline Model\n",
        "\n",
        "This notebook takes you step by step to the implementation of a simple baseline model to get you started on the coursework. You have a section for the English-German task and another for English-Chinese. They are made to be standalone so feel free to check only one of the sections. However, as the tasks require slighlty different approaches, going through both sections could help you to get inspired for your chosen task, especially each task processes english in a slighlty different way.\n",
        "\n",
        "Enjoy!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lweXud1Wpemd",
        "colab_type": "text"
      },
      "source": [
        "## A. English-German"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu6s3YOf_C93",
        "colab_type": "text"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scs7ICZrPFcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download and unzip the data\n",
        "from os.path import exists\n",
        "if not exists('ende_data.zip'):\n",
        "    !wget -O ende_data.zip https://competitions.codalab.org/my/datasets/download/c748d2c0-d6be-4e36-9f12-ca0e88819c4d\n",
        "    !unzip ende_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPy_iwHnOSAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Check the files\n",
        "import io\n",
        "\n",
        "#English-German\n",
        "print(\"---EN-DE---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.ende.src\", \"r\") as ende_src:\n",
        "  print(\"Source: \",ende_src.readline())\n",
        "with open(\"./train.ende.mt\", \"r\") as ende_mt:\n",
        "  print(\"Translation: \",ende_mt.readline())\n",
        "with open(\"./train.ende.scores\", \"r\") as ende_scores:\n",
        "  print(\"Score: \",ende_scores.readline())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiFHVnfH_Jpv",
        "colab_type": "text"
      },
      "source": [
        "### Computing Sentence Embeddings "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g05fv5GiSyQ4",
        "colab_type": "text"
      },
      "source": [
        "For this baseline model, we will simply use pre-trained GloVe embeddings via the Spacy module and compute the vector for each word and take the global mean for each sentence. We will do the same for both source and translation sentences. For chinese tokenization and embeddings we will have to find other tools.\n",
        "\n",
        "This is a very simplistic approach so feel free to be more creative and play around with how the sentence embeddings are computed for example ;)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcjZpNlra8TD",
        "colab_type": "text"
      },
      "source": [
        "GloVe embeddings do not support the Chinese language so in the section of the English-Chinese task we will have to download pretrained Chinese embeddings from word2vec repositories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96bRtBbuZLJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Downloading spacy models for english and german\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300\n",
        "\n",
        "!spacy download de_core_news_md\n",
        "!spacy link de_core_news_md de300"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Om6kQX5bX2mB",
        "colab_type": "text"
      },
      "source": [
        "We can now write our functions that will return the average embeddings for a sentence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhT2I6WYavY4",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing with Spacy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19gsNCgnW8ZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import spacy\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "stop_words_de = set(stopwords.words('german'))\n",
        "\n",
        "def get_sentence_emb(line,nlp,lang):\n",
        "  if lang == 'en':\n",
        "    text = line.lower()\n",
        "    l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "    l = ' '.join([word for word in l if word not in stop_words_en])\n",
        "\n",
        "  elif lang == 'de':\n",
        "    text = line.lower()\n",
        "    l = [token.lemma_ for token in nlp.tokenizer(text)]\n",
        "    l= ' '.join([word for word in l if word not in stop_words_de])\n",
        "\n",
        "  sen = nlp(l)\n",
        "  return sen.vector\n",
        "\n",
        "def get_embeddings(f,nlp,lang):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "      vec = get_sentence_emb(l,nlp,lang)\n",
        "      if vec is not None:\n",
        "        vec = np.mean(vec)\n",
        "        sentences_vectors.append(vec)\n",
        "      else:\n",
        "        print(\"didn't work :\", l)\n",
        "        sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUKMgbo2sreI",
        "colab_type": "text"
      },
      "source": [
        "#### Getting Training and Validation Sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXqZamIKs30T",
        "colab_type": "text"
      },
      "source": [
        "We will now run the code fo the English-German translations and getting our training and validation sets ready for the regression task.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyJr7cIkQ3E8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp_de =spacy.load('de300')\n",
        "nlp_en =spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LwoUIDj0otbf",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "#EN-DE files\n",
        "de_train_src = get_embeddings(\"./train.ende.src\",nlp_en,'en')\n",
        "de_train_mt = get_embeddings(\"./train.ende.mt\",nlp_de,'de')\n",
        "\n",
        "f_train_scores = open(\"./train.ende.scores\",'r')\n",
        "de_train_scores = f_train_scores.readlines()\n",
        "\n",
        "de_val_src = get_embeddings(\"./dev.ende.src\",nlp_en,'en')\n",
        "de_val_mt = get_embeddings(\"./dev.ende.mt\",nlp_de,'de')\n",
        "f_val_scores = open(\"./dev.ende.scores\",'r')\n",
        "de_val_scores = f_val_scores.readlines()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_K1CHl5VxiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#EN-DE\n",
        "print(f\"Training mt: {len(de_train_mt)} Training src: {len(de_train_src)}\")\n",
        "print()\n",
        "print(f\"Validation mt: {len(de_val_mt)} Validation src: {len(de_val_src)}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Px7ikaGoy9r0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Put the features into a list\n",
        "X_train= [np.array(de_train_src),np.array(de_train_mt)]\n",
        "X_train_de = np.array(X_train).transpose()\n",
        "\n",
        "X_val = [np.array(de_val_src),np.array(de_val_mt)]\n",
        "X_val_de = np.array(X_val).transpose()\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(de_train_scores).astype(float)\n",
        "y_train_de =train_scores\n",
        "\n",
        "val_scores = np.array(de_val_scores).astype(float)\n",
        "y_val_de =val_scores\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFp6yyBl4Kgf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# RUN IF WANT TO HAVE AVERAGE VECTOR(AND NOT GLOBAL MEAN), THIS GAVE WORSE PERFORMANCE THAN GLOBAL MEAN\n",
        "'''\n",
        "\n",
        "X_train= [np.array(train_src),np.array(train_mt)]\n",
        "X_train = np.array(X_train)\n",
        "\n",
        "\n",
        "X_test = [np.array(test_src),np.array(test_mt)]\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "\n",
        "#Reshaping if using shape >3\n",
        "nsamples, nx, ny = X_train.shape\n",
        "X_train = X_train.reshape((nx,ny*nsamples))\n",
        "\n",
        "nsamples, nx, ny = X_test.shape\n",
        "X_test = X_test.reshape((nx,ny*nsamples))\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(train_scores).astype(float)\n",
        "y_train =train_scores\n",
        "\n",
        "test_scores = np.array(test_scores).astype(float)\n",
        "y_test =test_scores\n",
        "'''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSIE7d8HCTpi",
        "colab_type": "text"
      },
      "source": [
        "### Training the Regressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eoY14lNCTe3",
        "colab_type": "text"
      },
      "source": [
        "At this point,  will try SVM and Random Tree Forests and choose the model with the highest Pearson correlation.\n",
        "\n",
        "First we will define our RMSE function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRcegRvW2F2q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IerDa2251swL",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exHbrWtq14jm",
        "colab_type": "text"
      },
      "source": [
        "SVM have many parameters such as the kernel and the regularizating constant C. Here we will use C = 1 and compare kernels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiHCkGUgsJ8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    clf_t.fit(X_train_de, y_train_de)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_de)\n",
        "    pearson = pearsonr(y_val_de, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_de)} Pearson {pearson[0]}')\n",
        "    print()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1Fr1RLm3-Kc",
        "colab_type": "text"
      },
      "source": [
        "Here the best kernel seems to be the polynomial one as it gives us the highest pearson correlation at 0.062."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qg9YSBUG1zaL",
        "colab_type": "text"
      },
      "source": [
        "#### Random Tree Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Au88fVS33K4W",
        "colab_type": "text"
      },
      "source": [
        "Another powerful regressor is the Random Tree Forest. Here we have to choose the number of trees we want to compute and we will pick n_estimators = 1000. The higher the number the longer it will compute. To fine tune that number you could compute the error per number of trees and select the number for which there is no more significant improvement( the \"elbow\" of the graph)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOld4zbmsOGL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the model we are using\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666)\n",
        "\n",
        "rf.fit(X_train_de, y_train_de);\n",
        "\n",
        "\n",
        "predictions = rf.predict(X_val_de)\n",
        "\n",
        "pearson = pearsonr(y_val_de, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_de))\n",
        "print(f\"Pearson {pearson[0]}\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L73jhAc6ZoM",
        "colab_type": "text"
      },
      "source": [
        "In this case, it seems like the SVM with a linear kernel performed the best on our validation set so we will save that model for the test set predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9puD_0zkC2c",
        "colab_type": "text"
      },
      "source": [
        "### Writing Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQvvIhPDkUnR",
        "colab_type": "text"
      },
      "source": [
        "Here is our function to write the scores into a txt file. We can follow the <Method> <ID> <SCORE> template but having only the scores will work too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN3NtkF4kPxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVss_RLBkFei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EN-DE\n",
        "\n",
        "de_test_src = get_embeddings(\"./test.ende.src\",nlp_en,'en')\n",
        "de_test_mt = get_embeddings(\"./test.ende.mt\",nlp_de,'de')\n",
        "\n",
        "X= [np.array(de_test_src),np.array(de_test_mt)]\n",
        "X_test = np.array(X).transpose()\n",
        "\n",
        "#Predict\n",
        "clf_de = SVR(kernel='rbf')\n",
        "clf_de.fit(X_train_de, y_train_de)\n",
        "\n",
        "predictions_de = clf_de.predict(X_val_de)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWnNUR0Gku_9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"SVR\",predictions_de)\n",
        "\n",
        "with ZipFile(\"en-de_svr.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-de_svr.zip') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyaM_P0bynB-",
        "colab_type": "text"
      },
      "source": [
        "### Results\n",
        "\n",
        "Once submitted to codalab, the pearson correlation is 0.0052."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3obhUYW5ptUS",
        "colab_type": "text"
      },
      "source": [
        "##B. English-Chinese\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OE9wypehaLrZ",
        "colab_type": "text"
      },
      "source": [
        "### Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5y34iNipyr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os.path import exists\n",
        "\n",
        "if not exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlXMiqJXq8fy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "3aa3f8fb-31cd-4e57-d21c-8a1c8ec52b07"
      },
      "source": [
        "#English-Chinese\n",
        "#Checking Data\n",
        "print(\"---EN-ZH---\")\n",
        "print()\n",
        "\n",
        "with open(\"./train.enzh.src\", \"r\") as enzh_src:\n",
        "  print(\"Source: \",enzh_src.readline())\n",
        "with open(\"./train.enzh.mt\", \"r\") as enzh_mt:\n",
        "  print(\"Translation: \",enzh_mt.readline())\n",
        "with open(\"./train.enzh.scores\", \"r\") as enzh_scores:\n",
        "  print(\"Score: \",enzh_scores.readline())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---EN-ZH---\n",
            "\n",
            "Source:  The last conquistador then rides on with his sword drawn.\n",
            "\n",
            "Translation:  最后的征服者骑着他的剑继续前进.\n",
            "\n",
            "Score:  -1.5284005772625449\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlOd_5a6aTVP",
        "colab_type": "text"
      },
      "source": [
        "### Computing Sentence Embeddings\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZgqjMa_wu0xz",
        "colab_type": "text"
      },
      "source": [
        "For this task, we will compute the embeddings for words in a sentence in one language and compute the global mean for that sentence, and do the same for the other language. However, we will have to find and download pre-traind embeddings for Chinese as Spacy nor GloVe handle it. The embeddings we will be using for Chinese are of dimension 100, therefore we need to adapt the embeddings for english from the dim 300 to 100. Glove does have English embeddings of dim 100 but Spacy does not have that model. So, we will tokenize the sentences using Spacy tokenizer and use GloVe directly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsKYMxCSolrx",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing English with GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd24p41jkv7N",
        "colab_type": "text"
      },
      "source": [
        "With GloVe's function *stoi()* (string to int) we can get the index corresponding to a given word and with the function *itos()* we get the word given its index. To obtain the vector of a word we first get the integer associated with it and then index it into the word embedding tensor with that index. Note that glove takes words in a lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lc4rdJnrE_Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "cb029a5a-93cb-4f33-ed55-88063d4a1b3d"
      },
      "source": [
        "# DON'T RUN IF YOU ALREADY RAN IT IN THE ENGLISH-GERMAN SECTION\n",
        "# Downloading spacy models for english\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\n",
            "\u001b[38;5;1m✘ Link 'en300' already exists\u001b[0m\n",
            "To overwrite an existing link, use the --force flag\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fx3Ja9zWFDj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torchtext\n",
        "import spacy\n",
        "\n",
        "#Embeddings\n",
        "glove = torchtext.vocab.GloVe(name='6B', dim=100)\n",
        "\n",
        "#tokenizer model\n",
        "nlp_en =spacy.load('en300')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxjmj7vUv08E",
        "colab_type": "text"
      },
      "source": [
        "We can now write our functions that will return the average embeddings for a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BUi2QiCIi9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e4972905-b881-438e-8380-81f3ca24fe58"
      },
      "source": [
        "#ENGLISH EMBEDDINGS methods from the section GERMAN-ENGLISH\n",
        "# The difference from previous section is that we will use Glove embeddings directly because we are using a smaller model that spacy doesn't have\n",
        "# We add a method to compute the word embedding and a method to compute the sentence embedding by averaging the word vectors\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "#downloading stopwords from the nltk package\n",
        "download('stopwords') #stopwords dictionary, run once\n",
        "stop_words_en = set(stopwords.words('english'))\n",
        "\n",
        "\n",
        "def preprocess(sentence,nlp):\n",
        "    text = sentence.lower()\n",
        "    doc = [token.lemma_ for token in  nlp.tokenizer(text)]\n",
        "    doc = [word for word in doc if word not in stop_words_en]\n",
        "    doc = [word for word in doc if word.isalpha()] #restricts string to alphabetic characters only\n",
        "    return doc\n",
        "\n",
        "def get_word_vector(embeddings, word):\n",
        "    try:\n",
        "      vec = embeddings.vectors[embeddings.stoi[word]]\n",
        "      return vec\n",
        "    except KeyError:\n",
        "      print(f\"Word {word} does not exist\")\n",
        "      pass\n",
        "\n",
        "def get_sentence_vector(embeddings,line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    emb = get_word_vector(embeddings,w)\n",
        "    #do not add if the word is out of vocabulary\n",
        "    if emb is not None:\n",
        "      vectors.append(emb)\n",
        "   \n",
        "  return torch.mean(torch.stack(vectors), 0).numpy()\n",
        "\n",
        "\n",
        "def get_embeddings(f,embeddings,lang):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "\n",
        "  for l in lines:\n",
        "    sentence= preprocess(l,lang)\n",
        "    try:\n",
        "      vec = get_sentence_vector(embeddings,sentence)\n",
        "      if vec is not None:\n",
        "        sentences_vectors.append(vec)\n",
        "    except Exception as e:\n",
        "      print(e, vec)\n",
        "      # sentences_vectors.append(0)\n",
        "\n",
        "  return sentences_vectors\n"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4JnbxSaaasu",
        "colab_type": "text"
      },
      "source": [
        "#### Loading Chinese Word2Vec Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3-NpUxd52nP",
        "colab_type": "text"
      },
      "source": [
        "We now have to download the pre-trained embeddings for Chinese. We will get them from the University of Oslo NLPL repository (http://vectors.nlpl.eu/repository/), which has word2vec vectors of dimension 100.\n",
        "\n",
        " We will also get Chinese stop words from https://github.com/Tony607/Chinese_sentiment_analysis.\n",
        "\n",
        "For embeddings of dimensions 300 you can find them searching on github repositories. One example is https://github.com/Kyubyong/wordvectors.\n",
        "\n",
        "If you want to work on colab and download other embeddings I would suggest you download the file and upload it on your dropbox and get the link from there.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jW3S2-rs6BV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "f562a27f-1e82-40e4-fc03-ea7bfc4bd882"
      },
      "source": [
        "\n",
        "!wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "!wget -O zh.zip http://vectors.nlpl.eu/repository/20/35.zip\n",
        "\n",
        "!unzip zh.zip \n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-06 10:42:27--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 192.30.253.113\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "chinese_stop_words.     [   <=>              ] 416.89K   478KB/s    in 0.9s    \n",
            "\n",
            "2020-02-06 10:42:29 (478 KB/s) - ‘chinese_stop_words.txt’ saved [426900]\n",
            "\n",
            "--2020-02-06 10:42:32--  http://vectors.nlpl.eu/repository/20/35.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1458485917 (1.4G) [application/zip]\n",
            "Saving to: ‘zh.zip’\n",
            "\n",
            "zh.zip              100%[===================>]   1.36G  9.60MB/s    in 2m 35s  \n",
            "\n",
            "2020-02-06 10:45:07 (8.95 MB/s) - ‘zh.zip’ saved [1458485917/1458485917]\n",
            "\n",
            "Archive:  zh.zip\n",
            "replace LIST? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "replace meta.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: N\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQM6Go4rEe9N",
        "colab_type": "text"
      },
      "source": [
        "We now load the pre-trained word2vec embeddings we downloaded using the gensim package. More info on gensim and how to use it to load models and embeddings here https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDUbXQ4aMv1K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "6407043e-f1c7-490b-a34e-a12cb671e54e"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "wv_from_bin = KeyedVectors.load_word2vec_format(\"model.bin\", binary=True) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhZ3HtrdodcW",
        "colab_type": "text"
      },
      "source": [
        "#### Pre-processing Chinese"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "her8c6oJFWAa",
        "colab_type": "text"
      },
      "source": [
        "For pre-processing chinese sentence we will use the tokenizer package for chinese called jieba and use the downloaded list of chinese stop words to remove them from our tokens. More info on jieba and its options at https://github.com/fxsjy/jieba. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LA9N1zgsSQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import string\n",
        "import jieba\n",
        "import gensim \n",
        "import spacy\n",
        "import numpy as np\n",
        "\n",
        "stop_words = [ line.rstrip() for line in open('./chinese_stop_words.txt',\"r\", encoding=\"utf-8\") ]\n",
        "\n",
        "\n",
        "def get_sentence_vector_zh(line):\n",
        "  vectors = []\n",
        "  for w in line:\n",
        "    try:\n",
        "      emb = wv_from_bin[w]\n",
        "      vectors.append(emb)\n",
        "    except:\n",
        "      pass #Do not add if the word is out of vocabulary\n",
        "  if vectors:\n",
        "    vectors = np.array(vectors)\n",
        "    return np.mean(vectors, axis=0)  \n",
        "\n",
        "\n",
        "def processing_zh(sentence):\n",
        "  seg_list = jieba.lcut(sentence,cut_all=True)\n",
        "  doc = [word for word in seg_list if word not in stop_words]\n",
        "  docs = [e for e in doc if e.isalnum()]\n",
        "  return docs\n",
        "\n",
        "\n",
        "def get_sentence_embeddings_zh(f):\n",
        "  file = open(f) \n",
        "  lines = file.readlines() \n",
        "  sentences_vectors =[]\n",
        "  for l in lines:\n",
        "    sent  = processing_zh(l)\n",
        "    vec = get_sentence_vector_zh(sent)\n",
        "\n",
        "    if vec is not None:\n",
        "      sentences_vectors.append(vec)\n",
        "    else:\n",
        "      print(l)\n",
        "  return sentences_vectors\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zVjor64tR8D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c8a5f736-fa74-4af0-fe86-455ffee14640"
      },
      "source": [
        "import spacy\n",
        "import torchtext\n",
        "from torchtext import data\n",
        "\n",
        "\n",
        "zh_train_mt = get_sentence_embeddings_zh(\"./train.enzh.mt\")\n",
        "zh_train_src = get_embeddings(\"./train.enzh.src\",glove,nlp_en)\n",
        "f_train_scores = open(\"./train.enzh.scores\",'r')\n",
        "zh_train_scores = f_train_scores.readlines()\n",
        "\n",
        "\n",
        "zh_val_src = get_embeddings(\"./dev.enzh.src\",glove,nlp_en)\n",
        "zh_val_mt = get_sentence_embeddings_zh(\"./dev.enzh.mt\")\n",
        "f_val_scores = open(\"./dev.enzh.scores\",'r')\n",
        "zh_val_scores = f_val_scores.readlines()\n",
        "\n",
        "\n"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indra Shri Venkatesh Steel & Alloys Ltd 、 Lapanga Dayal Steels Ltd 、 Chaha Sri Ram Power & Steel Pvt.\n",
            "\n",
            "Danny Baker Aisling Bea Cariad Lloyd Sarah Millican\n",
            "\n",
            "Egan, Charles E., \"U. S. Curbs Exportof Steel\".\n",
            "\n",
            "Word walkamerica does not exist\n",
            "Word kyrgios does not exist\n",
            "Word aggiornamento does not exist\n",
            "Word rymers does not exist\n",
            "Word physiopathology does not exist\n",
            "Word viviparity does not exist\n",
            "Word ovoviviparity does not exist\n",
            "Word átheos does not exist\n",
            "Word capullis does not exist\n",
            "Word alkhalifa does not exist\n",
            "Word mcvegan does not exist\n",
            "Word sallad does not exist\n",
            "Word unsheathe does not exist\n",
            "Word cochard does not exist\n",
            "Word ordelafo does not exist\n",
            "Word enactive does not exist\n",
            "Word argumenta does not exist\n",
            "Word linsanity does not exist\n",
            "Word windrip does not exist\n",
            "Word kustine does not exist\n",
            "Word sītā does not exist\n",
            "Word pārvatī does not exist\n",
            "Word neuravensburg does not exist\n",
            "Word ebringen does not exist\n",
            "Word norsingen does not exist\n",
            "Word neesty does not exist\n",
            "Word rugosities does not exist\n",
            "Word adamites does not exist\n",
            "Word hugetan does not exist\n",
            "Word yngvild does not exist\n",
            "Word palpability does not exist\n",
            "Word daughterhood does not exist\n",
            "Word wifehood does not exist\n",
            "Word tecombre does not exist\n",
            "Word reddle does not exist\n",
            "Word gorgodal does not exist\n",
            "Word contraluz does not exist\n",
            "Word toghtekin does not exist\n",
            "Word yeowell does not exist\n",
            "Word wheeltappers does not exist\n",
            "Word warmweed does not exist\n",
            "Word stavrogin does not exist\n",
            "Word macdonnel does not exist\n",
            "Word kikumoto does not exist\n",
            "Word unheimliche does not exist\n",
            "Word nestmate does not exist\n",
            "Word kepis does not exist\n",
            "Word futtocks does not exist\n",
            "Word futtocks does not exist\n",
            "Word calory does not exist\n",
            "Word hayriye does not exist\n",
            "Word aphthonius does not exist\n",
            "Word workbox does not exist\n",
            "Word moneyspider does not exist\n",
            "Word mcveggie does not exist\n",
            "Word yuranosuke does not exist\n",
            "Word kudayū does not exist\n",
            "Word kebap does not exist\n",
            "Word kebap does not exist\n",
            "Word gözleme does not exist\n",
            "Word kadaif does not exist\n",
            "Word kumpir does not exist\n",
            "Word mantı does not exist\n",
            "Word rakı does not exist\n",
            "Word arvina does not exist\n",
            "Word cazique does not exist\n",
            "Word greatheart does not exist\n",
            "Word nalgae does not exist\n",
            "Word myrtis does not exist\n",
            "Word dightman does not exist\n",
            "Word opitiis does not exist\n",
            "Word thouret does not exist\n",
            "Word bildergalerie does not exist\n",
            "Word isopi does not exist\n",
            "Word exostosis does not exist\n",
            "Word muérete does not exist\n",
            "Word verás does not exist\n",
            "Word exfiltrated does not exist\n",
            "Word smallsword does not exist\n",
            "Word ricasso does not exist\n",
            "Word moguntiacum does not exist\n",
            "Word disestablishments does not exist\n",
            "Word vexour does not exist\n",
            "Word outstretch does not exist\n",
            "Word hellraisers does not exist\n",
            "Word terga does not exist\n",
            "Word cribellum does not exist\n",
            "Word seishinjuu does not exist\n",
            "Word genseishin does not exist\n",
            "Word otariids does not exist\n",
            "Word strien does not exist\n",
            "Word delsin does not exist\n",
            "Word incoordination does not exist\n",
            "Word budoc does not exist\n",
            "Word leucher does not exist\n",
            "Word thuriau does not exist\n",
            "Word genévé does not exist\n",
            "Word paeon does not exist\n",
            "Word mouthpart does not exist\n",
            "Word batil does not exist\n",
            "Word patung does not exist\n",
            "Word sangwu does not exist\n",
            "Word baoheding does not exist\n",
            "Word pedalos does not exist\n",
            "Word subahu does not exist\n",
            "Word tataka does not exist\n",
            "Word maricha does not exist\n",
            "Word chemurgy does not exist\n",
            "Word tryphoninus does not exist\n",
            "Word ertzia does not exist\n",
            "Word cordaitales does not exist\n",
            "Word iulus does not exist\n",
            "Word consulari does not exist\n",
            "Word cystica does not exist\n",
            "Word nehelenia does not exist\n",
            "Word amazoness does not exist\n",
            "Word windcharger does not exist\n",
            "Word cumbrous does not exist\n",
            "Word parochet does not exist\n",
            "Word solieri does not exist\n",
            "Word hämmerlein does not exist\n",
            "Word tellerhäuser does not exist\n",
            "Word skarns does not exist\n",
            "Word ultimogeniture does not exist\n",
            "Word menuiserie does not exist\n",
            "Word pnei does not exist\n",
            "Word engria does not exist\n",
            "Word bonce does not exist\n",
            "Word reitel does not exist\n",
            "Word lapanga does not exist\n",
            "Word chaha does not exist\n",
            "Word imbed does not exist\n",
            "Word lindenhope does not exist\n",
            "Word luehrs does not exist\n",
            "Word memorabile does not exist\n",
            "Word okaru does not exist\n",
            "Word yuranosuke does not exist\n",
            "Word cayuelos does not exist\n",
            "Word kudari does not exist\n",
            "Word grasper does not exist\n",
            "Word grasper does not exist\n",
            "Word tumpang does not exist\n",
            "Word acetylides does not exist\n",
            "Word shikhandin does not exist\n",
            "Word gangaji does not exist\n",
            "Word qastal does not exist\n",
            "Word hexenwolf does not exist\n",
            "Word finnvox does not exist\n",
            "Word karmila does not exist\n",
            "Word ferhunde does not exist\n",
            "Word microaspiration does not exist\n",
            "Word bearfield does not exist\n",
            "Word ccbn does not exist\n",
            "Word radicalz does not exist\n",
            "Word pratunam does not exist\n",
            "Word akte does not exist\n",
            "Word onuczko does not exist\n",
            "Word heraclid does not exist\n",
            "Word puddler does not exist\n",
            "Word intermixture does not exist\n",
            "Word brawdy does not exist\n",
            "Word sternsheetsman does not exist\n",
            "Word coberger does not exist\n",
            "Word sinsollo does not exist\n",
            "Word oscillatorium does not exist\n",
            "Word pendulorum does not exist\n",
            "Word tachyarrhythmia does not exist\n",
            "Word ùruisgs does not exist\n",
            "Word catskardon does not exist\n",
            "Word incentivizes does not exist\n",
            "Word ralea does not exist\n",
            "Word varietys does not exist\n",
            "Word ordosensis does not exist\n",
            "Word odobești does not exist\n",
            "Word battement does not exist\n",
            "Word battement does not exist\n",
            "Word rhoptry does not exist\n",
            "Word moragana does not exist\n",
            "Word catamenia does not exist\n",
            "Word introits does not exist\n",
            "Word peculiars does not exist\n",
            "Word flashings does not exist\n",
            "Word weatherings does not exist\n",
            "Word downpipes does not exist\n",
            "Word caravela does not exist\n",
            "Word jeté does not exist\n",
            "Word manèges does not exist\n",
            "Word centaurian does not exist\n",
            "Word gloan does not exist\n",
            "Word hayeses does not exist\n",
            "Word exsultate does not exist\n",
            "Word shkëlqim does not exist\n",
            "Word serafine does not exist\n",
            "Word vandhana does not exist\n",
            "Word bolor does not exist\n",
            "Word ernage does not exist\n",
            "Word rokesmith does not exist\n",
            "Word vianda does not exist\n",
            "Word tapion does not exist\n",
            "Word tuoppi does not exist\n",
            "Word aarre does not exist\n",
            "Word bawarchi does not exist\n",
            "Word joroo does not exist\n",
            "Word shehzada does not exist\n",
            "Word ringspiel does not exist\n",
            "Word pyramides does not exist\n",
            "Word sunhat does not exist\n",
            "Word pilosula does not exist\n",
            "Word gyuma does not exist\n",
            "Word joyson does not exist\n",
            "Word savaiiense does not exist\n",
            "Word xanthochlora does not exist\n",
            "Word spiraeanthemum does not exist\n",
            "Word samoense does not exist\n",
            "Word streblus does not exist\n",
            "Word anthropophagorum does not exist\n",
            "Word skrimshires does not exist\n",
            "Word offerers does not exist\n",
            "Word offerer does not exist\n",
            "Word imade does not exist\n",
            "Word novokomponovana does not exist\n",
            "Word skweres does not exist\n",
            "Word cardiaca does not exist\n",
            "Word ptth does not exist\n",
            "Word allata does not exist\n",
            "Word prothorocic does not exist\n",
            "Word sanscrit does not exist\n",
            "Word manichees does not exist\n",
            "Word dohlaran does not exist\n",
            "Word cayleb does not exist\n",
            "Word chuckwallas does not exist\n",
            "Word nashvillians does not exist\n",
            "Word syberspace does not exist\n",
            "Word aromatization does not exist\n",
            "Word predentin does not exist\n",
            "Word hilberth does not exist\n",
            "Word mettwurst does not exist\n",
            "Word cherrybark does not exist\n",
            "Word elbury does not exist\n",
            "Word tlahuac does not exist\n",
            "Word idato does not exist\n",
            "Word slappable does not exist\n",
            "Word charisian does not exist\n",
            "Word ferayd does not exist\n",
            "Word tondern does not exist\n",
            "Word holstenius does not exist\n",
            "Word demigoddess does not exist\n",
            "Word honzō does not exist\n",
            "Word tzuyu does not exist\n",
            "Word nayeon does not exist\n",
            "Word jeongyeon does not exist\n",
            "Word weeklys does not exist\n",
            "Word witzin does not exist\n",
            "Word eastphalians does not exist\n",
            "Word teplov does not exist\n",
            "Word klingstedt does not exist\n",
            "Word spellbooks does not exist\n",
            "Word mcsyr does not exist\n",
            "Word vyprážaný does not exist\n",
            "Word cuanajo does not exist\n",
            "Word rellik does not exist\n",
            "Word gotobed does not exist\n",
            "Word microbats does not exist\n",
            "Word conically does not exist\n",
            "Word catrinel does not exist\n",
            "Word menghia does not exist\n",
            "Word feldspathoids does not exist\n",
            "Word krolowa does not exist\n",
            "Word midventral does not exist\n",
            "Word rahmlee does not exist\n",
            "Word powerbombing does not exist\n",
            "Word bubú does not exist\n",
            "Word delekhan does not exist\n",
            "Word pobedonostsev does not exist\n",
            "Word locksmithery does not exist\n",
            "Word sadot does not exist\n",
            "Word wistala does not exist\n",
            "Word desmitis does not exist\n",
            "Word trumeau does not exist\n",
            "Word rectocele does not exist\n",
            "Word fairdale does not exist\n",
            "Word brackenfell does not exist\n",
            "Word kraaifontein does not exist\n",
            "Word kuils does not exist\n",
            "Word mfuleni does not exist\n",
            "Word hoogte does not exist\n",
            "Word gammadion does not exist\n",
            "Word γαμμάδιον does not exist\n",
            "Word pikatan does not exist\n",
            "Word balaputra does not exist\n",
            "Word samaratunga does not exist\n",
            "Word astrohall does not exist\n",
            "Word fässler does not exist\n",
            "Word ferhunde does not exist\n",
            "Word gorbag does not exist\n",
            "Word carantoc does not exist\n",
            "Word scorbutic does not exist\n",
            "Word orthopterans does not exist\n",
            "Word shrevvy does not exist\n",
            "Word azhikode does not exist\n",
            "Word montucas does not exist\n",
            "Word sueles does not exist\n",
            "Word dejarme does not exist\n",
            "Word babaylan does not exist\n",
            "Word teschenite does not exist\n",
            "Word kuntry does not exist\n",
            "Word zubiaur does not exist\n",
            "Word calqued does not exist\n",
            "Word abstrait does not exist\n",
            "Word abstrait does not exist\n",
            "Word rignac does not exist\n",
            "Word tlahuiztli does not exist\n",
            "Word biosynthesize does not exist\n",
            "Word chrismatories does not exist\n",
            "Word monstrances does not exist\n",
            "Word unsociability does not exist\n",
            "Word chickenwing does not exist\n",
            "Word chickenwing does not exist\n",
            "Word ichnogenra does not exist\n",
            "Word dilophosauripus does not exist\n",
            "Word kayentapus does not exist\n",
            "Word haburamu does not exist\n",
            "Word laotienne does not exist\n",
            "Word rohu does not exist\n",
            "Word krempel does not exist\n",
            "Word vaippicotta does not exist\n",
            "Word ujhelyi does not exist\n",
            "Word göncz does not exist\n",
            "Word infantilize does not exist\n",
            "Word centuripe does not exist\n",
            "Word otacilius does not exist\n",
            "Word tugade does not exist\n",
            "Word heterostyly does not exist\n",
            "Word oxidates does not exist\n",
            "Word borneans does not exist\n",
            "Word ichnospecies does not exist\n",
            "Word creodontipus does not exist\n",
            "Word creodonts does not exist\n",
            "Word pasinski does not exist\n",
            "Word glycopeptide does not exist\n",
            "Word verticillus does not exist\n",
            "Word intercalate does not exist\n",
            "Word pirrip does not exist\n",
            "Word raathods does not exist\n",
            "Word ansh does not exist\n",
            "Word amaethon does not exist\n",
            "Word hypostylar does not exist\n",
            "Word negan does not exist\n",
            "Word söhngen does not exist\n",
            "Word planarian does not exist\n",
            "Word planarians does not exist\n",
            "Word chaugaon does not exist\n",
            "Word kusumba does not exist\n",
            "Word vascularius does not exist\n",
            "Word ochneae does not exist\n",
            "Word lophira does not exist\n",
            "Word lukbán does not exist\n",
            "Word ittōsai does not exist\n",
            "Word änggatan does not exist\n",
            "Word entablatures does not exist\n",
            "Word cobber does not exist\n",
            "Word rouvres does not exist\n",
            "Word bioparco does not exist\n",
            "Word darem does not exist\n",
            "Word ahoi does not exist\n",
            "Word pullmans does not exist\n",
            "Word carlough does not exist\n",
            "Word trinkhallen does not exist\n",
            "Word zenatello does not exist\n",
            "Word verd does not exist\n",
            "Word struzzo does not exist\n",
            "Word palanthas does not exist\n",
            "Word nuitari does not exist\n",
            "Word pâquis does not exist\n",
            "Word kúli does not exist\n",
            "Word bábis does not exist\n",
            "Word expellant does not exist\n",
            "Word herclis does not exist\n",
            "Word despote does not exist\n",
            "Word luxtorpeda does not exist\n",
            "Word rhoyne does not exist\n",
            "Word andalos does not exist\n",
            "Word andals does not exist\n",
            "Word braavos does not exist\n",
            "Word pentos does not exist\n",
            "Word motorise does not exist\n",
            "Word stylise does not exist\n",
            "Word entablatures does not exist\n",
            "Word chondrocyte does not exist\n",
            "Word cresswick does not exist\n",
            "Word wettinger does not exist\n",
            "Word saraçlar does not exist\n",
            "Word lexingtons does not exist\n",
            "Word waalhaven does not exist\n",
            "Word unioners does not exist\n",
            "Word pyrometer does not exist\n",
            "Word humitas does not exist\n",
            "Word choclo does not exist\n",
            "Word curanto does not exist\n",
            "Word sopaipillas does not exist\n",
            "Word laevinus does not exist\n",
            "Word christleton does not exist\n",
            "Word kleitis does not exist\n",
            "Word overexpress does not exist\n",
            "Word muzharul does not exist\n",
            "Word megaselia does not exist\n",
            "Word meconia does not exist\n",
            "Word kapoposang does not exist\n",
            "Word αι does not exist\n",
            "Word bartizans does not exist\n",
            "Word tamassee does not exist\n",
            "Word qpcr does not exist\n",
            "Word navabi does not exist\n",
            "Word vpay does not exist\n",
            "Word bcard does not exist\n",
            "Word rusgrove does not exist\n",
            "Word ωθ does not exist\n",
            "Word avak does not exist\n",
            "Word hakann does not exist\n",
            "Word ryujinou does not exist\n",
            "Word ryukendo does not exist\n",
            "Word habanniya does not exist\n",
            "Word kunnakudi does not exist\n",
            "Word gippes does not exist\n",
            "Word bamatabois does not exist\n",
            "Word promenaders does not exist\n",
            "Word incise does not exist\n",
            "Word megellus does not exist\n",
            "Word tifernum does not exist\n",
            "Word augurinus does not exist\n",
            "Word bovianum does not exist\n",
            "Word sopes does not exist\n",
            "Word tapitíos does not exist\n",
            "Word azones does not exist\n",
            "Word opisthodomos does not exist\n",
            "Word fooker does not exist\n",
            "Word leucher does not exist\n",
            "Word thuriau does not exist\n",
            "Word sthenelus does not exist\n",
            "Word stika does not exist\n",
            "Word padric does not exist\n",
            "Word nierop does not exist\n",
            "Word proctodeum does not exist\n",
            "Word cupless does not exist\n",
            "Word tequepa does not exist\n",
            "Word inniskillings does not exist\n",
            "Word swinge does not exist\n",
            "Word sportsmens does not exist\n",
            "Word poulengey does not exist\n",
            "Word bhuiyans does not exist\n",
            "Word damé does not exist\n",
            "Word heinkels does not exist\n",
            "Word scibec does not exist\n",
            "Word janolino does not exist\n",
            "Word baseships does not exist\n",
            "Word montrel does not exist\n",
            "Word davidse does not exist\n",
            "Word dirteater does not exist\n",
            "Word silverlode does not exist\n",
            "Word raillery does not exist\n",
            "Word gilbertian does not exist\n",
            "Word onibaba does not exist\n",
            "Word varmit does not exist\n",
            "Word warminskiego does not exist\n",
            "Word microsporangia does not exist\n",
            "Word integumented does not exist\n",
            "Word megasporangium does not exist\n",
            "Word gekisou does not exist\n",
            "Word carranger does not exist\n",
            "Word elyne does not exist\n",
            "Word shipkey does not exist\n",
            "Word kgr does not exist\n",
            "Word loksa does not exist\n",
            "Word antiates does not exist\n",
            "Word küchelbecker does not exist\n",
            "Word nikolayevka does not exist\n",
            "Word dioctophyma does not exist\n",
            "Word renale does not exist\n",
            "Word quechquemitl does not exist\n",
            "Word tilmas does not exist\n",
            "Word ryōhei does not exist\n",
            "Word denshichirō does not exist\n",
            "Word minihy does not exist\n",
            "Word lamprophyre does not exist\n",
            "Word kochadaiiyaan does not exist\n",
            "Word sobrà does not exist\n",
            "Word scaenae does not exist\n",
            "Word heagany does not exist\n",
            "Word dengwi does not exist\n",
            "Word economiser does not exist\n",
            "Word swinge does not exist\n",
            "Word metaurus does not exist\n",
            "Word footpad does not exist\n",
            "Word labneh does not exist\n",
            "Word kasatkina does not exist\n",
            "Word takki does not exist\n",
            "Word niggerlips does not exist\n",
            "Word marceli does not exist\n",
            "Word mechanostriders does not exist\n",
            "Word mukeke does not exist\n",
            "Word zufuru does not exist\n",
            "Word amphibrecon does not exist\n",
            "Word nauraspur does not exist\n",
            "Word bowloaders does not exist\n",
            "Word mailsea does not exist\n",
            "Word żelazna does not exist\n",
            "Word bronchiole does not exist\n",
            "Word autoamputation does not exist\n",
            "Word aridoamerica does not exist\n",
            "Word camauro does not exist\n",
            "Word vicarstown does not exist\n",
            "Word trutone does not exist\n",
            "Word tricouni does not exist\n",
            "Word tonalite does not exist\n",
            "Word saccharoidal does not exist\n",
            "Word broadaxe does not exist\n",
            "Word loncarevich does not exist\n",
            "Word cuckoldry does not exist\n",
            "Word duskwight does not exist\n",
            "Word promenaders does not exist\n",
            "Word compsognathid does not exist\n",
            "Word glaciate does not exist\n",
            "Word boulderers does not exist\n",
            "Word buckoffs does not exist\n",
            "Word gerardina does not exist\n",
            "Word cornicing does not exist\n",
            "Word laureldale does not exist\n",
            "Word notarize does not exist\n",
            "Word arthez does not exist\n",
            "Word poeylas does not exist\n",
            "Word lincensed does not exist\n",
            "Word blutarsky does not exist\n",
            "Word wesfalica does not exist\n",
            "Word bonasone does not exist\n",
            "Word felippe does not exist\n",
            "Word zomas does not exist\n",
            "Word lusius does not exist\n",
            "Word puddifoot does not exist\n",
            "Word raydan does not exist\n",
            "Word himyarites does not exist\n",
            "Word helenas does not exist\n",
            "Word hotstox does not exist\n",
            "Word cuajada does not exist\n",
            "Word tomcod does not exist\n",
            "Word séran does not exist\n",
            "Word lesnerac does not exist\n",
            "Word barcarolles does not exist\n",
            "Word bookstock does not exist\n",
            "Word spitalgate does not exist\n",
            "Word underdrive does not exist\n",
            "Word ourbus does not exist\n",
            "Word berdatak does not exist\n",
            "Word hazaradzor does not exist\n",
            "Word kaqavaberd does not exist\n",
            "Word kajaru does not exist\n",
            "Word zickuhr does not exist\n",
            "Word cariad does not exist\n",
            "Word overcalls does not exist\n",
            "Word fiesolana does not exist\n",
            "Word paravana does not exist\n",
            "Word mcarabia does not exist\n",
            "Word flaxans does not exist\n",
            "Word domsetco does not exist\n",
            "Word napaloni does not exist\n",
            "Word anyuta does not exist\n",
            "Word zarf does not exist\n",
            "Word myriophylla does not exist\n",
            "Word savettas does not exist\n",
            "Word joachimite does not exist\n",
            "Word monkwood does not exist\n",
            "Word burazjan does not exist\n",
            "Word semos does not exist\n",
            "Word berossos does not exist\n",
            "Word muchal does not exist\n",
            "Word americanise does not exist\n",
            "Word suske does not exist\n",
            "Word jatis does not exist\n",
            "Word mazahs does not exist\n",
            "Word atomica does not exist\n",
            "Word surjana does not exist\n",
            "Word lyapkin does not exist\n",
            "Word rebind does not exist\n",
            "Word democrates does not exist\n",
            "Word temnus does not exist\n",
            "Word nachtmystium does not exist\n",
            "Word nidingr does not exist\n",
            "Word sarke does not exist\n",
            "Word ignotus does not exist\n",
            "Word cardiaca does not exist\n",
            "Word ptth does not exist\n",
            "Word allata does not exist\n",
            "Word jeuvanile does not exist\n",
            "Word prothorocic does not exist\n",
            "Word jajaja does not exist\n",
            "Word falto does not exist\n",
            "Word strupper does not exist\n",
            "Word cazalès does not exist\n",
            "Word bergasse does not exist\n",
            "Word amburgh does not exist\n",
            "Word froim does not exist\n",
            "Word konjuh does not exist\n",
            "Word ritualise does not exist\n",
            "Word scarabaeus does not exist\n",
            "Word bullrack does not exist\n",
            "Word supplicate does not exist\n",
            "Word cucinare does not exist\n",
            "Word halcyons does not exist\n",
            "Word dicrescenzo does not exist\n",
            "Word tdsd does not exist\n",
            "Word amphisbaenians does not exist\n",
            "Word sicié does not exist\n",
            "Word tanneron does not exist\n",
            "Word beroea does not exist\n",
            "Word banderoles does not exist\n",
            "Word stoltze does not exist\n",
            "Word stoltze does not exist\n",
            "Word rehnskiöld does not exist\n",
            "Word pentzia does not exist\n",
            "Word monodiana does not exist\n",
            "Word tilhoana does not exist\n",
            "Word tilhoana does not exist\n",
            "Word chandrashekaran does not exist\n",
            "Word neopositivism does not exist\n",
            "Word sonero does not exist\n",
            "Word heartstopping does not exist\n",
            "Word morellos does not exist\n",
            "Word wisting does not exist\n",
            "Word technium does not exist\n",
            "Word khorvaire does not exist\n",
            "Word aerenal does not exist\n",
            "Word kelts does not exist\n",
            "Word rhizomorph does not exist\n",
            "Word steese does not exist\n",
            "Word rimrocks does not exist\n",
            "Word indiscrets does not exist\n",
            "Word gigantomachy does not exist\n",
            "Word pretarsus does not exist\n",
            "Word leshi does not exist\n",
            "Word natches does not exist\n",
            "Word sclerotised does not exist\n",
            "Word dromon does not exist\n",
            "Word cervid does not exist\n",
            "Word telemetacarpalia does not exist\n",
            "Word durgah does not exist\n",
            "Word kaattupalli does not exist\n",
            "Word hellenize does not exist\n",
            "Word deipnosophistae does not exist\n",
            "Word libius does not exist\n",
            "Word parkham does not exist\n",
            "Word woolfardisworthy does not exist\n",
            "Word xhalax does not exist\n",
            "Word confarreatio does not exist\n",
            "Word bethsan does not exist\n",
            "Word atomica does not exist\n",
            "Word sovershennyy does not exist\n",
            "Word besposhchadnyy does not exist\n",
            "Word sepulchrave does not exist\n",
            "Word absolutius does not exist\n",
            "Word vidit does not exist\n",
            "Word seamark does not exist\n",
            "Word hugenschmidt does not exist\n",
            "Word tanquary does not exist\n",
            "Word bildergalerie does not exist\n",
            "Word wharfed does not exist\n",
            "Word ratansingh does not exist\n",
            "Word bhandári does not exist\n",
            "Word víramgám does not exist\n",
            "Word tarly does not exist\n",
            "Word masaweng does not exist\n",
            "Word ansh does not exist\n",
            "Word antroz does not exist\n",
            "Word bitil does not exist\n",
            "Word nasadiya does not exist\n",
            "Word pamalayu does not exist\n",
            "Word katimahar does not exist\n",
            "Word teschenite does not exist\n",
            "Word resculpted does not exist\n",
            "Word infolding does not exist\n",
            "Word qbadic does not exist\n",
            "Word xenophile does not exist\n",
            "Word mucusless does not exist\n",
            "Word ansh does not exist\n",
            "Word vedashree does not exist\n",
            "Word izlet does not exist\n",
            "Word ljubov does not exist\n",
            "Word karposh does not exist\n",
            "Word sindkat does not exist\n",
            "Word pippidi does not exist\n",
            "Word canawagh does not exist\n",
            "Word meundeok does not exist\n",
            "Word intromittent does not exist\n",
            "Word phallodeum does not exist\n",
            "Word augustea does not exist\n",
            "Word yihud does not exist\n",
            "Word kurrajongs does not exist\n",
            "Word kurtas does not exist\n",
            "Word goalthe does not exist\n",
            "Word volcanológico does not exist\n",
            "Word disenchant does not exist\n",
            "Word haenfler does not exist\n",
            "Word holometabolism does not exist\n",
            "Word parau does not exist\n",
            "Word intercolumniations does not exist\n",
            "Word laodiceans does not exist\n",
            "Word abdül does not exist\n",
            "Word weylin does not exist\n",
            "Word outswingers does not exist\n",
            "Word underinflating does not exist\n",
            "Word baliddika does not exist\n",
            "Word rezhvolke does not exist\n",
            "Word septennial does not exist\n",
            "Word coboprotein does not exist\n",
            "Word documentalists does not exist\n",
            "Word sparidae does not exist\n",
            "Word scup does not exist\n",
            "Word skarns does not exist\n",
            "Word parasetigana does not exist\n",
            "Word exorista does not exist\n",
            "Word larvarum does not exist\n",
            "Word paraphrasis does not exist\n",
            "Word daggerboards does not exist\n",
            "Word saigonese does not exist\n",
            "Word dissimulate does not exist\n",
            "Word warmwell does not exist\n",
            "Word kuttelwascher does not exist\n",
            "Word flightlessness does not exist\n",
            "Word strowman does not exist\n",
            "Word caesares does not exist\n",
            "Word smooshi does not exist\n",
            "Word recao does not exist\n",
            "Word culantro does not exist\n",
            "Word cachucha does not exist\n",
            "Word cubanelle does not exist\n",
            "Word powerbombing does not exist\n",
            "Word garlics does not exist\n",
            "Word župans does not exist\n",
            "Word pakatugg does not exist\n",
            "Word eulaliaaaa does not exist\n",
            "Word fetsund does not exist\n",
            "Word fetsund does not exist\n",
            "Word sensualism does not exist\n",
            "Word negan does not exist\n",
            "Word pansuh does not exist\n",
            "Word carpenterworm does not exist\n",
            "Word toonopedia does not exist\n",
            "Word sajar does not exist\n",
            "Word redifon does not exist\n",
            "Word oldebarnevelt does not exist\n",
            "Word hozen does not exist\n",
            "Word aenarion does not exist\n",
            "Word proem does not exist\n",
            "Word myrine does not exist\n",
            "Word memorabile does not exist\n",
            "Word disestablishments does not exist\n",
            "Word thieve does not exist\n",
            "Word xou does not exist\n",
            "Word bobeou does not exist\n",
            "Word dançou does not exist\n",
            "Word cannonading does not exist\n",
            "Word supecell does not exist\n",
            "Word crystalloid does not exist\n",
            "Word akelaitis does not exist\n",
            "Word cachucha does not exist\n",
            "Word claquesous does not exist\n",
            "Word gueulemer does not exist\n",
            "Word overskirt does not exist\n",
            "Word tianfei does not exist\n",
            "Word guilledo does not exist\n",
            "Word stretchability does not exist\n",
            "Word bfts does not exist\n",
            "Word buckoffs does not exist\n",
            "Word phelp does not exist\n",
            "Word derogatively does not exist\n",
            "Word schwarzfuchs does not exist\n",
            "Word arfin does not exist\n",
            "Word falto does not exist\n",
            "Word disasterpieces does not exist\n",
            "Word cerevisia does not exist\n",
            "Word cellobiose does not exist\n",
            "Word kaungton does not exist\n",
            "Word portopí does not exist\n",
            "Word trahair does not exist\n",
            "Word snehabhavan does not exist\n",
            "Word valsalya does not exist\n",
            "Word dastarkhān does not exist\n",
            "Word starchie does not exist\n",
            "Word iachimo does not exist\n",
            "Word peitro does not exist\n",
            "Word sopkin does not exist\n",
            "Word auriculiformis does not exist\n",
            "Word sannomaru does not exist\n",
            "Word enceintes does not exist\n",
            "Word gorast does not exist\n",
            "Word capulins does not exist\n",
            "Word bernardinos does not exist\n",
            "Word pasteurellosis does not exist\n",
            "Word orchises does not exist\n",
            "Word springhare does not exist\n",
            "Word homininan does not exist\n",
            "Word dendre does not exist\n",
            "Word sistra does not exist\n",
            "Word preëminent does not exist\n",
            "Word fuuta does not exist\n",
            "Word fulɓe does not exist\n",
            "Word cogged does not exist\n",
            "Word pyrimidinedione does not exist\n",
            "Word häffner does not exist\n",
            "Word kinnikinnick does not exist\n",
            "Word suske does not exist\n",
            "Word circumciser does not exist\n",
            "Word tyrians does not exist\n",
            "Word unsheathe does not exist\n",
            "Word compeed does not exist\n",
            "Word blisterpatch does not exist\n",
            "Word ndembu does not exist\n",
            "Word metox does not exist\n",
            "Word nazirites does not exist\n",
            "Word flashings does not exist\n",
            "Word medlink does not exist\n",
            "Word randallia does not exist\n",
            "Word pwra does not exist\n",
            "Word wpra does not exist\n",
            "Word akropolites does not exist\n",
            "Word babr does not exist\n",
            "Word ramuh does not exist\n",
            "Word alliterating does not exist\n",
            "Word ismah does not exist\n",
            "Word impeccability does not exist\n",
            "Word knockwurst does not exist\n",
            "Word seetharama does not exist\n",
            "Word yuvaraju does not exist\n",
            "Word iacite does not exist\n",
            "Word bovianum does not exist\n",
            "Word delanos does not exist\n",
            "Word aradam does not exist\n",
            "Word verás does not exist\n",
            "Word demyan does not exist\n",
            "Word korotchenko does not exist\n",
            "Word meithaba does not exist\n",
            "Word fnspe does not exist\n",
            "Word sadducee does not exist\n",
            "Word neurophilosophers does not exist\n",
            "Word khunzakh does not exist\n",
            "Word vinodolski does not exist\n",
            "Word fužine does not exist\n",
            "Word glucuronides does not exist\n",
            "Word necrose does not exist\n",
            "Word belliniano does not exist\n",
            "Word cruyllas does not exist\n",
            "Word memorabile does not exist\n",
            "Word ryuoon does not exist\n",
            "Word bouken does not exist\n",
            "Word jabō does not exist\n",
            "Word seiryūtō does not exist\n",
            "Word poetising does not exist\n",
            "Word sarvanash does not exist\n",
            "Word monotoring does not exist\n",
            "Word druschetzky does not exist\n",
            "Word pythoness does not exist\n",
            "Word inque does not exist\n",
            "Word corrugate does not exist\n",
            "Word gablets does not exist\n",
            "Word poecilandra does not exist\n",
            "Word poricidal does not exist\n",
            "Word balsamroot does not exist\n",
            "Word donative does not exist\n",
            "Word bessas does not exist\n",
            "Word abasgian does not exist\n",
            "Word zoute does not exist\n",
            "Word modikara does not exist\n",
            "Word motorise does not exist\n",
            "Word rosanes does not exist\n",
            "Word pashinyan does not exist\n",
            "Word wholecloth does not exist\n",
            "Word loredani does not exist\n",
            "Word linkola does not exist\n",
            "Word amanteca does not exist\n",
            "Word lentuli does not exist\n",
            "Word epidermoid does not exist\n",
            "Word intratesticular does not exist\n",
            "Word attalid does not exist\n",
            "Word rellik does not exist\n",
            "Word inconspicuousness does not exist\n",
            "Word galiakot does not exist\n",
            "Word syedi does not exist\n",
            "Word wellerisms does not exist\n",
            "Word kuppepadav does not exist\n",
            "Word tacode does not exist\n",
            "Word moodbidri does not exist\n",
            "Word keyfa does not exist\n",
            "Word větřní does not exist\n",
            "Word gwmnma does not exist\n",
            "Word resodded does not exist\n",
            "Word rhodesiensis does not exist\n",
            "Word bichrome does not exist\n",
            "Word halogenate does not exist\n",
            "Word mazlin does not exist\n",
            "Word quatercentenary does not exist\n",
            "Word douji does not exist\n",
            "Word vilherm does not exist\n",
            "Word tortoni does not exist\n",
            "Word taibout does not exist\n",
            "Word rujm does not exist\n",
            "Word absidial does not exist\n",
            "Word terramort does not exist\n",
            "Word saltar does not exist\n",
            "Word bludrigg does not exist\n",
            "Word darkqueen does not exist\n",
            "Word wasmannian does not exist\n",
            "Word dominula does not exist\n",
            "Word cerevisia does not exist\n",
            "Word cerevisia does not exist\n",
            "Word gorons does not exist\n",
            "Word bedazzlement does not exist\n",
            "Word hypoblast does not exist\n",
            "Word dethman does not exist\n",
            "Word natalbany does not exist\n",
            "Word viṣṇu does not exist\n",
            "Word prajāpati does not exist\n",
            "Word topee does not exist\n",
            "Word individualisation does not exist\n",
            "Word boxvans does not exist\n",
            "Word vlpy does not exist\n",
            "Word unbanded does not exist\n",
            "Word bioherms does not exist\n",
            "Word depcitions does not exist\n",
            "Word ányos does not exist\n",
            "Word jedlik does not exist\n",
            "Word jazłowiec does not exist\n",
            "Word jazłowiec does not exist\n",
            "Word overarch does not exist\n",
            "Word rushmi does not exist\n",
            "Word raondriana does not exist\n",
            "Word aggiornamento does not exist\n",
            "Word enserfment does not exist\n",
            "Word bernad does not exist\n",
            "Word rullepølse does not exist\n",
            "Word immortalization does not exist\n",
            "Word gaumata does not exist\n",
            "Word genale does not exist\n",
            "Word dworcowa does not exist\n",
            "Word gadrooned does not exist\n",
            "Word kishka does not exist\n",
            "Word ithobaal does not exist\n",
            "Word xylorimba does not exist\n",
            "Word spiritualize does not exist\n",
            "Word singulares does not exist\n",
            "Word ardier does not exist\n",
            "Word pedosphere does not exist\n",
            "Word erks does not exist\n",
            "Word supervene does not exist\n",
            "Word smetanka does not exist\n",
            "Word nuqta does not exist\n",
            "Word avilán does not exist\n",
            "Word moncler does not exist\n",
            "Word lametrie does not exist\n",
            "Word wardon does not exist\n",
            "Word lametrie does not exist\n",
            "Word battlecarrier does not exist\n",
            "Word kteh does not exist\n",
            "Word swaminaryan does not exist\n",
            "Word agathiphagidae does not exist\n",
            "Word lumpsuckers does not exist\n",
            "Word mouthpart does not exist\n",
            "Word queyroz does not exist\n",
            "Word mcbryar does not exist\n",
            "Word cloghoppers does not exist\n",
            "Word bezant does not exist\n",
            "Word byelaw does not exist\n",
            "Word fōku does not exist\n",
            "Word laforcade does not exist\n",
            "Word notarize does not exist\n",
            "Word transorbital does not exist\n",
            "Word brehan does not exist\n",
            "Word antonn does not exist\n",
            "Word cystovaries does not exist\n",
            "Word semudera does not exist\n",
            "Word maurrassian does not exist\n",
            "Word sorelian does not exist\n",
            "Word rabefagnatrika does not exist\n",
            "Word fanjahira does not exist\n",
            "Word jozani does not exist\n",
            "Word bushpigs does not exist\n",
            "Word aksan does not exist\n",
            "Word shellbark does not exist\n",
            "Word misericordias does not exist\n",
            "Word świętojańska does not exist\n",
            "Word porada does not exist\n",
            "Word temozarela does not exist\n",
            "Word atwells does not exist\n",
            "Word apotropaics does not exist\n",
            "Word imbed does not exist\n",
            "Word elisabetha does not exist\n",
            "Word merox does not exist\n",
            "Word desulfurize does not exist\n",
            "Word enfeoff does not exist\n",
            "Word neuenwalde does not exist\n",
            "Word duello does not exist\n",
            "Word peanutbutter does not exist\n",
            "Word bojack does not exist\n",
            "Word necromass does not exist\n",
            "Word epigraphists does not exist\n",
            "Word oprichnik does not exist\n",
            "Word cainozoic does not exist\n",
            "Word interramal does not exist\n",
            "Word submental does not exist\n",
            "Word publilius does not exist\n",
            "Word diselenium does not exist\n",
            "Word diiodide does not exist\n",
            "Word lambarde does not exist\n",
            "Word ranae does not exist\n",
            "Word apfelroth does not exist\n",
            "Word dogmatization does not exist\n",
            "Word juncalito does not exist\n",
            "Word teklehaimanot does not exist\n",
            "Word vidur does not exist\n",
            "Word khushkismat does not exist\n",
            "Word ferayd does not exist\n",
            "Word delferahk does not exist\n",
            "Word charisian does not exist\n",
            "Word wisting does not exist\n",
            "Word inertrite does not exist\n",
            "Word siniaková does not exist\n",
            "Word retia does not exist\n",
            "Word mirabilia does not exist\n",
            "Word notson does not exist\n",
            "Word wiveleslie does not exist\n",
            "Word mcclearn does not exist\n",
            "Word ovophile does not exist\n",
            "Word mouthbrooders does not exist\n",
            "Word marciszewski does not exist\n",
            "Word polymerise does not exist\n",
            "Word bipedally does not exist\n",
            "Word monstrat does not exist\n",
            "Word philhellenists does not exist\n",
            "Word gorjani does not exist\n",
            "Word genhom does not exist\n",
            "Word assemblé does not exist\n",
            "Word glissade does not exist\n",
            "Word frappés does not exist\n",
            "Word lamprophyre does not exist\n",
            "Word porphyrite does not exist\n",
            "Word milicent does not exist\n",
            "Word achillas does not exist\n",
            "Word savius does not exist\n",
            "Word ahon does not exist\n",
            "Word crabbes does not exist\n",
            "Word ravy does not exist\n",
            "Word temozarela does not exist\n",
            "Word hadramis does not exist\n",
            "Word mousers does not exist\n",
            "Word parthenios does not exist\n",
            "Word anstetten does not exist\n",
            "Word wakwak does not exist\n",
            "Word brygoi does not exist\n",
            "Word tilaco does not exist\n",
            "Word mzali does not exist\n",
            "Word tsingtau does not exist\n",
            "Word biaix does not exist\n",
            "Word loyard does not exist\n",
            "Word taylorbass does not exist\n",
            "Word fensonbass does not exist\n",
            "Word goldingbass does not exist\n",
            "Word chapmandrums does not exist\n",
            "Word littledrums does not exist\n",
            "Word dornisch does not exist\n",
            "Word khafiya does not exist\n",
            "Word jahariyya does not exist\n",
            "Word gedimu does not exist\n",
            "Word killadoon does not exist\n",
            "Word ardrass does not exist\n",
            "Word ballymakeally does not exist\n",
            "Word crippaun does not exist\n",
            "Word killadoon does not exist\n",
            "Word killenlea does not exist\n",
            "Word posseckstown does not exist\n",
            "Word exhilarate does not exist\n",
            "Word gneisenaus does not exist\n",
            "Word vijaynagara does not exist\n",
            "Word majlinda does not exist\n",
            "Word overbister does not exist\n",
            "Word fingermark does not exist\n",
            "Word incise does not exist\n",
            "Word impend does not exist\n",
            "Word urinogenital does not exist\n",
            "Word cowhouse does not exist\n",
            "Word sersali does not exist\n",
            "Word carigara does not exist\n",
            "Word pseudobiceros does not exist\n",
            "Word bedfordi does not exist\n",
            "Word kolten does not exist\n",
            "Word miggle does not exist\n",
            "Word repr does not exist\n",
            "Word pilastered does not exist\n",
            "Word atss does not exist\n",
            "Word cesse does not exist\n",
            "Word orbiel does not exist\n",
            "Word pechlaurier does not exist\n",
            "Word medano does not exist\n",
            "Word grazela does not exist\n",
            "Word epidoc does not exist\n",
            "Word preradović does not exist\n",
            "Word oilbbl does not exist\n",
            "Word nusco does not exist\n",
            "Word pitón does not exist\n",
            "Word evangelii does not exist\n",
            "Word nuntiandi does not exist\n",
            "Word saddlebreds does not exist\n",
            "Word satyagrahis does not exist\n",
            "Word gabool does not exist\n",
            "Word bludrigg does not exist\n",
            "Word ossius does not exist\n",
            "Word corduba does not exist\n",
            "Word tequisquiapan does not exist\n",
            "Word ixtle does not exist\n",
            "Word kuyperian does not exist\n",
            "Word dirik does not exist\n",
            "Word olavsson does not exist\n",
            "Word demolisher does not exist\n",
            "Word éirí does not exist\n",
            "Word amach does not exist\n",
            "Word cásca does not exist\n",
            "Word macmullen does not exist\n",
            "Word tughlaqpur does not exist\n",
            "Word salmonic does not exist\n",
            "Word basilikon does not exist\n",
            "Word plōimon does not exist\n",
            "Word tordenskioldeika does not exist\n",
            "Word åsgårdstrand does not exist\n",
            "Word perilloux does not exist\n",
            "Word anticlinorium does not exist\n",
            "Word pajou does not exist\n",
            "Word tarfon does not exist\n",
            "Word handbreadths does not exist\n",
            "Word handbreadths does not exist\n",
            "Word cheremisinoff does not exist\n",
            "Word gigantomachy does not exist\n",
            "Word subahs does not exist\n",
            "Word asfr does not exist\n",
            "Word zigliara does not exist\n",
            "Word aeterni does not exist\n",
            "Word kinilaw does not exist\n",
            "Word kilawin does not exist\n",
            "Word calamansi does not exist\n",
            "Word ablator does not exist\n",
            "Word ablator does not exist\n",
            "Word idealise does not exist\n",
            "Word novogodišnja does not exist\n",
            "Word constanten does not exist\n",
            "Word tropine does not exist\n",
            "Word trii does not exist\n",
            "Word pseudotropine does not exist\n",
            "Word syncretizing does not exist\n",
            "Word tattie does not exist\n",
            "Word azais does not exist\n",
            "Word chambard does not exist\n",
            "Word waheno does not exist\n",
            "Word lunitari does not exist\n",
            "Word weathertech does not exist\n",
            "Word nauticos does not exist\n",
            "Word gangmumei does not exist\n",
            "Word phlegra does not exist\n",
            "Word teiresias does not exist\n",
            "Word adamellite does not exist\n",
            "Word porphyrite does not exist\n",
            "Word erinpura does not exist\n",
            "Word toonopedia does not exist\n",
            "Word methink does not exist\n",
            "Word anemestione does not exist\n",
            "Word anaglyptarius does not exist\n",
            "Word pandoraviridae does not exist\n",
            "Word thiosulphate does not exist\n",
            "Word vacherin does not exist\n",
            "Word paraphrasis does not exist\n",
            "Word sigdrifa does not exist\n",
            "Word messallinus does not exist\n",
            "Word skycruise does not exist\n",
            "Word babyla does not exist\n",
            "Word futtocks does not exist\n",
            "Word tauzia does not exist\n",
            "Word martiné does not exist\n",
            "Word mythologists does not exist\n",
            "Word combatron does not exist\n",
            "Word carrascalão does not exist\n",
            "Word rafey does not exist\n",
            "Word underutilize does not exist\n",
            "Word rcks does not exist\n",
            "Word privati does not exist\n",
            "Word inactiveness does not exist\n",
            "Word cassola does not exist\n",
            "Word gueri does not exist\n",
            "Word thete does not exist\n",
            "Word calory does not exist\n",
            "Word aristology does not exist\n",
            "Word selachimorpha does not exist\n",
            "Word elasmobranchii does not exist\n",
            "Word cholis does not exist\n",
            "Word vaisampayana does not exist\n",
            "Word libertytown does not exist\n",
            "Word impropriations does not exist\n",
            "Word mihrabs does not exist\n",
            "Word pratchat does not exist\n",
            "Word ontos does not exist\n",
            "Word hachijōjima does not exist\n",
            "Word colonettes does not exist\n",
            "Word spectro does not exist\n",
            "Word spectro does not exist\n",
            "Word cannoneer does not exist\n",
            "Word pantas does not exist\n",
            "Word sunhat does not exist\n",
            "Word terga does not exist\n",
            "Word serosal does not exist\n",
            "Word abuted does not exist\n",
            "Word poetise does not exist\n",
            "Word longsuffering does not exist\n",
            "Word quavo does not exist\n",
            "Word quavo does not exist\n",
            "Word huncho does not exist\n",
            "Word spinodiapophyseal does not exist\n",
            "Word eeylops does not exist\n",
            "Word cutwaters does not exist\n",
            "Word jötunheimr does not exist\n",
            "Word contemplator does not exist\n",
            "Word skellingthorpe does not exist\n",
            "Word ornithophobia does not exist\n",
            "Word cognoscente does not exist\n",
            "Word tellurate does not exist\n",
            "Word sylvanite does not exist\n",
            "Word calaverite does not exist\n",
            "Word platycoelous does not exist\n",
            "Word armourial does not exist\n",
            "Word papora does not exist\n",
            "Word greencell does not exist\n",
            "Word artuqid does not exist\n",
            "Word saruj does not exist\n",
            "Word floatpond does not exist\n",
            "Word zhaoyinshi does not exist\n",
            "Word yuanyou does not exist\n",
            "Word 猿狖 does not exist\n",
            "Word seigl does not exist\n",
            "Word binita does not exist\n",
            "Word pseudodipteroi does not exist\n",
            "Word casr does not exist\n",
            "Word ebirah does not exist\n",
            "Word frenchification does not exist\n",
            "Word provençalistion does not exist\n",
            "Word prvovenčani does not exist\n",
            "Word hamerow does not exist\n",
            "Word périès does not exist\n",
            "Word mustasch does not exist\n",
            "Word zenodochium does not exist\n",
            "Word coccivorella does not exist\n",
            "Word coccid does not exist\n",
            "Word agendum does not exist\n",
            "Word capturer does not exist\n",
            "Word ductules does not exist\n",
            "Word burstead does not exist\n",
            "Word cainozoic does not exist\n",
            "Word medjez does not exist\n",
            "Word aoukaz does not exist\n",
            "Word blackwork does not exist\n",
            "Word badiano does not exist\n",
            "Word boylin does not exist\n",
            "Word sanananda does not exist\n",
            "Word nothura does not exist\n",
            "Word nothura does not exist\n",
            "Word agassizii does not exist\n",
            "Word bortles does not exist\n",
            "Word kulaakeran does not exist\n",
            "Word subhu does not exist\n",
            "Word idolise does not exist\n",
            "Word sugumadhapura does not exist\n",
            "Word explanatio does not exist\n",
            "Word guillelmi does not exist\n",
            "Word sanct does not exist\n",
            "Word nangape does not exist\n",
            "Word oneil does not exist\n",
            "Word essentialities does not exist\n",
            "Word sallier does not exist\n",
            "Word streckfus does not exist\n",
            "Word pārvatī does not exist\n",
            "Word paraśurāma does not exist\n",
            "Word buthidaung does not exist\n",
            "Word heitan does not exist\n",
            "Word hamerweit does not exist\n",
            "Word podro does not exist\n",
            "Word monbron does not exist\n",
            "Word scratchpad does not exist\n",
            "Word flashings does not exist\n",
            "Word artistestes does not exist\n",
            "Word divinised does not exist\n",
            "Word gregarines does not exist\n",
            "Word ginghams does not exist\n",
            "Word boombah does not exist\n",
            "Word barraco does not exist\n",
            "Word tichelen does not exist\n",
            "Word gyrfalcons does not exist\n",
            "Word mairianne does not exist\n",
            "Word vorondil does not exist\n",
            "Word rhûn does not exist\n",
            "Word thraldom does not exist\n",
            "Word ogives does not exist\n",
            "Word ogives does not exist\n",
            "Word ogives does not exist\n",
            "Word sarikamish does not exist\n",
            "Word totoy does not exist\n",
            "Word pehli does not exist\n",
            "Word jashan does not exist\n",
            "Word bongsunga does not exist\n",
            "Word bogash does not exist\n",
            "Word ultrasonication does not exist\n",
            "Word mushika does not exist\n",
            "Word nordicism does not exist\n",
            "Word necrafa does not exist\n",
            "Word mysticons does not exist\n",
            "Word largus does not exist\n",
            "Word altostratus does not exist\n",
            "Word crati does not exist\n",
            "Word sceales does not exist\n",
            "Word idolater does not exist\n",
            "Word handloader does not exist\n",
            "Word pleb does not exist\n",
            "Word mahabharatas does not exist\n",
            "Word gløgg does not exist\n",
            "Word breding does not exist\n",
            "Word baillifs does not exist\n",
            "Word seneschals does not exist\n",
            "Word spectrography does not exist\n",
            "Word ralea does not exist\n",
            "Word thieve does not exist\n",
            "Word kyasht does not exist\n",
            "Word lussonium does not exist\n",
            "Word leife does not exist\n",
            "Word frima does not exist\n",
            "Word dentilled does not exist\n",
            "Word strowman does not exist\n",
            "Word hereditarianism does not exist\n",
            "Word boeser does not exist\n",
            "Word valonia does not exist\n",
            "Word turbellaria does not exist\n",
            "Word corrugate does not exist\n",
            "Word bullsnakes does not exist\n",
            "Word popcraft does not exist\n",
            "Word tendresse does not exist\n",
            "Word negan does not exist\n",
            "Word krassel does not exist\n",
            "Word achatmühle does not exist\n",
            "Word parkwide does not exist\n",
            "Word tajadas does not exist\n",
            "Word koturo does not exist\n",
            "Word seqiro does not exist\n",
            "Word jhalwa does not exist\n",
            "Word chattala does not exist\n",
            "Word sanshodhani does not exist\n",
            "Word purobi does not exist\n",
            "Word mukulika does not exist\n",
            "Word simanto does not exist\n",
            "Word indiera does not exist\n",
            "Word rodkinson does not exist\n",
            "Word makurian does not exist\n",
            "Word aydhab does not exist\n",
            "Word wazarats does not exist\n",
            "Word haelan does not exist\n",
            "Word sunstones does not exist\n",
            "Word ulfstead does not exist\n",
            "Word ulfstead does not exist\n",
            "Word dalguise does not exist\n",
            "Word divie does not exist\n",
            "Word dunphail does not exist\n",
            "Word kashibai does not exist\n",
            "Word dudarova does not exist\n",
            "Word brûlée does not exist\n",
            "Word rhyodacitic does not exist\n",
            "Word chakratirtha does not exist\n",
            "Word veneerings does not exist\n",
            "Word cocoyams does not exist\n",
            "Word smokeroom does not exist\n",
            "Word smilen does not exist\n",
            "Word gaštarovski does not exist\n",
            "Word pikisipi does not exist\n",
            "Word trpkov does not exist\n",
            "Word decarburizing does not exist\n",
            "Word bournes does not exist\n",
            "Word durdan does not exist\n",
            "Word ellezelloise does not exist\n",
            "Word shatov does not exist\n",
            "Word cryptophyte does not exist\n",
            "Word nucleomorph does not exist\n",
            "Word chlorarachniophytes does not exist\n",
            "Word iniga does not exist\n",
            "Word prikol does not exist\n",
            "Word nārad does not exist\n",
            "Word draisaitl does not exist\n",
            "Word unimpassioned does not exist\n",
            "Word paraphrasis does not exist\n",
            "Word werecoyotes does not exist\n",
            "Word avilán does not exist\n",
            "Word caballerosidad does not exist\n",
            "Word rubenid does not exist\n",
            "Word soundsational does not exist\n",
            "Word jeta does not exist\n",
            "Word curufin does not exist\n",
            "Word caranthir does not exist\n",
            "Word tsort does not exist\n",
            "Word rimwards does not exist\n",
            "Word fleute does not exist\n",
            "Word aspersum does not exist\n",
            "Word pomatia does not exist\n",
            "Word hirtelen does not exist\n",
            "Word felugrott does not exist\n",
            "Word elrohant does not exist\n",
            "Word stierlitz does not exist\n",
            "Word indigotine does not exist\n",
            "Word dolabra does not exist\n",
            "Word mencs does not exist\n",
            "Word skutt does not exist\n",
            "Word muthamma does not exist\n",
            "Word columbkille does not exist\n",
            "Word primps does not exist\n",
            "Word bekishe does not exist\n",
            "Word pía does not exist\n",
            "Word cremello does not exist\n",
            "Word ovangkol does not exist\n",
            "Word vcore does not exist\n",
            "Word nidhoggr does not exist\n",
            "Word bierkellers does not exist\n",
            "Word selvakannan does not exist\n",
            "Word rajaramchandra does not exist\n",
            "Word ayyaa does not exist\n",
            "Word naachiyar does not exist\n",
            "Word mescalin does not exist\n",
            "Word pariss does not exist\n",
            "Word thonnelier does not exist\n",
            "Word selinunte does not exist\n",
            "Word vappula does not exist\n",
            "Word halfas does not exist\n",
            "Word krassel does not exist\n",
            "Word geschwitz does not exist\n",
            "Word miracinonyx does not exist\n",
            "Word iliaș does not exist\n",
            "Word pè does not exist\n",
            "Word byouk does not exist\n",
            "Word vondervotteimittis does not exist\n",
            "Word polycomb does not exist\n",
            "Word trithorax does not exist\n",
            "Word outmatch does not exist\n",
            "Word grandiosities does not exist\n",
            "Word syncopate does not exist\n",
            "Word antedate does not exist\n",
            "Word bajramović does not exist\n",
            "Word govenlock does not exist\n",
            "Word vestures does not exist\n",
            "Word onagers does not exist\n",
            "Word glengorse does not exist\n",
            "Word etinger does not exist\n",
            "Word schevill does not exist\n",
            "Word grapnel does not exist\n",
            "Word megapodes does not exist\n",
            "Word bronzebeard does not exist\n",
            "Word wildhammer does not exist\n",
            "Word baiame does not exist\n",
            "Word cumborah does not exist\n",
            "Word narran does not exist\n",
            "Word chthonios does not exist\n",
            "Word eubouleus does not exist\n",
            "Word euclius does not exist\n",
            "Word corrugate does not exist\n",
            "Word onora does not exist\n",
            "Word quassim does not exist\n",
            "Word korsgaard does not exist\n",
            "Word sycophanta does not exist\n",
            "Word pyrenoids does not exist\n",
            "Word bruxa does not exist\n",
            "Word nivellan does not exist\n",
            "Word polysulfanes does not exist\n",
            "Word miraclefeet does not exist\n",
            "Word karyogamy does not exist\n",
            "Word ascospore does not exist\n",
            "Word lightstreet does not exist\n",
            "Word nobuna does not exist\n",
            "Word letart does not exist\n",
            "Word axell does not exist\n",
            "Word selyse does not exist\n",
            "Word rangoji does not exist\n",
            "Word petlád does not exist\n",
            "Word áhmedábád does not exist\n",
            "Word paraglide does not exist\n",
            "Word huangguan does not exist\n",
            "Word ryuto does not exist\n",
            "Word riseross does not exist\n",
            "Word southmore does not exist\n",
            "Word saddletail does not exist\n",
            "Word asselt does not exist\n",
            "Word asselt does not exist\n",
            "Word paralogism does not exist\n",
            "Word iulus does not exist\n",
            "Word zakare does not exist\n",
            "Word mkhargrzeli does not exist\n",
            "Word shaddadid does not exist\n",
            "Word burgniard does not exist\n",
            "Word telelever does not exist\n",
            "Word maheno does not exist\n",
            "Word unsheathe does not exist\n",
            "Word lactucinus does not exist\n",
            "Word beautiple does not exist\n",
            "Word zunō does not exist\n",
            "Word keisatsu does not exist\n",
            "Word cocoyam does not exist\n",
            "Word cluseret does not exist\n",
            "Word anthi does not exist\n",
            "Word kithic does not exist\n",
            "Word aguçadoura does not exist\n",
            "Word sontonga does not exist\n",
            "Word mqhayi does not exist\n",
            "Word sorelian does not exist\n",
            "Word liedekerke does not exist\n",
            "Word eskimoes does not exist\n",
            "Word søndrål does not exist\n",
            "Word bergschrunds does not exist\n",
            "Word asculum does not exist\n",
            "Word altrichter does not exist\n",
            "Word devanampiya does not exist\n",
            "Word gymnovarian does not exist\n",
            "Word stjepko does not exist\n",
            "Word toqta does not exist\n",
            "Word baklawa does not exist\n",
            "Word kanafeh does not exist\n",
            "Word outranged does not exist\n",
            "Word corsac does not exist\n",
            "Word dinuguan does not exist\n",
            "Word mahaba does not exist\n",
            "Word nimball does not exist\n",
            "Word grushenka does not exist\n",
            "Word patchiness does not exist\n",
            "Word puszczyński does not exist\n",
            "Word magrathean does not exist\n",
            "Word eulogises does not exist\n",
            "Word boomie does not exist\n",
            "Word autunite does not exist\n",
            "Word carnotite does not exist\n",
            "Word murgescu does not exist\n",
            "Word rechinul does not exist\n",
            "Word marsuinul does not exist\n",
            "Word cybermats does not exist\n",
            "Word soundy does not exist\n",
            "Word dysphemisms does not exist\n",
            "Word ἑταιρείαι does not exist\n",
            "Word companionships does not exist\n",
            "Word fattoush does not exist\n",
            "Word arnson does not exist\n",
            "Word svarlien does not exist\n",
            "Word timocracy does not exist\n",
            "Word semidome does not exist\n",
            "Word brassards does not exist\n",
            "Word sharleyan does not exist\n",
            "Word corisande does not exist\n",
            "Word eucalyptol does not exist\n",
            "Word rubberise does not exist\n",
            "Word goldbeater does not exist\n",
            "Word cruppi does not exist\n",
            "Word lymphopenia does not exist\n",
            "Word dragée does not exist\n",
            "Word vidhurapandita does not exist\n",
            "Word kshanti does not exist\n",
            "Word avadhana does not exist\n",
            "Word cerebrates does not exist\n",
            "Word corrugate does not exist\n",
            "Word palmations does not exist\n",
            "Word vilano does not exist\n",
            "Word nikolaidi does not exist\n",
            "Word galeran does not exist\n",
            "Word baillif does not exist\n",
            "Word guthorm does not exist\n",
            "Word drachen does not exist\n",
            "Word barreno does not exist\n",
            "Word tsinelas does not exist\n",
            "Word pnictogens does not exist\n",
            "Word berlusconismo does not exist\n",
            "Word futtock does not exist\n",
            "Word azarie does not exist\n",
            "Word aromatize does not exist\n",
            "Word multipicta does not exist\n",
            "Word prestress does not exist\n",
            "Word pames does not exist\n",
            "Word najdanović does not exist\n",
            "Word centromyrmex does not exist\n",
            "Word iridomyrmex does not exist\n",
            "Word bambaattaa does not exist\n",
            "Word oads does not exist\n",
            "Word monoreme does not exist\n",
            "Word vannal does not exist\n",
            "Word dickle does not exist\n",
            "Word pyritz does not exist\n",
            "Word pyritz does not exist\n",
            "Word phaedon does not exist\n",
            "Word sokolnikov does not exist\n",
            "Word phocids does not exist\n",
            "Word otariid does not exist\n",
            "Word orated does not exist\n",
            "Word alliyah does not exist\n",
            "Word laiotă does not exist\n",
            "Word helite does not exist\n",
            "Word pedalboats does not exist\n",
            "Word paralogism does not exist\n",
            "Word icecubes does not exist\n",
            "Word redoutables does not exist\n",
            "Word temeraires does not exist\n",
            "Word manufacted does not exist\n",
            "Word hypothemic does not exist\n",
            "Word kidimi does not exist\n",
            "Word toussidé does not exist\n",
            "Word inniskilings does not exist\n",
            "Word reginsmál does not exist\n",
            "Word overglaze does not exist\n",
            "Word calamansi does not exist\n",
            "Word calamondin does not exist\n",
            "Word amangkurat does not exist\n",
            "Word minatory does not exist\n",
            "Word fishway does not exist\n",
            "Word ervadi does not exist\n",
            "Word crannógs does not exist\n",
            "Word nazty does not exist\n",
            "Word šeštokai does not exist\n",
            "Word cavum does not exist\n",
            "Word ziervogel does not exist\n",
            "Word leeuwpoort does not exist\n",
            "Word otarioidea does not exist\n",
            "Word phocoidea does not exist\n",
            "Word vasilache does not exist\n",
            "Word zindīq does not exist\n",
            "Word xenolith does not exist\n",
            "Word jocotitlán does not exist\n",
            "Word tiraniemai does not exist\n",
            "Word aboleths does not exist\n",
            "Word flayers does not exist\n",
            "Word herpetarium does not exist\n",
            "Word bubulcus does not exist\n",
            "Word rinser does not exist\n",
            "Word thermomechanical does not exist\n",
            "Word gicas does not exist\n",
            "Word gaudavaho does not exist\n",
            "Word telehandlers does not exist\n",
            "Word adiyarkunallar does not exist\n",
            "Word cilappatikaram does not exist\n",
            "Word forqué does not exist\n",
            "Word didact does not exist\n",
            "Word bodach does not exist\n",
            "Word briogais does not exist\n",
            "Word blackdamp does not exist\n",
            "Word whitedamp does not exist\n",
            "Word confrères does not exist\n",
            "Word veirman does not exist\n",
            "Word mokjong does not exist\n",
            "Word duntisbourne does not exist\n",
            "Word tenejapa does not exist\n",
            "Word hoppmann does not exist\n",
            "Word yrarrázaval does not exist\n",
            "Word highspire does not exist\n",
            "Word flashings does not exist\n",
            "Word kinnim does not exist\n",
            "Word artmane does not exist\n",
            "Word barded does not exist\n",
            "Word milds does not exist\n",
            "Word snitchers does not exist\n",
            "Word thieve does not exist\n",
            "Word leoonard does not exist\n",
            "Word eärnil does not exist\n",
            "Word wainriders does not exist\n",
            "Word valenictus does not exist\n",
            "Word odobenus does not exist\n",
            "Word unrighteousness does not exist\n",
            "Word ravencroft does not exist\n",
            "Word japanac does not exist\n",
            "Word canul does not exist\n",
            "Word daishōs does not exist\n",
            "Word korfa does not exist\n",
            "Word ontop does not exist\n",
            "Word parure does not exist\n",
            "Word benade does not exist\n",
            "Word haardvark does not exist\n",
            "Word shukoff does not exist\n",
            "Word prerecord does not exist\n",
            "Word cherimoyas does not exist\n",
            "Word mameys does not exist\n",
            "Word spellbind does not exist\n",
            "Word beingal does not exist\n",
            "Word bovianum does not exist\n",
            "Word caenum does not exist\n",
            "Word kirchberger does not exist\n",
            "Word toonopedia does not exist\n",
            "Word mühlentor does not exist\n",
            "Word ohigashi does not exist\n",
            "Word masakatu does not exist\n",
            "Word colchic does not exist\n",
            "Word econlockhatchee does not exist\n",
            "Word ahgwey does not exist\n",
            "Word dismission does not exist\n",
            "Word betroth does not exist\n",
            "Word heimir does not exist\n",
            "Word ixali does not exist\n",
            "Word resummoned does not exist\n",
            "Word doxsey does not exist\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-pXbaJzExaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "ed45402c-c907-47b8-ce28-7415b8cde826"
      },
      "source": [
        "print(f\"Training mt: {len(zh_train_mt)} Training src: {len(zh_train_src)}\")\n",
        "print()\n",
        "print(f\"Validation mt: {len(zh_val_mt)} Validation src: {len(zh_val_src)}\")\n",
        "\n",
        "print(f\"CHI Dimension: {zh_train_mt[0].shape}\")\n",
        "print(f\"ENG Dimension: {zh_train_src[0].shape}\")"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training mt: 6997 Training src: 7000\n",
            "\n",
            "Validation mt: 1000 Validation src: 1000\n",
            "CHI Dimension: (100,)\n",
            "ENG Dimension: (100,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljBHJpa9ATNf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "9eb42674-c61f-450b-8851-629e3a221204"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "X_train= [zh_train_src, zh_train_mt]\n",
        "X_train_zh = np.array(X_train).transpose()\n",
        "X_train = np.dstack((zh_train_src, zh_train_mt))\n",
        "print(X_train_zh.shape)\n",
        "\n",
        "X_val = [np.array(zh_val_src),np.array(zh_val_mt)]\n",
        "X_val_zh = np.array(X_val).transpose()\n",
        "\n",
        "#Scores\n",
        "train_scores = np.array(zh_train_scores).astype(float)\n",
        "y_train_zh =train_scores\n",
        "\n",
        "val_scores = np.array(zh_val_scores).astype(float)\n",
        "y_val_zh =val_scores\n"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-0199165cad6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mzh_train_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_train_mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_train_zh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzh_train_src\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzh_train_mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_zh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mdstack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0marrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 7000 and the array at index 1 has size 6997"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luNEyefram7Z",
        "colab_type": "text"
      },
      "source": [
        "### Training the Regressor\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvCS6pa-yIIB",
        "colab_type": "text"
      },
      "source": [
        "At this point,  will try SVM and Random Tree Forests and choose the model with the highest Pearson correlation.\n",
        "\n",
        "First we will define our RMSE function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USalvKtRAvQv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def rmse(predictions, targets):\n",
        "    return np.sqrt(((predictions - targets) ** 2).mean())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0wOEUhXgteG",
        "colab_type": "text"
      },
      "source": [
        "#### SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rY29AeVyM1n",
        "colab_type": "text"
      },
      "source": [
        "SVM have many parameters such as the kernel and the regularizating constant C. Here we will use default C = 1 and compare kernels. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf_aJK0QK8jx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "outputId": "0b708ad9-ae36-4fcb-f29b-02ec861ba737"
      },
      "source": [
        "from sklearn.svm import SVR\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "for k in ['linear','poly','rbf','sigmoid']:\n",
        "    clf_t = SVR(kernel=k)\n",
        "    print(X_train_zh.shape)\n",
        "    clf_t.fit(X_train_zh, y_train_zh)\n",
        "    print(k)\n",
        "    predictions = clf_t.predict(X_val_zh)\n",
        "    pearson = pearsonr(y_val_zh, predictions)\n",
        "    print(f'RMSE: {rmse(predictions,y_val_zh)} Pearson {pearson[0]}')\n",
        "    print()\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-1886c1507f94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mclf_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_zh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mclf_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_zh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_zh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val_zh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    146\u001b[0m         X, y = check_X_y(X, y, dtype=np.float64,\n\u001b[1;32m    147\u001b[0m                          \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m                          accept_large_sparse=False)\n\u001b[0m\u001b[1;32m    149\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaOP4zpOgkFP",
        "colab_type": "text"
      },
      "source": [
        "In this case, the radial basis function kernel performed the best with a Pearson correlation of 0.1147. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wtg69eGbgmHI",
        "colab_type": "text"
      },
      "source": [
        "#### Random Tree Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OD22DmWvyPs-",
        "colab_type": "text"
      },
      "source": [
        "Another powerful regressor is the Random Tree Forest. Here we have to choose the number of trees we want to compute and we will pick n_estimators = 1000. The higher the number the longer it will compute. To fine tune that number you could compute the error per number of trees and select the number for which there is no more significant improvement( the \"elbow\" of the graph)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wEoExkggqHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the model we are using\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rf = RandomForestRegressor(n_estimators = 1000, random_state = 666)\n",
        "rf.fit(X_train_zh, y_train_zh);\n",
        "predictions = rf.predict(X_val_zh)\n",
        "\n",
        "pearson = pearsonr(y_val_zh, predictions)\n",
        "print('RMSE:', rmse(predictions,y_val_zh))\n",
        "print(f\"Pearson {pearson[0]}\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWiQ2X6Lj3iG",
        "colab_type": "text"
      },
      "source": [
        "Finally, we see that SVM with RBF kernel is the best model here. We will now use it to predict on the test set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cuIsX8LNiOJm",
        "colab_type": "text"
      },
      "source": [
        "### Writing Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SQlcfiCITuC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "def writeScores(method_name,scores):\n",
        "    fn = \"predictions.txt\"\n",
        "    print(\"\")\n",
        "    with open(fn, 'w') as output_file:\n",
        "        for idx,x in enumerate(scores):\n",
        "            #out =  metrics[idx]+\":\"+str(\"{0:.2f}\".format(x))+\"\\n\"\n",
        "            #print(out)\n",
        "            output_file.write(f\"{x}\\n\")\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VC3ALWVEXYVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EN_ZH\n",
        "\n",
        "zh_test_mt = get_sentence_embeddings_zh(\"./test.enzh.mt\")\n",
        "zh_test_src = get_embeddings(\"./test.enzh.src\",glove,nlp_en)\n",
        "\n",
        "X= [np.array(zh_test_mt),np.array(zh_test_src)]\n",
        "X_test_zh = np.array(X).transpose()\n",
        "\n",
        "#Predict\n",
        "clf_zh = SVR(kernel='rbf')\n",
        "clf_zh.fit(X_train_zh, y_train_zh)\n",
        "\n",
        "predictions_zh = clf_zh.predict(X_test_zh)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r-nDAsi3Xt-4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#EN_ZH\n",
        "\n",
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "\n",
        "writeScores(\"SVR\",predictions_zh)\n",
        "\n",
        "with ZipFile(\"en-zh_svr.zip\",\"w\") as newzip:\n",
        "\tnewzip.write(\"predictions.txt\")\n",
        " \n",
        "files.download('en-zh_svr.zip') \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlGblmKPyUFr",
        "colab_type": "text"
      },
      "source": [
        "### Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWUSJ7kAyXxC",
        "colab_type": "text"
      },
      "source": [
        "Once submitted to codalab, the pearson correlation is 0.0795"
      ]
    }
  ]
}