{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "QEV.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPCRxoyTtoPA24fEizb6JHM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ansonmiu0214/C490CW/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEKvQGwiJhlX",
        "colab_type": "text"
      },
      "source": [
        "# Coursework: BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70hpBC8gP-Ck",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "af6484c6-62c5-4d90-b7d3-77f1424a7ac7"
      },
      "source": [
        "!pip install pytorch-pretrained-bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch-pretrained-bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 22.2MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20kB 3.1MB/s eta 0:00:01\r\u001b[K     |████████                        | 30kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 40kB 3.0MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 51kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 61kB 4.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 71kB 5.0MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 81kB 5.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 92kB 6.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 102kB 4.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 112kB 4.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 122kB 4.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 4.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (4.28.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.17.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.4.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (1.11.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert) (2.21.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert) (1.14.15)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert) (2019.11.28)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (2.6.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch-pretrained-bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSN72uyXX8zr",
        "colab_type": "code",
        "outputId": "99322fd3-1eb4-46b5-b7bf-d8ecfecda9b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "# Imports\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sklearn\n",
        "import tqdm\n",
        "\n",
        "from pytorch_pretrained_bert import BertConfig, BertTokenizer, BertForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'DEVICE={device}')\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "print(torch.cuda.memory_summary(device=device))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEVICE=cuda\n",
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dW0tBzjD6zEw",
        "colab_type": "code",
        "outputId": "e642b346-3e6a-4196-90ad-83e717220027",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "# Google Drive authorisation\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ls /content/gdrive/My\\ Drive\n",
        "\n",
        "def in_gdrive(path):\n",
        "    return os.path.join('/content/gdrive/My Drive/Colab Notebooks', path)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-8431debcaf18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/gdrive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls /content/gdrive/My\\\\ Drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, use_metadata_server)\u001b[0m\n\u001b[1;32m    231\u001b[0m             \u001b[0;34m': timeout during initial read of root folder; for more info: '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             'https://research.google.com/colaboratory/faq.html#drive-timeout')\n\u001b[0;32m--> 233\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m       \u001b[0;31m# Not already authorized, so do the authorization dance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: mount failed"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JV59lAFJ2Tv",
        "colab_type": "text"
      },
      "source": [
        "## Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Rjr6T2qJlxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists('enzh_data.zip'):\n",
        "    !wget -O enzh_data.zip https://competitions.codalab.org/my/datasets/download/03e23bd7-8084-4542-997b-6a1ca6dd8a5f\n",
        "    !unzip enzh_data.zip\n",
        "\n",
        "TRAIN_EN = 'train.enzh.src'\n",
        "TRAIN_ZH = 'train.enzh.mt'\n",
        "TRAIN_SCORES = 'train.enzh.scores'\n",
        "VAL_EN = 'dev.enzh.src'\n",
        "VAL_ZH = 'dev.enzh.mt'\n",
        "VAL_SCORES = 'dev.enzh.scores'\n",
        "TEST_EN = 'test.enzh.src'\n",
        "TEST_ZH = 'test.enzh.mt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMBmQxeIQOPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read from file\n",
        "\n",
        "with open(TRAIN_EN) as f:\n",
        "    train_en = f.readlines()\n",
        "with open(TRAIN_ZH) as f:\n",
        "    train_zh = f.readlines()\n",
        "with open(TRAIN_SCORES) as f:\n",
        "    train_scores = [float(score.strip()) for score in f]\n",
        "with open(VAL_EN) as f:\n",
        "    val_en = f.readlines()\n",
        "with open(VAL_ZH) as f:\n",
        "    val_zh = f.readlines()\n",
        "with open(VAL_SCORES) as f:\n",
        "    val_scores = [float(score.strip()) for score in f]\n",
        "with open(TEST_EN) as f:\n",
        "    test_en = f.readlines()\n",
        "with open(TEST_ZH) as f:\n",
        "    test_zh = f.readlines()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MkP11o2TStyB",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zrSFbr_SvM6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "f7ba2ce9-0e12-4cc4-a8a0-08cffeb9e4f9"
      },
      "source": [
        "BERT_PRETRAINED_MODEL = 'bert-base-multilingual-cased'\n",
        "\n",
        "# Load tokenizer\n",
        "print(f'Loading tokenizer <{BERT_PRETRAINED_MODEL}>...', end=' ')\n",
        "tokenizer = BertTokenizer.from_pretrained(BERT_PRETRAINED_MODEL,\n",
        "                                          do_lower_case=False)\n",
        "print('done!')\n",
        "print()\n",
        "\n",
        "# Check tokenizer\n",
        "sample_sent_id = 42\n",
        "\n",
        "print('English')\n",
        "print(train_en[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_en[sample_sent_id]))\n",
        "print()\n",
        "\n",
        "print('Chinese')\n",
        "print(train_zh[sample_sent_id])\n",
        "print(tokenizer.tokenize(train_zh[sample_sent_id]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading tokenizer <bert-base-multilingual-cased>... done!\n",
            "\n",
            "English\n",
            "All 6 of the artillerymen recorded as wounded died).\n",
            "\n",
            "['All', '6', 'of', 'the', 'artillery', '##men', 'recorded', 'as', 'wounded', 'died', ')', '.']\n",
            "\n",
            "Chinese\n",
            "据记录 ， 所有 6 名炮兵都受伤了) 。\n",
            "\n",
            "['据', '记', '录', '，', '所', '有', '6', '名', '炮', '兵', '都', '受', '伤', '了', ')', '。']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mJWNZ4dWvFM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentence_pairs_to_bert_input(tokenizer, en_sents, zh_sents, *, max_seq_length=256):\n",
        "\n",
        "    bert_inputs = []\n",
        "\n",
        "    for en_sent, zh_sent in zip(en_sents, zh_sents):\n",
        "\n",
        "        en_tokens = tokenizer.tokenize(en_sent)\n",
        "        zh_tokens = tokenizer.tokenize(zh_sent)\n",
        "\n",
        "        num_bert_markers = 3\n",
        "\n",
        "        total_length = len(en_tokens) + len(zh_tokens) + num_bert_markers\n",
        "        if total_length > max_seq_length:\n",
        "            raise Exception(f'Too long ({total_length})')\n",
        "        \n",
        "        tokens = ['[CLS]'] + en_tokens + ['[SEP]'] + zh_tokens + ['[SEP]']\n",
        "\n",
        "        ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        padding = [0] * (max_seq_length - len(ids))\n",
        "\n",
        "        ids_tensor = torch.LongTensor(ids + padding)\n",
        "\n",
        "        bert_inputs.append(ids_tensor)\n",
        "\n",
        "    return torch.stack(bert_inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xvbsh2hjZVk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs = sentence_pairs_to_bert_input(tokenizer, train_en, train_zh, max_seq_length=132)\n",
        "val_inputs = sentence_pairs_to_bert_input(tokenizer, val_en, val_zh, max_seq_length=132)\n",
        "test_inputs = sentence_pairs_to_bert_input(tokenizer, test_en, test_zh, max_seq_length=132)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIwHlUgIdYbe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "\n",
        "def get_mini_batches(inputs, scores, *, batch_size=8):\n",
        "\n",
        "    num_batches = math.ceil(len(inputs) / batch_size)\n",
        "\n",
        "    for batch_id in range(num_batches):\n",
        "        start_id = batch_id * batch_size\n",
        "        end_id = (batch_id + 1) * batch_size\n",
        "        yield inputs[start_id:end_id], scores[start_id:end_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-yHLtLaRuK7",
        "colab_type": "text"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4aXOvi_blZ7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "outputId": "2028e868-4594-464c-f214-073a94fea5d2"
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "print(torch.cuda.memory_summary(device=device))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlJHziqpRwT-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = BertConfig(vocab_size_or_config_json_file=30522)\n",
        "\n",
        "class BertForQE(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.bert = BertForSequenceClassification.from_pretrained(BERT_PRETRAINED_MODEL, num_labels=1)\n",
        "        # self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "        # self.out = nn.Linear(config.hidden_size, 1)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        score = self.bert(input_ids)\n",
        "        # pooled = self.dropout(pooled_output)\n",
        "        # score = self.out(pooled_output)\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VRC6uyOgUOM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d65ab4f-49a8-437e-dc46-27c5c1f7f65a"
      },
      "source": [
        "model = BertForQE()\n",
        "print(model)\n",
        "\n",
        "LR = 0.003\n",
        "optimiser = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# optimiser = BertAdam(model.parameters(), lr=LR, schedule='warmup_linear', warmup=0.1, t_total=1000)\n",
        "\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BertForQE(\n",
            "  (bert): BertForSequenceClassification(\n",
            "    (bert): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): BertLayerNorm()\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): BertLayerNorm()\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): BertLayerNorm()\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): BertPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "    (classifier): Linear(in_features=768, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCGWXTLNZ0tl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gradient_descent(model, loss_fn, optimiser, input_ids, scores):\n",
        "    model.train()\n",
        "\n",
        "    model.zero_grad()\n",
        "\n",
        "    predictions = model(input_ids.to(device)).squeeze()\n",
        "    \n",
        "    loss = loss_fn(predictions, torch.Tensor(scores).to(device))\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimiser.step()\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train(model, loss_fn, optimiser, train_inputs, train_scores, val_inputs, val_scores, *, num_epochs=10, batch_size=32):\n",
        "\n",
        "    for epoch_idx in range(num_epochs):\n",
        "        print(f'Epoch #{epoch_idx + 1}')\n",
        "\n",
        "        model.to(device)\n",
        "        \n",
        "        processed = 0\n",
        "        increment = 0.05\n",
        "        milestone = 0.05\n",
        "        print('Training', end='')\n",
        "        for input_ids, scores in get_mini_batches(train_inputs, train_scores, batch_size=batch_size):\n",
        "            loss = gradient_descent(model, loss_fn, optimiser, input_ids, scores)\n",
        "            processed += len(input_ids)\n",
        "\n",
        "            if processed / len(train_inputs) >= milestone:\n",
        "                print('.', end='')\n",
        "                milestone += increment\n",
        "        print('done!')\n",
        "        print('Recent loss', loss)\n",
        "\n",
        "        # Check validation loss\n",
        "        model.eval()\n",
        "        model.to('cpu')\n",
        "\n",
        "        print('Getting validation predictions...', end='')\n",
        "        val_preds = model(val_inputs[:50]).squeeze().detach()\n",
        "        print(f'done! {val_preds[0]}..{val_preds[-1]}')\n",
        "        val_loss = loss_fn(val_preds, torch.Tensor(val_scores[:50]))\n",
        "        print('Validation loss', val_loss)\n",
        "\n",
        "        pearson, _ = pearsonr(val_preds.numpy(), np.array(val_scores[:50]))\n",
        "        print('Validation Pearson', pearson)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSoCgQ7YmKvW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1c2a51a1-651b-415e-b17c-b90edd6c5e90"
      },
      "source": [
        "train(model, loss_fn, optimiser, train_inputs[:100], train_scores[:100], val_inputs, val_scores, batch_size=8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch #1\n",
            "Training.............done!\n",
            "Recent loss tensor(0.8049, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! -0.7593356966972351..-0.7593356966972351\n",
            "Validation loss tensor(1.1567)\n",
            "Validation Pearson 0.020010134978328507\n",
            "Epoch #2\n",
            "Training.............done!\n",
            "Recent loss tensor(1.2965, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.27154621481895447..0.27154621481895447\n",
            "Validation loss tensor(0.7492)\n",
            "Validation Pearson -0.15317945884856743\n",
            "Epoch #3\n",
            "Training.............done!\n",
            "Recent loss tensor(1.0521, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.06314269453287125..0.06314270198345184\n",
            "Validation loss tensor(0.7395)\n",
            "Validation Pearson 0.0981606542187859\n",
            "Epoch #4\n",
            "Training.............done!\n",
            "Recent loss tensor(1.3717, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.17315824329853058..0.17315824329853058\n",
            "Validation loss tensor(0.7373)\n",
            "Validation Pearson nan\n",
            "Epoch #5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
            "  warnings.warn(PearsonRConstantInputWarning())\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training.............done!\n",
            "Recent loss tensor(1.1355, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! -0.018087113276124..-0.018087105825543404\n",
            "Validation loss tensor(0.7515)\n",
            "Validation Pearson 0.11258339568929353\n",
            "Epoch #6\n",
            "Training.............done!\n",
            "Recent loss tensor(1.1619, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.05061214044690132..0.05061214044690132\n",
            "Validation loss tensor(0.7408)\n",
            "Validation Pearson nan\n",
            "Epoch #7\n",
            "Training.............done!\n",
            "Recent loss tensor(1.2263, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.14069204032421112..0.14069204032421112\n",
            "Validation loss tensor(0.7363)\n",
            "Validation Pearson -0.08381997168645508\n",
            "Epoch #8\n",
            "Training.............done!\n",
            "Recent loss tensor(1.2192, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.05778025463223457..0.05778025463223457\n",
            "Validation loss tensor(0.7400)\n",
            "Validation Pearson 0.1565319490376306\n",
            "Epoch #9\n",
            "Training.............done!\n",
            "Recent loss tensor(1.3176, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.17504118382930756..0.17504118382930756\n",
            "Validation loss tensor(0.7374)\n",
            "Validation Pearson nan\n",
            "Epoch #10\n",
            "Training.............done!\n",
            "Recent loss tensor(1.1004, device='cuda:0', grad_fn=<SqrtBackward>)\n",
            "Getting validation predictions...done! 0.06424802541732788..0.06424804031848907\n",
            "Validation loss tensor(0.7394)\n",
            "Validation Pearson -0.02817262831633989\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQJ06kXdK-qc",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ZU6c-b6Lgp1",
        "colab_type": "text"
      },
      "source": [
        "### English\n",
        "\n",
        "1. Tokenise with spaCy language model\n",
        "2. Remove stop words and punctuation\n",
        "3. Normalise - lemmas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYS01soSJ8DP",
        "colab_type": "code",
        "outputId": "d6011b69-4bd0-4bc7-e97c-98ceecf81357",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "# Downloading spacy models for English\n",
        "\n",
        "!spacy download en_core_web_md\n",
        "!spacy link en_core_web_md en300 --force"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting en_core_web_md==2.1.0\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz (95.4MB)\n",
            "\u001b[K     |████████████████████████████████| 95.4MB 814kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-md\n",
            "  Building wheel for en-core-web-md (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-md: filename=en_core_web_md-2.1.0-cp36-none-any.whl size=97126236 sha256=a49473a29579e1d429d79548ab525630017c2af11f75936c97ddd80e22536f72\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-arqmcjtz/wheels/c1/2c/5f/fd7f3ec336bf97b0809c86264d2831c5dfb00fc2e239d1bb01\n",
            "Successfully built en-core-web-md\n",
            "Installing collected packages: en-core-web-md\n",
            "Successfully installed en-core-web-md-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/en_core_web_md -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/en300\n",
            "You can now load the model via spacy.load('en300')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ysk8sSgwOMNJ",
        "colab_type": "code",
        "outputId": "3c071a69-5bcf-4651-ad64-fe2201502b62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Downloading stop words for English\n",
        "\n",
        "from nltk import download\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "download('stopwords')\n",
        "stop_words_en = set(stopwords.words('english'))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFh-oANJOv9y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get tokenizer\n",
        "\n",
        "import spacy\n",
        "\n",
        "nlp_en = spacy.load('en300')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh5Bst_uRXzi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_en(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        text = sentence.lower()\n",
        "        processed = [token.lemma_ for token in nlp_en.tokenizer(text)]\n",
        "        processed = [token for token in processed if token.isalpha()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words_en]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UsvjK3mMGEW",
        "colab_type": "text"
      },
      "source": [
        "### Chinese\n",
        "\n",
        "1. Tokenise with jieba\n",
        "2. Remove stop words and punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YaaRTU3XMPmA",
        "colab_type": "code",
        "outputId": "693ea535-5560-40b3-dcb5-6dabaa1eb682",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        }
      },
      "source": [
        "# Download stop words\n",
        "FILE_STOP_WORDS_ZH = './chinese_stop_words.txt'\n",
        "\n",
        "if not os.path.exists(FILE_STOP_WORDS_ZH):\n",
        "    !wget -c https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
        "\n",
        "with open(FILE_STOP_WORDS_ZH, 'r', encoding='utf-8') as f:\n",
        "    stop_words_zh = [line.rstrip() for line in f]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-16 19:58:45--  https://github.com/Tony607/Chinese_sentiment_analysis/blob/master/data/chinese_stop_words.txt\n",
            "Resolving github.com (github.com)... 13.250.177.223\n",
            "Connecting to github.com (github.com)|13.250.177.223|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘chinese_stop_words.txt’\n",
            "\n",
            "\rchinese_stop_words.     [<=>                 ]       0  --.-KB/s               \rchinese_stop_words.     [ <=>                ] 416.77K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-02-16 19:58:46 (13.5 MB/s) - ‘chinese_stop_words.txt’ saved [426769]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmS0Q6fOUO2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import jieba\n",
        "\n",
        "def preprocess_zh(sentence=None, *, keep_stopwords=False):\n",
        "    def wrapper(sentence):\n",
        "        tokens = jieba.cut(sentence, cut_all=True)\n",
        "        processed = [token for token in tokens if token.isalnum()]\n",
        "        if not keep_stopwords:\n",
        "            processed = [token for token in processed if token not in stop_words]\n",
        "        return processed\n",
        "\n",
        "    return wrapper if sentence is None else wrapper(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meeee7ttmJD9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tn3Ar3-6MZWV",
        "colab_type": "text"
      },
      "source": [
        "## Language Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgPvP2XYMr5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Language(object):\n",
        "\n",
        "    SOS_TOKEN = '<SOS>'\n",
        "    EOS_TOKEN = '<EOS>'\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        self.word2idx = {}\n",
        "        self.word2count = {}\n",
        "        self.idx2word = {0: self.SOS_TOKEN,\n",
        "                         1: self.EOS_TOKEN,\n",
        "                         2: self.UNK_TOKEN}\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.idx2word)\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for token in sentence:\n",
        "            self.add_word(token)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2idx:\n",
        "            idx = len(self)\n",
        "            self.word2idx[word] = idx\n",
        "            self.idx2word[idx] = word\n",
        "        \n",
        "        count = self.word2count.get(word, 0)\n",
        "        self.word2count[word] = count + 1\n",
        "\n",
        "    def sent_to_idxs(self, sent):\n",
        "        return [self.word2idx.get(word, 2) for word in sent]\n",
        "    \n",
        "    def __repr__(self):\n",
        "        return f'Language(name={self.name}) with {len(self)} words'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DZWJs-CQMIb",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aaR6q37RMsO",
        "colab_type": "code",
        "outputId": "77795c1b-2d12-415f-a1a7-1370afc3d997",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# English data\n",
        "\n",
        "preprocess_english = preprocess_en(keep_stopwords=True)\n",
        "\n",
        "train_en_sents = [preprocess_english(sent) for sent in train_en]\n",
        "val_en_sents = [preprocess_english(sent) for sent in val_en]\n",
        "test_en_sents = [preprocess_english(sent) for sent in test_en]\n",
        "\n",
        "EN = Language('EN')\n",
        "for sent in train_en_sents:\n",
        "    EN.add_sentence(sent)\n",
        "\n",
        "print(EN)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_en = train_en_sents[42]\n",
        "print(sample_sent_en)\n",
        "print(EN.sent_to_idxs(sample_sent_en))\n",
        "\n",
        "train_en_idxs = [EN.sent_to_idxs(sent) for sent in train_en_sents]\n",
        "val_en_idxs = [EN.sent_to_idxs(sent) for sent in val_en_sents]\n",
        "test_en_idxs = [EN.sent_to_idxs(sent) for sent in test_en_sents]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Language(name=EN) with 19248 words\n",
            "\n",
            "Sample sentence\n",
            "['all', 'of', 'the', 'artilleryman', 'record', 'a', 'wound', 'die']\n",
            "[340, 31, 3, 341, 342, 59, 343, 344]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "DEZK9El_U9v3",
        "outputId": "6243c115-1c54-4aaf-cea7-c7cee28ed695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "# Chinese data\n",
        "\n",
        "preprocess_chinese = preprocess_zh(keep_stopwords=True)\n",
        "\n",
        "train_zh_sents = [preprocess_chinese(sent) for sent in train_zh]\n",
        "val_zh_sents = [preprocess_chinese(sent) for sent in val_zh]\n",
        "test_zh_sents = [preprocess_chinese(sent) for sent in test_zh]\n",
        "\n",
        "ZH = Language('ZH')\n",
        "for sent in train_zh_sents:\n",
        "    ZH.add_sentence(sent)\n",
        "\n",
        "print(ZH)\n",
        "\n",
        "print()\n",
        "print('Sample sentence')\n",
        "sample_sent_zh = train_zh_sents[42]\n",
        "print(sample_sent_zh)\n",
        "print(ZH.sent_to_idxs(sample_sent_zh))\n",
        "\n",
        "train_zh_idxs = [ZH.sent_to_idxs(sent) for sent in train_zh_sents]\n",
        "val_zh_idxs = [ZH.sent_to_idxs(sent) for sent in val_zh_sents]\n",
        "test_zh_idxs = [ZH.sent_to_idxs(sent) for sent in test_zh_sents]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.774 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Language(name=ZH) with 23851 words\n",
            "\n",
            "Sample sentence\n",
            "['据', '记录', '所有', '6', '名', '炮兵', '都', '受伤', '了']\n",
            "[483, 484, 485, 267, 486, 487, 488, 489, 17]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCR41KviW6Ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Process scores\n",
        "\n",
        "def prepare_score(score):\n",
        "    return float(score)\n",
        "\n",
        "train_scores = [prepare_score(score) for score in train_scores]\n",
        "val_scores = [prepare_score(score) for score in val_scores]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qYQlzaEWViN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Datasets\n",
        "\n",
        "train_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_en_idxs]\n",
        "train_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in train_zh_idxs]\n",
        "\n",
        "train_pairs = list(zip(train_en_tensors, train_zh_tensors))\n",
        "train_set = list(zip(train_pairs, train_scores))\n",
        "\n",
        "val_en_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_en_idxs]\n",
        "val_zh_tensors = [torch.LongTensor(sent_idxs) for sent_idxs in val_zh_idxs]\n",
        "\n",
        "val_pairs = list(zip(val_en_tensors, val_zh_tensors))\n",
        "val_set = list(zip(val_pairs, val_scores))\n",
        "\n",
        "# val_pairs = list(zip(val_en_idxs, val_zh_idxs))\n",
        "# test_pairs = list(zip(test_en_idxs, test_zh_idxs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBU5dUInLx-R",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOtsfA_hdPmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Utilities\n",
        "\n",
        "from scipy.stats.stats import pearsonr\n",
        "\n",
        "def unzip(args):\n",
        "    return zip(*args)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZFiF4FSRlCx",
        "colab_type": "text"
      },
      "source": [
        "### FFNN with trained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oWCA9Mdbbta",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FFNN(nn.Module):\n",
        "    \n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_hidden = nn.Linear(self.emb_dim, 1)\n",
        "        self.zh_hidden = nn.Linear(self.emb_dim, 1)\n",
        "\n",
        "        self.out = nn.Linear(2, 1)\n",
        "    \n",
        "    def forward(self, en_tensors, zh_tensors):\n",
        "        en_emb = self.en_embedding(en_tensors)\n",
        "        zh_emb = self.zh_embedding(zh_tensors)\n",
        "\n",
        "        en_hid = F.relu(self.en_hidden(en_emb))\n",
        "        zh_hid = F.relu(self.zh_hidden(en_emb))\n",
        "\n",
        "        hid_concat = torch.stack((en_hid, zh_hid), axis=1).squeeze()\n",
        "        score = self.out(hid_concat)\n",
        "        return score.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NZ1SoBa5csKg",
        "colab_type": "code",
        "outputId": "6fb3fc7f-8e45-494d-bc20-ec352a0efeb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "ffnn = FFNN(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=200)\n",
        "ffnn.to(device)\n",
        "print(ffnn)\n",
        "\n",
        "ffnn_opt = torch.optim.Adam(ffnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FFNN(\n",
            "  (en_embedding): Embedding(19248, 200)\n",
            "  (zh_embedding): Embedding(23851, 200)\n",
            "  (en_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (zh_hidden): Linear(in_features=200, out_features=1, bias=True)\n",
            "  (out): Linear(in_features=2, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa9MTNFHdTJ4",
        "colab_type": "code",
        "outputId": "9914e71c-2679-4927-a496-bec543c87efc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        }
      },
      "source": [
        "NUM_EPOCHS = 100\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_pearson = []\n",
        "\n",
        "for eidx in range(NUM_EPOCHS):\n",
        "    print(f'Epoch {eidx + 1}: \\t', end=' ')\n",
        "    ffnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        loss += loss_fn(pred, score)\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    train_losses.append(loss)\n",
        "    \n",
        "    print(f'train loss = {loss:.5f}\\t', end='')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    for (en_tensor, zh_tensor), score in val_set:\n",
        "        pred = ffnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'validation loss = {val_loss:.5f}\\t', end='')\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(ffnn(en_tensor.to(device), zh_tensor.to(device)).detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    \n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    val_pearson.append(pearson_score)\n",
        "    print(f'validation pearson = {pearson_score:.5f}\\t')\n",
        "\n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    ffnn_opt.step()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1: \t train loss = 0.87688\tvalidation loss = 0.88592\tvalidation pearson = 0.01748\t\n",
            "Epoch 2: \t train loss = 0.86025\tvalidation loss = 0.87088\tvalidation pearson = 0.02019\t\n",
            "Epoch 3: \t train loss = 0.84733\tvalidation loss = 0.85943\tvalidation pearson = 0.01939\t\n",
            "Epoch 4: \t train loss = 0.83801\tvalidation loss = 0.85154\tvalidation pearson = 0.02470\t\n",
            "Epoch 5: \t train loss = 0.82957\tvalidation loss = 0.84433\tvalidation pearson = 0.03254\t\n",
            "Epoch 6: \t train loss = 0.82264\tvalidation loss = 0.83841\tvalidation pearson = 0.03838\t\n",
            "Epoch 7: \t train loss = 0.81701\tvalidation loss = 0.83367\tvalidation pearson = 0.04050\t\n",
            "Epoch 8: \t train loss = 0.81212\tvalidation loss = 0.82953\tvalidation pearson = 0.04263\t\n",
            "Epoch 9: \t train loss = 0.80755\tvalidation loss = 0.82555\tvalidation pearson = 0.04476\t\n",
            "Epoch 10: \t train loss = 0.80332\tvalidation loss = 0.82175\tvalidation pearson = 0.04683\t\n",
            "Epoch 11: \t train loss = 0.79937\tvalidation loss = 0.81817\tvalidation pearson = 0.04816\t\n",
            "Epoch 12: \t train loss = 0.79570\tvalidation loss = 0.81483\tvalidation pearson = 0.04975\t\n",
            "Epoch 13: \t train loss = 0.79230\tvalidation loss = 0.81172\tvalidation pearson = 0.05156\t\n",
            "Epoch 14: \t train loss = 0.78910\tvalidation loss = 0.80876\tvalidation pearson = 0.05291\t\n",
            "Epoch 15: \t train loss = 0.78611\tvalidation loss = 0.80595\tvalidation pearson = 0.05509\t\n",
            "Epoch 16: \t train loss = 0.78332\tvalidation loss = 0.80328\tvalidation pearson = 0.05735\t\n",
            "Epoch 17: \t train loss = 0.78071\tvalidation loss = 0.80075\tvalidation pearson = 0.05934\t\n",
            "Epoch 18: \t train loss = 0.77822\tvalidation loss = 0.79836\tvalidation pearson = 0.06081\t\n",
            "Epoch 19: \t train loss = 0.77587\tvalidation loss = 0.79610\tvalidation pearson = 0.06205\t\n",
            "Epoch 20: \t train loss = 0.77364\tvalidation loss = 0.79395\tvalidation pearson = 0.06280\t\n",
            "Epoch 21: \t train loss = 0.77155\tvalidation loss = 0.79191\tvalidation pearson = 0.06318\t\n",
            "Epoch 22: \t train loss = 0.76956\tvalidation loss = 0.78997\tvalidation pearson = 0.06354\t\n",
            "Epoch 23: \t train loss = 0.76765\tvalidation loss = 0.78811\tvalidation pearson = 0.06419\t\n",
            "Epoch 24: \t train loss = 0.76582\tvalidation loss = 0.78636\tvalidation pearson = 0.06420\t\n",
            "Epoch 25: \t train loss = 0.76406\tvalidation loss = 0.78469\tvalidation pearson = 0.06371\t\n",
            "Epoch 26: \t train loss = 0.76236\tvalidation loss = 0.78310\tvalidation pearson = 0.06218\t\n",
            "Epoch 27: \t train loss = 0.76072\tvalidation loss = 0.78159\tvalidation pearson = 0.06035\t\n",
            "Epoch 28: \t train loss = 0.75912\tvalidation loss = 0.78014\tvalidation pearson = 0.05821\t\n",
            "Epoch 29: \t train loss = 0.75758\tvalidation loss = 0.77875\tvalidation pearson = 0.05548\t\n",
            "Epoch 30: \t train loss = 0.75608\tvalidation loss = 0.77741\tvalidation pearson = 0.05306\t\n",
            "Epoch 31: \t train loss = 0.75461\tvalidation loss = 0.77611\tvalidation pearson = 0.05023\t\n",
            "Epoch 32: \t train loss = 0.75317\tvalidation loss = 0.77483\tvalidation pearson = 0.04724\t\n",
            "Epoch 33: \t train loss = 0.75175\tvalidation loss = 0.77359\tvalidation pearson = 0.04478\t\n",
            "Epoch 34: \t train loss = 0.75036\tvalidation loss = 0.77236\tvalidation pearson = 0.04302\t\n",
            "Epoch 35: \t "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUlPsvWsL4mp",
        "colab_type": "text"
      },
      "source": [
        "### RNN Chain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UkdfLZMoI5j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, en_vocab_size, zh_vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.en_vocab_size = en_vocab_size\n",
        "        self.zh_vocab_size = zh_vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.en_embedding = nn.Embedding(self.en_vocab_size, self.emb_dim)\n",
        "        self.zh_embedding = nn.Embedding(self.zh_vocab_size, self.emb_dim)\n",
        "\n",
        "        self.en_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "        self.zh_rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, en_tensor, zh_tensor):\n",
        "        en_emb = self.en_embedding(en_tensor)\n",
        "        zh_emb = self.zh_embedding(zh_tensor)\n",
        "\n",
        "        en_hidden = torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "        for word_idx in en_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, en_hidden = self.en_rnn(word_idx, en_hidden)\n",
        "    \n",
        "        zh_hidden = en_hidden\n",
        "        for word_idx in zh_emb:\n",
        "            word_idx = word_idx.view(1, 1, -1)\n",
        "            _, zh_hidden = self.zh_rnn(word_idx, zh_hidden)\n",
        "\n",
        "        score = self.out(F.relu(self.hidden(zh_hidden[-1])))\n",
        "        return score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDPzyUWzp4ZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "USE_PREV = True\n",
        "\n",
        "rnn = RNNChain(en_vocab_size=len(EN), zh_vocab_size=len(ZH), emb_dim=100)\n",
        "rnn.to(device)\n",
        "\n",
        "rnn_opt = torch.optim.Adam(rnn.parameters(), lr=0.003)\n",
        "loss_fn = RMSELoss\n",
        "\n",
        "NUM_EPOCHS = 100\n",
        "\n",
        "state = {\n",
        "    'curr_epoch': 1,\n",
        "    'train_losses': [],\n",
        "    'val_losses': [],\n",
        "    'val_pearson': [],\n",
        "}\n",
        "\n",
        "if USE_PREV and os.path.exists(in_gdrive('rnn.pt')):\n",
        "    print('Loading from Google Drive...', end=' ')\n",
        "    rnn.load_state_dict(torch.load(in_gdrive('rnn.pt')))\n",
        "\n",
        "    with open(in_gdrive('rnn.json'), 'r') as f:\n",
        "        state = json.load(f)\n",
        "    print('done!')\n",
        "\n",
        "\n",
        "while state['curr_epoch'] <= NUM_EPOCHS:\n",
        "    print(f'Epoch {state[\"curr_epoch\"]}:')\n",
        "    rnn.zero_grad()\n",
        "    \n",
        "    loss = 0\n",
        "    print(f'Training {len(train_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(train_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze()\n",
        "        curr_loss = loss_fn(pred, score) \n",
        "        loss += curr_loss\n",
        "        if idx % 500 == 0:\n",
        "            print('.', end='')\n",
        "    print()\n",
        "\n",
        "    loss /= len(train_set)\n",
        "    state['train_losses'].append(loss.detach().cpu().numpy().tolist())\n",
        "    \n",
        "    print(f'==>train loss = {loss:.5f}')\n",
        "\n",
        "    # Validation loss\n",
        "    val_loss = 0\n",
        "    print(f'Validating loss {len(val_set)}: ', end='')\n",
        "    for idx, ((en_tensor, zh_tensor), score) in enumerate(val_set):\n",
        "        pred = rnn(en_tensor.to(device), zh_tensor.to(device))\n",
        "        val_loss += loss_fn(pred, score)\n",
        "\n",
        "        if idx % 100 == 0:\n",
        "            print('.', end='')\n",
        "    print()    \n",
        "\n",
        "    val_loss /= len(val_set)\n",
        "    print(f'==>validation loss = {val_loss:.5f}')\n",
        "    state['val_losses'].append(val_loss.detach().cpu().numpy().tolist())\n",
        "\n",
        "    # Validation score\n",
        "    val_preds, val_targets = unzip([(rnn(en_tensor.to(device), zh_tensor.to(device)).squeeze().detach().cpu().numpy(), score)\n",
        "                              for (en_tensor, zh_tensor), score in val_set])\n",
        "    val_preds = np.array(val_preds)\n",
        "    val_targets = np.array(val_targets)\n",
        "\n",
        "    pearson_score, _ = pearsonr(val_preds, val_targets)\n",
        "    state['val_pearson'].append(pearson_score)\n",
        "    print(f'==>validation pearson = {pearson_score:.5f}')\n",
        "\n",
        "    # Backpropagation\n",
        "    print('Backpropagation...', end=' ')\n",
        "    loss.backward()\n",
        "    rnn_opt.step()\n",
        "    print('done!')\n",
        "\n",
        "    # Save\n",
        "    print('Saving to Google Drive...', end=' ')\n",
        "    torch.save(rnn.state_dict(), in_gdrive('rnn.pt'))\n",
        "\n",
        "    state['curr_epoch'] += 1\n",
        "    with open(in_gdrive('rnn.json'), 'w') as f:\n",
        "        json.dump(state, f)\n",
        "\n",
        "    print('done!\\n')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxsp-O3FL3si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RNNChain(nn.Module):\n",
        "\n",
        "    def __init__(self, *, vocab_size, emb_dim):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.emb_dim)\n",
        "        self.rnn = nn.GRU(self.emb_dim, self.emb_dim, bidirectional=True)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        emb = self.embedding(x)\n",
        "        output = emb.view(1, 1, -1)\n",
        "        output, hidden = self.rnn(output, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return torch.zeros(2, 1, self.emb_dim, device=device)\n",
        "\n",
        "class RegressorLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, *, emb_dim):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "\n",
        "        self.hidden = nn.Linear(self.emb_dim, 50)\n",
        "        self.out = nn.Linear(50, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.out(F.relu(self.hidden(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5ZnU2SMa9hh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_model = RNNChain(vocab_size=len(EN), emb_dim=200)\n",
        "zh_model = RNNChain(vocab_size=len(ZH), emb_dim=200)\n",
        "regressor = RegressorLayer(emb_dim=200)\n",
        "\n",
        "en_model.to(device)\n",
        "zh_model.to(device)\n",
        "regressor.to(device)\n",
        "\n",
        "print(en_model)\n",
        "print(zh_model)\n",
        "\n",
        "LR = 0.003\n",
        "\n",
        "en_opt = torch.optim.Adam(en_model.parameters(), lr=LR)\n",
        "zh_opt = torch.optim.Adam(zh_model.parameters(), lr=LR)\n",
        "regressor_opt = torch.optim.Adam(regressor.parameters(), lr=LR)\n",
        "\n",
        "def RMSELoss(pred, target):\n",
        "    return torch.sqrt(torch.mean((pred - target) ** 2))\n",
        "\n",
        "loss_fn = RMSELoss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MOiNoElbLD5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(en_tensor, zh_tensor, score):\n",
        "    en_model.zero_grad()\n",
        "    zh_model.zero_grad()\n",
        "\n",
        "    en_hidden = en_model.init_hidden()\n",
        "\n",
        "    for word_idx in en_tensor:\n",
        "        hids, en_hidden = en_model(word_idx, en_hidden)\n",
        "        print('Hids', hids.shape)\n",
        "    \n",
        "    # print('EN final hidden state', en_hidden)\n",
        "\n",
        "    zh_hidden = en_hidden\n",
        "    for word_idx in zh_tensor:\n",
        "        _, zh_hidden = zh_model(word_idx, zh_hidden)\n",
        "    \n",
        "    # print('ZH final hidden state', zh_hidden)\n",
        "\n",
        "    pred_score = regressor(zh_hidden).squeeze()\n",
        "\n",
        "    loss = loss_fn(pred_score, score)\n",
        "    \n",
        "    # print('Loss', loss)    \n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    regressor_opt.step()\n",
        "    zh_opt.step()\n",
        "    en_opt.step()\n",
        "\n",
        "    return loss.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzmHLS82c8Yu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "for eidx in range(100):\n",
        "    loss = 0\n",
        "    for (en_tensor, zh_tensor), score in train_set[:100]:\n",
        "        loss += train(en_tensor.to(device), zh_tensor.to(device), score)\n",
        "    loss /= 100\n",
        "    print(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW6b5QrLdOnK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}